{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"russo","text":"<p> Testing framework for LLM tool-call accuracy \u2014 audio &amp; text </p> <p> </p> <p>Documentation: https://mohit2152sharma.github.io/russo</p> <p>Source Code: https://github.com/mohit2152sharma/russo</p> <p>russo is a testing framework for verifying that LLM agents make the correct tool calls when given audio (or text) input. Think of it as pytest for voice AI tool-calling accuracy.</p>"},{"location":"#why-russo","title":"Why russo?","text":"<p>Voice AI agents powered by LLMs increasingly use tool calling (function calling) to take actions \u2014 booking flights, controlling smart homes, querying databases. But how do you verify the agent calls the right tool with the right arguments when it hears a spoken command?</p> <p>russo solves this with a simple pipeline:</p> <pre><code>Text Prompt \u2192 Synthesizer (TTS) \u2192 Agent Under Test \u2192 Evaluator \u2192 Pass/Fail\n</code></pre>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Provider-agnostic \u2014 works with Gemini, OpenAI, or any custom agent via structural typing (protocols)</li> <li>Audio-first \u2014 synthesize text prompts to audio, send to your agent, evaluate tool calls</li> <li>pytest integration \u2014 use markers, fixtures, and familiar test patterns</li> <li>Built-in caching \u2014 skip TTS on repeated runs, saving time and money</li> <li>Extensible \u2014 swap synthesizers, agents, evaluators, and parsers without inheritance</li> </ul>"},{"location":"#quick-example","title":"Quick Example","text":"<pre><code>import russo\nfrom russo.synthesizers import GoogleSynthesizer\nfrom russo.adapters import GeminiLiveAgent\nfrom russo.evaluators import ExactEvaluator\n\nresult = await russo.run(\n    prompt=\"Book a flight from Berlin to Rome for tomorrow\",\n    synthesizer=GoogleSynthesizer(api_key=\"...\"),\n    agent=GeminiLiveAgent(api_key=\"...\", tools=[...]),\n    evaluator=ExactEvaluator(),\n    expect=[\n        russo.tool_call(\"book_flight\", from_city=\"Berlin\", to_city=\"Rome\"),\n    ],\n)\n\nassert result.passed\n</code></pre> <p>Or with pytest:</p> <pre><code>import pytest\nimport russo\n\n@pytest.mark.russo(\n    prompt=\"Book a flight from NYC to LA\",\n    expect=[russo.tool_call(\"book_flight\", from_city=\"NYC\", to_city=\"LA\")],\n)\nasync def test_book_flight(russo_result):\n    russo.assert_tool_calls(russo_result)\n</code></pre>"},{"location":"#architecture","title":"Architecture","text":"<p>russo uses a protocol-based design. You never need to inherit from base classes \u2014 if your object has the right methods, it works:</p> <pre><code>graph LR\n    A[Text Prompt] --&gt; B[Synthesizer]\n    B --&gt; C[Audio]\n    C --&gt; D[Agent]\n    D --&gt; E[AgentResponse]\n    E --&gt; F[Evaluator]\n    F --&gt; G[EvalResult]</code></pre> Protocol Method Purpose <code>Synthesizer</code> <code>async synthesize(text) \u2192 Audio</code> Convert text to audio <code>Agent</code> <code>async run(audio) \u2192 AgentResponse</code> Run the agent under test <code>Evaluator</code> <code>evaluate(expected, actual) \u2192 EvalResult</code> Compare tool calls <code>ResponseParser</code> <code>parse(raw) \u2192 AgentResponse</code> Normalize provider responses"},{"location":"#next-steps","title":"Next Steps","text":"<ul> <li>Installation \u2014 install russo and optional dependencies</li> <li>First Test \u2014 write your first tool-call test</li> <li>Tutorial \u2014 deep dive into every component</li> <li>API Reference \u2014 full API documentation</li> </ul>"},{"location":"concepts/architecture/","title":"Architecture","text":"<p>russo is designed around a simple pipeline with pluggable components connected by protocols.</p>"},{"location":"concepts/architecture/#the-pipeline","title":"The Pipeline","text":"<pre><code>graph TD\n    P[\"Text Prompt\"]\n    S[\"Synthesizer\"]\n    C[\"Cache Layer\"]\n    AG[\"Agent Under Test\"]\n    PR[\"Response Parser\"]\n    E[\"Evaluator\"]\n    R[\"EvalResult\"]\n\n    P --&gt; S\n    S &lt;-.-&gt; C\n    S --&gt;|Audio| AG\n    AG --&gt;|Raw Response| PR\n    PR --&gt;|AgentResponse| E\n    E --&gt; R</code></pre>"},{"location":"concepts/architecture/#flow","title":"Flow","text":"<ol> <li>Text Prompt \u2192 The natural language instruction (e.g., \"Book a flight from Berlin to Rome\")</li> <li>Synthesizer \u2192 Converts text to audio using a TTS provider. The cache layer intercepts here to avoid redundant API calls.</li> <li>Agent \u2192 The LLM agent under test receives the audio and returns tool calls. Agents may use a ResponseParser internally to normalize provider-specific formats.</li> <li>Evaluator \u2192 Compares expected tool calls against actual ones, producing a detailed <code>EvalResult</code>.</li> </ol>"},{"location":"concepts/architecture/#data-types","title":"Data Types","text":"<p>All data flows through Pydantic models:</p> <pre><code>classDiagram\n    class Audio {\n        +bytes data\n        +str format\n        +int sample_rate\n        +int channels\n        +save(path)\n    }\n\n    class ToolCall {\n        +str name\n        +dict arguments\n    }\n\n    class AgentResponse {\n        +list~ToolCall~ tool_calls\n        +Any raw\n    }\n\n    class EvalResult {\n        +bool passed\n        +list~ToolCall~ expected\n        +list~ToolCall~ actual\n        +list~ToolCallMatch~ matches\n        +match_rate() float\n        +summary() str\n    }\n\n    class ToolCallMatch {\n        +ToolCall expected\n        +ToolCall actual\n        +bool matched\n        +str details\n    }\n\n    AgentResponse --&gt; ToolCall\n    EvalResult --&gt; ToolCall\n    EvalResult --&gt; ToolCallMatch\n    ToolCallMatch --&gt; ToolCall</code></pre>"},{"location":"concepts/architecture/#design-principles","title":"Design Principles","text":""},{"location":"concepts/architecture/#protocol-based-structural-typing","title":"Protocol-based (Structural Typing)","text":"<p>russo uses <code>typing.Protocol</code> for all extension points. You never inherit from a base class \u2014 if your object has the right methods, it works:</p> <pre><code># This is a valid Synthesizer \u2014 no inheritance needed\nclass MySynth:\n    async def synthesize(self, text: str) -&gt; Audio:\n        ...\n</code></pre>"},{"location":"concepts/architecture/#async-first","title":"Async-first","text":"<p>The pipeline is fully async. Synthesizers and agents are <code>async</code> methods, making it natural to call external APIs without blocking.</p>"},{"location":"concepts/architecture/#provider-agnostic","title":"Provider-agnostic","text":"<p>The core pipeline knows nothing about Gemini, OpenAI, or any specific provider. Provider-specific logic lives in adapters and parsers.</p>"},{"location":"concepts/architecture/#pydantic-models","title":"Pydantic Models","text":"<p>All data types are Pydantic models, giving you:</p> <ul> <li>Automatic validation</li> <li>Serialization / deserialization</li> <li>Rich <code>repr</code> for debugging</li> <li>Type safety</li> </ul>"},{"location":"concepts/architecture/#module-layout","title":"Module Layout","text":"<pre><code>russo/\n\u251c\u2500\u2500 __init__.py          # Public API surface\n\u251c\u2500\u2500 _types.py            # Pydantic data models\n\u251c\u2500\u2500 _protocols.py        # Protocol definitions\n\u251c\u2500\u2500 _pipeline.py         # The run() function\n\u251c\u2500\u2500 _cache.py            # AudioCache + CachedSynthesizer\n\u251c\u2500\u2500 _helpers.py          # tool_call() + @agent decorator\n\u251c\u2500\u2500 _assertions.py       # assert_tool_calls()\n\u251c\u2500\u2500 adapters/            # Agent adapters (Gemini, OpenAI, HTTP, WS)\n\u251c\u2500\u2500 synthesizers/        # TTS providers (Google)\n\u251c\u2500\u2500 evaluators/          # Matching logic (ExactEvaluator)\n\u251c\u2500\u2500 parsers/             # Response normalizers (Gemini, OpenAI)\n\u251c\u2500\u2500 report/              # Terminal + HTML reporting\n\u251c\u2500\u2500 pytest_plugin.py     # pytest integration\n\u251c\u2500\u2500 cli.py               # CLI runner\n\u251c\u2500\u2500 config.py            # Config file loading\n\u251c\u2500\u2500 models.py            # Extended models for CLI/config mode\n\u251c\u2500\u2500 interfaces.py        # ABC interfaces for CLI/config mode\n\u251c\u2500\u2500 pipeline.py          # CLI pipeline runner\n\u2514\u2500\u2500 registry.py          # Component registry for config mode\n</code></pre> <p>Private modules (prefixed with <code>_</code>) contain the core API. Public modules contain provider-specific implementations and integrations.</p>"},{"location":"concepts/protocols/","title":"Protocols","text":"<p>russo uses Python's <code>typing.Protocol</code> for all extension points. This means structural subtyping \u2014 you don't need to inherit from a base class. If your class has the right methods with the right signatures, it satisfies the protocol.</p>"},{"location":"concepts/protocols/#why-protocols","title":"Why Protocols?","text":"<ul> <li>No coupling \u2014 your code never depends on russo base classes</li> <li>Duck typing with type safety \u2014 mypy/pyright verify protocol conformance at check time</li> <li>Runtime checkable \u2014 all russo protocols are <code>@runtime_checkable</code>, so <code>isinstance()</code> works too</li> </ul>"},{"location":"concepts/protocols/#the-four-protocols","title":"The Four Protocols","text":""},{"location":"concepts/protocols/#synthesizer","title":"Synthesizer","text":"<p>Converts text to audio.</p> <pre><code>@runtime_checkable\nclass Synthesizer(Protocol):\n    async def synthesize(self, text: str) -&gt; Audio: ...\n</code></pre> <p>Implementations: <code>GoogleSynthesizer</code>, <code>CachedSynthesizer</code>, or any class with a matching <code>synthesize</code> method.</p>"},{"location":"concepts/protocols/#agent","title":"Agent","text":"<p>The agent under test. Takes audio, returns tool calls.</p> <pre><code>@runtime_checkable\nclass Agent(Protocol):\n    async def run(self, audio: Audio) -&gt; AgentResponse: ...\n</code></pre> <p>Implementations: <code>GeminiAgent</code>, <code>GeminiLiveAgent</code>, <code>OpenAIAgent</code>, <code>OpenAIRealtimeAgent</code>, <code>HttpAgent</code>, <code>WebSocketAgent</code>, <code>CallableAgent</code>, or any class with a matching <code>run</code> method.</p>"},{"location":"concepts/protocols/#evaluator","title":"Evaluator","text":"<p>Compares expected tool calls against actual ones.</p> <pre><code>@runtime_checkable\nclass Evaluator(Protocol):\n    def evaluate(self, expected: list[ToolCall], actual: list[ToolCall]) -&gt; EvalResult: ...\n</code></pre> <p>Implementations: <code>ExactEvaluator</code>, or any class with a matching <code>evaluate</code> method.</p>"},{"location":"concepts/protocols/#responseparser","title":"ResponseParser","text":"<p>Normalizes provider-specific raw responses into <code>AgentResponse</code>.</p> <pre><code>@runtime_checkable\nclass ResponseParser(Protocol):\n    def parse(self, raw_response: Any) -&gt; AgentResponse: ...\n</code></pre> <p>Implementations: <code>GeminiResponseParser</code>, <code>OpenAIResponseParser</code>, or any class with a matching <code>parse</code> method.</p>"},{"location":"concepts/protocols/#implementing-a-protocol","title":"Implementing a Protocol","text":"<p>Just write a class with the right method:</p> <pre><code>import russo\n\nclass MyEvaluator:\n    def evaluate(\n        self,\n        expected: list[russo.ToolCall],\n        actual: list[russo.ToolCall],\n    ) -&gt; russo.EvalResult:\n        # Your custom matching logic\n        passed = len(expected) == len(actual)\n        return russo.EvalResult(\n            passed=passed,\n            expected=expected,\n            actual=actual,\n        )\n\n# Works with russo.run() \u2014 no inheritance needed\nresult = await russo.run(\n    ...,\n    evaluator=MyEvaluator(),\n    ...,\n)\n</code></pre>"},{"location":"concepts/protocols/#runtime-checking","title":"Runtime Checking","text":"<pre><code>from russo._protocols import Synthesizer, Agent, Evaluator\n\nassert isinstance(my_synth, Synthesizer)    # True if it has .synthesize()\nassert isinstance(my_agent, Agent)          # True if it has .run()\nassert isinstance(my_eval, Evaluator)       # True if it has .evaluate()\n</code></pre>"},{"location":"concepts/protocols/#api-reference","title":"API Reference","text":"<p>See the Protocols reference for full API docs.</p>"},{"location":"examples/","title":"Examples","text":"<p>Runnable, step-by-step examples for every major russo feature. Each example is also available as a standalone Python file in the <code>examples/</code> directory.</p>"},{"location":"examples/#quick-reference","title":"Quick Reference","text":"Example What it shows Basic Pipeline Minimal <code>russo.run()</code> end-to-end pipeline Custom Agent Wrap any async function with <code>@russo.agent</code> Custom Evaluator Build a custom evaluator via structural subtyping Custom Synthesizer Build a file-based or silence synthesizer for offline testing Gemini Adapters <code>GeminiAgent</code>, <code>GeminiLiveAgent</code>, and Vertex AI OpenAI Adapters <code>OpenAIAgent</code> and <code>OpenAIRealtimeAgent</code> HTTP Agent Test HTTP endpoints with <code>HttpAgent</code> WebSocket Agent Test WebSocket endpoints with custom hooks Caching <code>CachedSynthesizer</code> and <code>AudioCache</code> Concurrent Runs <code>russo.run_concurrent()</code> \u2014 multi-prompt and multi-run testing pytest Integration Markers, fixtures, and CLI options WebSocket Testing (E2E) End-to-end WebSocket server + Gemini, tested with real TTS Config-Driven Pipeline YAML-driven pipeline via CLI or programmatic loader"},{"location":"examples/basic-pipeline/","title":"Basic Pipeline","text":"<p>The simplest way to use russo: synthesize audio from text, send it to an agent, and evaluate the tool calls it makes.</p> <p>Source file</p> <p><code>examples/basic_pipeline.py</code></p>"},{"location":"examples/basic-pipeline/#step-1-define-an-agent","title":"Step 1: Define an agent","text":"<p>Every russo test needs an agent -- the thing you're testing. The <code>@russo.agent</code> decorator turns any async function with the right signature into a valid agent:</p> <pre><code>import russo\n\n@russo.agent\nasync def fake_agent(audio: russo.Audio) -&gt; russo.AgentResponse:\n    return russo.AgentResponse(\n        tool_calls=[\n            russo.ToolCall(\n                name=\"book_flight\",\n                arguments={\"from_city\": \"Berlin\", \"to_city\": \"Rome\"},\n            ),\n        ]\n    )\n</code></pre> <p>In a real test you'd swap this for a <code>GeminiLiveAgent</code>, <code>OpenAIAgent</code>, or any other adapter. We're using a fake here so the example runs without API keys.</p>"},{"location":"examples/basic-pipeline/#step-2-define-a-synthesizer","title":"Step 2: Define a synthesizer","text":"<p>A synthesizer converts a text prompt into audio. Again, we use a fake one here -- in production you'd use <code>GoogleSynthesizer</code>:</p> <pre><code>class FakeSynthesizer:\n    async def synthesize(self, text: str) -&gt; russo.Audio:\n        return russo.Audio(data=b\"\\x00\" * 4800, format=\"wav\", sample_rate=24000)\n</code></pre> <p>Any object with an <code>async def synthesize(self, text: str) -&gt; Audio</code> method satisfies the <code>Synthesizer</code> protocol.</p>"},{"location":"examples/basic-pipeline/#step-3-run-the-pipeline","title":"Step 3: Run the pipeline","text":"<p><code>russo.run()</code> chains everything together: synthesize -&gt; agent -&gt; evaluate.</p> <pre><code>from russo.evaluators import ExactEvaluator\n\nresult = await russo.run(\n    prompt=\"Book a flight from Berlin to Rome for tomorrow\",\n    synthesizer=FakeSynthesizer(),\n    agent=fake_agent,\n    evaluator=ExactEvaluator(),\n    expect=[\n        russo.tool_call(\"book_flight\", from_city=\"Berlin\", to_city=\"Rome\"),\n    ],\n)\n</code></pre> <p>The <code>expect</code> list defines what tool calls the agent should make. <code>russo.tool_call()</code> is a shorthand for creating <code>ToolCall</code> objects.</p>"},{"location":"examples/basic-pipeline/#step-4-check-the-results","title":"Step 4: Check the results","text":"<pre><code># Human-readable summary\nprint(result.summary())\n# PASSED (100% match rate)\n#   [+] book_flight({'from_city': 'Berlin', 'to_city': 'Rome'}) -&gt; book_flight(...)\n\n# Programmatic checks\nassert result.passed\nassert result.match_rate == 1.0\n\n# Or use the assertion helper (raises ToolCallAssertionError on failure)\nrusso.assert_tool_calls(result)\n</code></pre> <p><code>result</code> is an <code>EvalResult</code> with:</p> <ul> <li><code>passed</code> -- did all expected tool calls match?</li> <li><code>match_rate</code> -- fraction of expected calls matched (0.0 to 1.0)</li> <li><code>matches</code> -- per-call match details</li> <li><code>summary()</code> -- human-readable output</li> </ul>"},{"location":"examples/basic-pipeline/#full-example","title":"Full example","text":"<pre><code>import asyncio\nimport russo\nfrom russo.evaluators import ExactEvaluator\n\n\n@russo.agent\nasync def fake_agent(audio: russo.Audio) -&gt; russo.AgentResponse:\n    return russo.AgentResponse(\n        tool_calls=[\n            russo.ToolCall(\n                name=\"book_flight\",\n                arguments={\"from_city\": \"Berlin\", \"to_city\": \"Rome\"},\n            ),\n        ]\n    )\n\n\nclass FakeSynthesizer:\n    async def synthesize(self, text: str) -&gt; russo.Audio:\n        return russo.Audio(data=b\"\\x00\" * 4800, format=\"wav\", sample_rate=24000)\n\n\nasync def main():\n    result = await russo.run(\n        prompt=\"Book a flight from Berlin to Rome for tomorrow\",\n        synthesizer=FakeSynthesizer(),\n        agent=fake_agent,\n        evaluator=ExactEvaluator(),\n        expect=[\n            russo.tool_call(\"book_flight\", from_city=\"Berlin\", to_city=\"Rome\"),\n        ],\n    )\n\n    print(result.summary())\n    assert result.passed\n    assert result.match_rate == 1.0\n    russo.assert_tool_calls(result)\n    print(\"\\nAll checks passed!\")\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <p>Run it:</p> <pre><code>python examples/basic_pipeline.py\n</code></pre> <p>Expected output:</p> <pre><code>PASSED (100% match rate)\n  [+] book_flight({'from_city': 'Berlin', 'to_city': 'Rome'}) -&gt; book_flight({'from_city': 'Berlin', 'to_city': 'Rome'})\n\nAll checks passed!\n</code></pre>"},{"location":"examples/caching/","title":"Caching","text":"<p>TTS API calls are slow and expensive. <code>CachedSynthesizer</code> wraps any synthesizer with a file-system cache so repeated test runs skip the TTS call entirely.</p> <p>Source file</p> <p><code>examples/caching.py</code></p>"},{"location":"examples/caching/#how-it-works","title":"How it works","text":"<p>The cache key is a SHA-256 hash of the prompt text (plus optional extras). Identical prompts always return cached audio without calling the TTS API.</p> <p>Each cached entry is a pair of files on disk:</p> <pre><code>.russo_cache/\n  a1b2c3d4e5f6.audio   # raw audio bytes\n  a1b2c3d4e5f6.meta    # JSON metadata (format, sample_rate, prompt)\n</code></pre>"},{"location":"examples/caching/#example-1-basic-caching","title":"Example 1: Basic caching","text":"<p>Wrap any synthesizer with <code>CachedSynthesizer</code>:</p> <pre><code>from russo import CachedSynthesizer\nfrom russo.synthesizers import GoogleSynthesizer\n\ninner = GoogleSynthesizer(api_key=\"...\")\nsynth = CachedSynthesizer(inner)\n</code></pre> <p>First call with a prompt: cache miss -- calls the TTS API and stores the result. Second call with the same prompt: cache hit -- returns audio from disk instantly.</p> <pre><code>import russo\nfrom russo.evaluators import ExactEvaluator\n\n# First run: TTS API is called\nawait russo.run(\n    prompt=\"Book a flight from NYC to LA\",\n    synthesizer=synth,\n    agent=my_agent,\n    evaluator=ExactEvaluator(),\n    expect=[russo.tool_call(\"book_flight\", from_city=\"NYC\", to_city=\"LA\")],\n)\nprint(f\"Cache size: {synth.cache.size()}\")  # 1\n\n# Second run with same prompt: TTS is skipped\nawait russo.run(\n    prompt=\"Book a flight from NYC to LA\",\n    synthesizer=synth,\n    ...\n)\n# No TTS call was made!\n</code></pre>"},{"location":"examples/caching/#example-2-custom-cache-directory","title":"Example 2: Custom cache directory","text":"<p>By default, cached audio goes to <code>.russo_cache/</code> in the current directory. You can customize this:</p> <pre><code>from pathlib import Path\nfrom russo import AudioCache, CachedSynthesizer\n\ncustom_cache = AudioCache(Path(\"/tmp/russo_audio_cache\"))\nsynth = CachedSynthesizer(inner, cache=custom_cache)\n</code></pre>"},{"location":"examples/caching/#example-3-cache-key-extras","title":"Example 3: Cache key extras","text":"<p>Include synthesizer config in the cache key so changing the voice or model automatically invalidates the cache:</p> <pre><code>synth = CachedSynthesizer(\n    inner,\n    cache_key_extra={\n        \"voice\": \"Kore\",\n        \"model\": \"gemini-2.5-flash-preview-tts\",\n    },\n)\n</code></pre> <p>Same prompt + same config = cache hit. Same prompt + different voice = cache miss.</p>"},{"location":"examples/caching/#example-4-disable-caching-at-runtime","title":"Example 4: Disable caching at runtime","text":"<p>Temporarily bypass the cache without changing your setup:</p> <pre><code>synth = CachedSynthesizer(inner, enabled=False)\n# All calls go to the inner synthesizer directly\n</code></pre>"},{"location":"examples/caching/#cache-management","title":"Cache management","text":"<pre><code># Check how many entries are cached\nsynth.cache.size()\n\n# Clear all cached entries\nsynth.cache.clear()\n</code></pre>"},{"location":"examples/caching/#pytest-integration","title":"pytest integration","text":"<p>The russo pytest plugin supports caching out of the box via CLI options:</p> <pre><code>pytest --russo-cache                # enable audio cache (default)\npytest --russo-no-cache             # disable caching\npytest --russo-clear-cache          # clear cache before running\npytest --russo-cache-dir .my_cache  # custom cache directory\n</code></pre> <p>Run the demo:</p> <pre><code>python examples/caching.py\n</code></pre> <p>Expected output:</p> <pre><code>=== Example 1: Basic caching ===\n  [TTS] Synthesizing: 'Book a flight from NYC to LA'  (call #1)\n  Cache size after first run: 1\n  Total TTS calls: 1 (should be 1 \u2014 second was cached)\n\n=== Example 2: Custom cache directory ===\n  Cache dir: /tmp/russo_audio_cache\n\n=== Example 3: Cache key extras ===\n  Cache key for same prompt with different config will differ\n\n=== Example 4: Disable caching ===\n  [TTS] Synthesizing: 'test'  (call #2)\n  TTS calls with caching disabled: 2\n\nDone!\n</code></pre>"},{"location":"examples/concurrent-runs/","title":"Concurrent Runs","text":"<p>Run the pipeline multiple times asynchronously \u2014 for reliability testing, prompt variant testing, or a full matrix of both. All runs execute concurrently via <code>asyncio.gather()</code>.</p> <p>Source file</p> <p><code>examples/concurrent_runs.py</code></p>"},{"location":"examples/concurrent-runs/#three-scenarios","title":"Three scenarios","text":"Scenario What it does Use case Single prompt, N runs Same prompt repeated N times Reliability / flakiness testing Multiple prompts, 1 run Each prompt runs once Prompt variant testing M prompts \u00d7 N runs Full matrix (M \u00d7 N tasks) Comprehensive coverage"},{"location":"examples/concurrent-runs/#scenario-1-single-prompt-multiple-runs","title":"Scenario 1: Single prompt, multiple runs","text":"<p>Test how reliably your agent handles the same prompt by running it N times concurrently:</p> <pre><code>import russo\nfrom russo.evaluators import ExactEvaluator\n\nresult = await russo.run_concurrent(\n    prompts=\"Book a flight from NYC to LA\",\n    synthesizer=my_synthesizer,\n    agent=my_agent,\n    evaluator=ExactEvaluator(ignore_extra_args=True),\n    expect=[russo.tool_call(\"book_flight\")],\n    runs=5,\n)\n\nprint(result.summary())\nassert result.pass_rate &gt;= 0.8  # at least 80% should pass\n</code></pre> <p><code>result</code> is a <code>BatchResult</code> with:</p> <ul> <li><code>total</code> \u2014 number of runs (5)</li> <li><code>passed</code> \u2014 <code>True</code> only if every run passed</li> <li><code>pass_rate</code> \u2014 fraction of runs that passed (0.0 to 1.0)</li> <li><code>match_rate</code> \u2014 average match rate across all runs</li> <li><code>runs</code> \u2014 list of <code>SingleRunResult</code> for per-run inspection</li> </ul>"},{"location":"examples/concurrent-runs/#scenario-2-multiple-prompts-single-run-each","title":"Scenario 2: Multiple prompts, single run each","text":"<p>Test different phrasings of the same intent:</p> <pre><code>result = await russo.run_concurrent(\n    prompts=[\n        \"Book a flight from NYC to LA\",\n        \"I need to fly from New York to Los Angeles\",\n        \"Please book me a flight, departing NYC, arriving LA\",\n    ],\n    synthesizer=my_synthesizer,\n    agent=my_agent,\n    evaluator=ExactEvaluator(ignore_extra_args=True),\n    expect=[russo.tool_call(\"book_flight\")],\n)\n\nassert result.total == 3\nassert result.passed\n</code></pre>"},{"location":"examples/concurrent-runs/#scenario-3-multiple-prompts-multiple-runs","title":"Scenario 3: Multiple prompts \u00d7 multiple runs","text":"<p>Full matrix \u2014 every prompt is run N times:</p> <pre><code>result = await russo.run_concurrent(\n    prompts=[\n        \"Book a flight from Berlin to Rome\",\n        \"Fly me from Tokyo to Sydney\",\n    ],\n    synthesizer=my_synthesizer,\n    agent=my_agent,\n    evaluator=ExactEvaluator(ignore_extra_args=True),\n    expect=[russo.tool_call(\"book_flight\")],\n    runs=3,\n    max_concurrency=4,  # at most 4 simultaneous pipeline runs\n)\n\nassert result.total == 6  # 2 prompts \u00d7 3 runs\n</code></pre>"},{"location":"examples/concurrent-runs/#controlling-concurrency","title":"Controlling concurrency","text":"<p>By default, all runs execute simultaneously. Use <code>max_concurrency</code> to limit the number of parallel tasks \u2014 useful when hitting rate-limited APIs:</p> <pre><code>result = await russo.run_concurrent(\n    prompts=\"test prompt\",\n    ...,\n    runs=20,\n    max_concurrency=5,  # at most 5 calls at a time\n)\n</code></pre>"},{"location":"examples/concurrent-runs/#inspecting-individual-results","title":"Inspecting individual results","text":"<p>Each run is accessible as a <code>SingleRunResult</code>:</p> <pre><code>for run in result.runs:\n    icon = \"+\" if run.eval_result.passed else \"-\"\n    print(f\"[{icon}] prompt={run.prompt!r}  run={run.run_index}  \"\n          f\"match_rate={run.eval_result.match_rate:.0%}\")\n</code></pre> <p>The <code>summary()</code> method groups results by prompt automatically:</p> <pre><code>PASSED (100% pass rate, 6 runs)\n  Passed: 6/6\n  Prompt: 'Book a flight from Berlin to Rome'\n    3/3 passed\n    [+] run 0: 100% match\n    [+] run 1: 100% match\n    [+] run 2: 100% match\n  Prompt: 'Fly me from Tokyo to Sydney'\n    3/3 passed\n    [+] run 0: 100% match\n    [+] run 1: 100% match\n    [+] run 2: 100% match\n</code></pre>"},{"location":"examples/concurrent-runs/#pytest-integration","title":"pytest integration","text":"<p>The same functionality is available via the <code>@pytest.mark.russo</code> marker:</p>"},{"location":"examples/concurrent-runs/#single-prompt-multiple-runs","title":"Single prompt, multiple runs","text":"<pre><code>@pytest.mark.russo(\n    prompt=\"Book a flight from NYC to LA\",\n    expect=[russo.tool_call(\"book_flight\", from_city=\"NYC\", to_city=\"LA\")],\n    runs=3,\n)\nasync def test_reliability(russo_result):\n    assert isinstance(russo_result, russo.BatchResult)\n    assert russo_result.pass_rate &gt;= 0.8\n</code></pre>"},{"location":"examples/concurrent-runs/#multiple-prompts","title":"Multiple prompts","text":"<pre><code>@pytest.mark.russo(\n    prompts=[\n        \"Book a flight from NYC to LA\",\n        \"I need to fly from NYC to LA\",\n    ],\n    expect=[russo.tool_call(\"book_flight\", from_city=\"NYC\", to_city=\"LA\")],\n)\nasync def test_prompt_variants(russo_result):\n    assert russo_result.total == 2\n    assert russo_result.passed\n</code></pre>"},{"location":"examples/concurrent-runs/#full-matrix","title":"Full matrix","text":"<pre><code>@pytest.mark.russo(\n    prompts=[\"Book from NYC to LA\", \"Fly NYC to LA\"],\n    expect=[russo.tool_call(\"book_flight\", from_city=\"NYC\", to_city=\"LA\")],\n    runs=3,\n    max_concurrency=4,\n)\nasync def test_full_matrix(russo_result):\n    assert russo_result.total == 6  # 2 prompts \u00d7 3 runs\n</code></pre>"},{"location":"examples/concurrent-runs/#cli-run-count-override","title":"CLI run count override","text":"<p>Set a default run count for all russo tests from the command line:</p> <pre><code>pytest --russo-runs 5\npytest --russo-runs 5 --russo-max-concurrency 3\n</code></pre> <p>Marker-level <code>runs=</code> takes precedence over the CLI option.</p> <p>Source files</p> <p><code>examples/pytest_integration/test_concurrent.py</code></p>"},{"location":"examples/concurrent-runs/#cli-config-driven","title":"CLI (config-driven)","text":"<p>Add <code>runs</code> and <code>max_concurrency</code> to your config file:</p> <pre><code>pipeline:\n  # ... component references ...\n\ntests:\n  - id: \"book_flight_test\"\n    # ... test spec ...\n\nruns: 5               # run each test 5 times\nmax_concurrency: 3    # at most 3 simultaneous runs\n</code></pre> <p>Or override from the command line:</p> <pre><code>russo --config config.yaml --runs 10 --max-concurrency 5\n</code></pre> <p>The <code>--runs</code> flag overrides the config file value.</p>"},{"location":"examples/concurrent-runs/#full-example","title":"Full example","text":"<pre><code>import asyncio\nimport russo\nfrom russo.evaluators import ExactEvaluator\n\n\nclass FakeSynthesizer:\n    async def synthesize(self, text: str) -&gt; russo.Audio:\n        return russo.Audio(data=b\"\\x00\" * 4800, format=\"wav\", sample_rate=24000)\n\n\n@russo.agent\nasync def fake_agent(audio: russo.Audio) -&gt; russo.AgentResponse:\n    return russo.AgentResponse(\n        tool_calls=[russo.ToolCall(name=\"book_flight\", arguments={\"from_city\": \"NYC\", \"to_city\": \"LA\"})]\n    )\n\n\nasync def main():\n    result = await russo.run_concurrent(\n        prompts=[\"Book a flight from NYC to LA\", \"Fly me from NYC to LA\"],\n        synthesizer=FakeSynthesizer(),\n        agent=fake_agent,\n        evaluator=ExactEvaluator(ignore_extra_args=True),\n        expect=[russo.tool_call(\"book_flight\")],\n        runs=3,\n        max_concurrency=4,\n    )\n\n    print(result.summary())\n    assert result.passed\n    print(f\"\\nAll {result.total} runs passed!\")\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <p>Run it:</p> <pre><code>python examples/concurrent_runs.py\n</code></pre>"},{"location":"examples/config-driven/","title":"Config-Driven Pipeline","text":"<p>Define your entire test pipeline and test suite in a YAML file. Run it via the <code>russo</code> CLI or load it programmatically from Python.</p> <p>Source files</p> <p><code>examples/config_driven/</code></p>"},{"location":"examples/config-driven/#how-it-works","title":"How it works","text":"<p>A config file has two sections:</p> <ol> <li><code>pipeline</code> -- references to Python classes for each pipeline component</li> <li><code>tests</code> -- list of test case specifications</li> </ol> <p>Each component is referenced by an import path (<code>class_path</code>) and constructor parameters (<code>params</code>). The russo CLI resolves imports, instantiates components, and runs the tests.</p>"},{"location":"examples/config-driven/#the-config-file","title":"The config file","text":"<pre><code># config.yaml\n\npipeline:\n  sample_generator:\n    name: tts_generator\n    class_path: \"russo.synthesizers.google.GoogleSynthesizer\"\n    params:\n      voice: \"Kore\"\n      model: \"gemini-2.5-flash-preview-tts\"\n\n  stream_source:\n    name: pcm_streamer\n    class_path: \"russo.synthesizers.google.GoogleSynthesizer\"\n    params: {}\n\n  model_adapter:\n    name: gemini_live\n    class_path: \"russo.adapters.gemini.GeminiLiveAgent\"\n    params:\n      model: \"gemini-live-2.5-flash-native-audio\"\n\n  tool_recorder:\n    name: recorder\n    class_path: \"russo.evaluators.exact.ExactEvaluator\"\n    params: {}\n\n  matcher:\n    name: exact_matcher\n    class_path: \"russo.evaluators.exact.ExactEvaluator\"\n    params: {}\n\n  # audio_evaluator is optional \u2014 omit to skip audio response evaluation\n\ntests:\n  - id: \"book_flight_berlin_rome\"\n    description: \"User asks to book a flight from Berlin to Rome\"\n    audio_spec:\n      id: \"tts_berlin_rome\"\n      generator: \"tts_generator\"\n      parameters:\n        text: \"Book a flight from Berlin to Rome for tomorrow\"\n    instructions: &gt;\n      You are a travel assistant. When the user asks to book a flight,\n      call the book_flight function with from_city and to_city.\n    tools:\n      - name: \"book_flight\"\n        description: \"Book a flight between two cities\"\n        json_schema:\n          type: object\n          properties:\n            from_city:\n              type: string\n              description: \"Departure city\"\n            to_city:\n              type: string\n              description: \"Arrival city\"\n          required:\n            - from_city\n            - to_city\n    tool_expectation:\n      name: \"book_flight\"\n      arguments:\n        from_city: \"Berlin\"\n        to_city: \"Rome\"\n\n  - id: \"get_weather_tokyo\"\n    description: \"User asks about weather in Tokyo\"\n    audio_spec:\n      id: \"tts_weather_tokyo\"\n      generator: \"tts_generator\"\n      parameters:\n        text: \"What's the weather like in Tokyo today?\"\n    instructions: &gt;\n      You are a helpful assistant with access to weather tools.\n      When the user asks about weather, call get_weather with the city.\n    tools:\n      - name: \"get_weather\"\n        description: \"Get current weather for a city\"\n        json_schema:\n          type: object\n          properties:\n            city:\n              type: string\n              description: \"City name\"\n          required:\n            - city\n    tool_expectation:\n      name: \"get_weather\"\n      arguments:\n        city: \"Tokyo\"\n\n# Run each test 3 times concurrently (optional, default: 1)\nruns: 3\n# Limit to 2 simultaneous pipeline runs (optional, default: unlimited)\nmax_concurrency: 2\n</code></pre>"},{"location":"examples/config-driven/#running-via-cli","title":"Running via CLI","text":"<p>The simplest way -- just point the <code>russo</code> command at your config:</p> <pre><code>russo --config config.yaml\n\n# Save the report as JSON\nrusso --config config.yaml --report report.json\n\n# Override runs from the command line (takes precedence over config)\nrusso --config config.yaml --runs 5 --max-concurrency 3\n</code></pre>"},{"location":"examples/config-driven/#running-programmatically","title":"Running programmatically","text":"<p>For more control over component construction and result handling:</p> <pre><code>import asyncio\nimport json\nfrom pathlib import Path\n\nfrom russo.config import build_component, build_registry, load_config\nfrom russo.pipeline import DefaultTestRunner, PipelineDependencies\n\n\nasync def main():\n    config_path = Path(\"config.yaml\")\n\n    # 1. Load configuration\n    config = load_config(config_path)\n    print(f\"Loaded {len(config.suite.tests)} test case(s)\")\n\n    # 2. Build the component registry\n    registry = build_registry(config)\n\n    # 3. Instantiate pipeline components\n    deps = PipelineDependencies(\n        sample_generator=build_component(registry, config.pipeline.sample_generator),\n        stream_source=build_component(registry, config.pipeline.stream_source),\n        model_adapter=build_component(registry, config.pipeline.model_adapter),\n        tool_recorder=build_component(registry, config.pipeline.tool_recorder),\n        matcher=build_component(registry, config.pipeline.matcher),\n        audio_evaluator=(\n            build_component(registry, config.pipeline.audio_evaluator)\n            if config.pipeline.audio_evaluator\n            else None\n        ),\n    )\n\n    # 4. Run all tests\n    runner = DefaultTestRunner(deps)\n    report = await runner.run_many(config.suite.tests)\n\n    # 5. Print results\n    print(f\"Run ID: {report.run_id}\")\n    print(f\"Summary: {report.summary}\")\n    for result in report.results:\n        status = \"PASS\" if result.tool_call_result.passed else \"FAIL\"\n        print(f\"  [{status}] {result.test_id}\")\n\n    # 6. Save report\n    Path(\"report.json\").write_text(json.dumps(report.to_dict(), indent=2))\n\n\nasyncio.run(main())\n</code></pre>"},{"location":"examples/config-driven/#what-each-step-does","title":"What each step does","text":"<ol> <li><code>load_config()</code> -- reads YAML or JSON, parses into <code>Config</code> with pipeline and test suite sections</li> <li><code>build_registry()</code> -- resolves <code>class_path</code> imports and registers them as named factories</li> <li><code>build_component()</code> -- instantiates each component from the registry, passing <code>params</code> as <code>**kwargs</code></li> <li><code>DefaultTestRunner</code> -- orchestrates the pipeline: generate audio -&gt; stream to model -&gt; record tool calls -&gt; match expectations</li> <li><code>run_many()</code> -- runs all test cases and returns a <code>TestRunReport</code> with per-case results</li> </ol> <pre><code>python examples/config_driven/run.py\n</code></pre>"},{"location":"examples/custom-agent/","title":"Custom Agent","text":"<p>The <code>@russo.agent</code> decorator turns any async function into a valid agent. This is useful when your agent is a REST API call, a gRPC service, or anything that doesn't fit the built-in adapters.</p> <p>Source file</p> <p><code>examples/custom_agent.py</code></p>"},{"location":"examples/custom-agent/#the-russoagent-decorator","title":"The <code>@russo.agent</code> decorator","text":"<p>The decorator wraps any async function with the signature <code>(Audio) -&gt; AgentResponse</code>:</p> <pre><code>import russo\n\n@russo.agent\nasync def my_travel_agent(audio: russo.Audio) -&gt; russo.AgentResponse:\n    # In a real scenario you'd call your backend:\n    #   response = await httpx.post(\"https://my-api/voice\", content=audio.data)\n    #   parsed = response.json()\n    #   tool_calls = [\n    #       russo.ToolCall(name=tc[\"name\"], arguments=tc[\"args\"])\n    #       for tc in parsed[\"tool_calls\"]\n    #   ]\n\n    return russo.AgentResponse(\n        tool_calls=[\n            russo.ToolCall(\n                name=\"search_hotels\",\n                arguments={\"city\": \"Paris\", \"checkin\": \"2026-03-01\"},\n            ),\n        ]\n    )\n</code></pre> <p>The decorated function satisfies the <code>Agent</code> protocol, so you can pass it directly to <code>russo.run()</code>.</p>"},{"location":"examples/custom-agent/#how-it-works","title":"How it works","text":"<p>Under the hood, <code>@russo.agent</code> wraps your function in a <code>_CallableAgent</code> class that has a <code>run(audio)</code> method -- exactly what the <code>Agent</code> protocol requires:</p> <pre><code># These two are equivalent:\nagent = my_travel_agent  # decorated function\n\n# vs. implementing the protocol manually:\nclass MyAgent:\n    async def run(self, audio: russo.Audio) -&gt; russo.AgentResponse:\n        return await my_travel_agent(audio)\n</code></pre>"},{"location":"examples/custom-agent/#running-the-test","title":"Running the test","text":"<pre><code>import asyncio\nfrom russo.evaluators import ExactEvaluator\n\nclass FakeSynthesizer:\n    async def synthesize(self, text: str) -&gt; russo.Audio:\n        return russo.Audio(data=b\"\\x00\" * 4800, format=\"wav\", sample_rate=24000)\n\nasync def main():\n    result = await russo.run(\n        prompt=\"Find hotels in Paris for March first\",\n        synthesizer=FakeSynthesizer(),\n        agent=my_travel_agent,\n        evaluator=ExactEvaluator(),\n        expect=[\n            russo.tool_call(\"search_hotels\", city=\"Paris\", checkin=\"2026-03-01\"),\n        ],\n    )\n\n    print(result.summary())\n    russo.assert_tool_calls(result)\n\nasyncio.run(main())\n</code></pre> <p>Run it:</p> <pre><code>python examples/custom_agent.py\n</code></pre> <p>Expected output:</p> <pre><code>PASSED (100% match rate)\n  [+] search_hotels({'city': 'Paris', 'checkin': '2026-03-01'}) -&gt; search_hotels(...)\n\nCustom agent test passed!\n</code></pre>"},{"location":"examples/custom-evaluator/","title":"Custom Evaluator","text":"<p>russo uses structural subtyping (protocols), so you don't need to inherit from anything. Just implement the right method signature and you have a valid evaluator.</p> <p>Source file</p> <p><code>examples/custom_evaluator.py</code></p>"},{"location":"examples/custom-evaluator/#the-evaluator-protocol","title":"The Evaluator protocol","text":"<p>Any class with this method is a valid evaluator:</p> <pre><code>def evaluate(self, expected: list[ToolCall], actual: list[ToolCall]) -&gt; EvalResult\n</code></pre> <p>No base class, no registration -- if the method signature matches, russo accepts it.</p>"},{"location":"examples/custom-evaluator/#building-a-fuzzy-evaluator","title":"Building a fuzzy evaluator","text":"<p>The built-in <code>ExactEvaluator</code> requires exact name and argument matches. Let's build a fuzzy evaluator that:</p> <ul> <li>Matches tool names case-insensitively</li> <li>Only checks that expected arguments are a subset of actual arguments (extra args are OK)</li> </ul>"},{"location":"examples/custom-evaluator/#step-1-define-the-evaluator-class","title":"Step 1: Define the evaluator class","text":"<pre><code>import russo\nfrom russo._types import EvalResult, ToolCall, ToolCallMatch\n\n\nclass FuzzyEvaluator:\n    \"\"\"Case-insensitive name matching + subset argument checking.\"\"\"\n\n    def evaluate(self, expected: list[ToolCall], actual: list[ToolCall]) -&gt; EvalResult:\n        matches: list[ToolCallMatch] = []\n        remaining = list(actual)\n\n        for exp in expected:\n            match = self._find_match(exp, remaining)\n            matches.append(match)\n            if match.matched and match.actual in remaining:\n                remaining.remove(match.actual)\n\n        passed = all(m.matched for m in matches)\n        return EvalResult(passed=passed, expected=expected, actual=actual, matches=matches)\n</code></pre>"},{"location":"examples/custom-evaluator/#step-2-implement-the-matching-logic","title":"Step 2: Implement the matching logic","text":"<pre><code>    def _find_match(self, expected: ToolCall, candidates: list[ToolCall]) -&gt; ToolCallMatch:\n        for candidate in candidates:\n            if self._is_match(expected, candidate):\n                return ToolCallMatch(expected=expected, actual=candidate, matched=True)\n\n        return ToolCallMatch(\n            expected=expected,\n            matched=False,\n            details=f\"No fuzzy match found for {expected.name}\",\n        )\n\n    def _is_match(self, expected: ToolCall, actual: ToolCall) -&gt; bool:\n        # Case-insensitive name matching\n        if expected.name.lower() != actual.name.lower():\n            return False\n        # Expected args must be a subset of actual args\n        return all(actual.arguments.get(k) == v for k, v in expected.arguments.items())\n</code></pre>"},{"location":"examples/custom-evaluator/#step-3-test-it","title":"Step 3: Test it","text":"<p>The fuzzy evaluator handles cases where the agent returns different casing or extra arguments:</p> <pre><code>@russo.agent\nasync def agent_with_extra_args(audio: russo.Audio) -&gt; russo.AgentResponse:\n    return russo.AgentResponse(\n        tool_calls=[\n            russo.ToolCall(\n                name=\"Book_Flight\",  # different casing!\n                arguments={\n                    \"from_city\": \"NYC\",\n                    \"to_city\": \"LA\",\n                    \"airline\": \"Delta\",  # extra argument\n                    \"class\": \"economy\",  # extra argument\n                },\n            ),\n        ]\n    )\n</code></pre> <p>Now run the pipeline with the fuzzy evaluator:</p> <pre><code>result = await russo.run(\n    prompt=\"Book a flight from NYC to LA\",\n    synthesizer=FakeSynthesizer(),\n    agent=agent_with_extra_args,\n    evaluator=FuzzyEvaluator(),  # our custom evaluator\n    expect=[\n        russo.tool_call(\"book_flight\", from_city=\"NYC\", to_city=\"LA\"),\n    ],\n)\n\nrusso.assert_tool_calls(result)\n# Passes! \"Book_Flight\" matches \"book_flight\", extra args are ignored.\n</code></pre> <p>Run it:</p> <pre><code>python examples/custom_evaluator.py\n</code></pre> <p>Expected output:</p> <pre><code>PASSED (100% match rate)\n  [+] book_flight({'from_city': 'NYC', 'to_city': 'LA'}) -&gt; Book_Flight({'from_city': 'NYC', 'to_city': 'LA', 'airline': 'Delta', 'class': 'economy'})\n\nFuzzy evaluator matched despite case difference and extra args!\n</code></pre>"},{"location":"examples/custom-evaluator/#when-to-use-a-custom-evaluator","title":"When to use a custom evaluator","text":"<ul> <li>Fuzzy matching -- case-insensitive names, partial argument matches</li> <li>Semantic matching -- use an LLM to judge if arguments are \"close enough\"</li> <li>Scoring -- return a confidence score instead of pass/fail</li> <li>Subset matching -- only require some of the expected tool calls to match</li> </ul>"},{"location":"examples/custom-synthesizer/","title":"Custom Synthesizer","text":"<p>Build your own synthesizer for offline testing, pre-recorded audio, or alternative TTS providers. Like all russo extension points, you just implement the right method -- no inheritance required.</p> <p>Source file</p> <p><code>examples/custom_synthesizer.py</code></p>"},{"location":"examples/custom-synthesizer/#the-synthesizer-protocol","title":"The Synthesizer protocol","text":"<p>Any class with this method is a valid synthesizer:</p> <pre><code>async def synthesize(self, text: str) -&gt; Audio\n</code></pre>"},{"location":"examples/custom-synthesizer/#example-1-file-based-synthesizer","title":"Example 1: File-based synthesizer","text":"<p>Reads pre-recorded audio files from a directory, keyed by a hash of the prompt text. Useful when you have a fixed set of test prompts with recorded audio.</p> <pre><code>import hashlib\nfrom pathlib import Path\nimport russo\n\n\nclass FileSynthesizer:\n    def __init__(\n        self,\n        audio_dir: str | Path,\n        format: str = \"wav\",\n        sample_rate: int = 24000,\n    ) -&gt; None:\n        self.audio_dir = Path(audio_dir)\n        self.format = format\n        self.sample_rate = sample_rate\n\n    async def synthesize(self, text: str) -&gt; russo.Audio:\n        key = hashlib.sha256(text.encode()).hexdigest()[:16]\n        audio_path = self.audio_dir / f\"{key}.{self.format}\"\n        if not audio_path.exists():\n            raise FileNotFoundError(\n                f\"No pre-recorded audio for prompt (key={key}): {text!r}\"\n            )\n        return russo.Audio(\n            data=audio_path.read_bytes(),\n            format=self.format,\n            sample_rate=self.sample_rate,\n        )\n</code></pre> <p>Usage:</p> <pre><code>synth = FileSynthesizer(audio_dir=\"test_audio/\")\n</code></pre> <p>Pre-record your audio files named by their SHA-256 hash prefix (e.g. <code>a1b2c3d4e5f6g7h8.wav</code>).</p>"},{"location":"examples/custom-synthesizer/#example-2-silence-synthesizer","title":"Example 2: Silence synthesizer","text":"<p>Generates silent audio of a fixed duration. Great for integration tests where the audio content doesn't matter -- you just want to verify the pipeline wiring works.</p> <pre><code>class SilenceSynthesizer:\n    def __init__(\n        self, duration_seconds: float = 1.0, sample_rate: int = 24000\n    ) -&gt; None:\n        self.duration_seconds = duration_seconds\n        self.sample_rate = sample_rate\n\n    async def synthesize(self, text: str) -&gt; russo.Audio:\n        num_samples = int(self.sample_rate * self.duration_seconds)\n        silent_pcm = b\"\\x00\\x00\" * num_samples  # 16-bit silence\n        return russo.Audio(\n            data=silent_pcm, format=\"wav\", sample_rate=self.sample_rate\n        )\n</code></pre> <p>Usage:</p> <pre><code>from russo.evaluators import ExactEvaluator\n\nresult = await russo.run(\n    prompt=\"What's the weather in Tokyo?\",\n    synthesizer=SilenceSynthesizer(duration_seconds=0.5),\n    agent=my_agent,\n    evaluator=ExactEvaluator(),\n    expect=[russo.tool_call(\"get_weather\", city=\"Tokyo\")],\n)\n</code></pre> <p>Run the demo:</p> <pre><code>python examples/custom_synthesizer.py\n</code></pre> <p>Expected output:</p> <pre><code>PASSED (100% match rate)\n  [+] get_weather({'city': 'Tokyo'}) -&gt; get_weather({'city': 'Tokyo'})\n\nCustom synthesizer test passed!\n</code></pre>"},{"location":"examples/custom-synthesizer/#when-to-use-a-custom-synthesizer","title":"When to use a custom synthesizer","text":"<ul> <li>Offline testing -- no TTS API calls, no cost, no latency</li> <li>Pre-recorded audio -- use real human recordings for higher fidelity</li> <li>Alternative TTS -- plug in ElevenLabs, Azure Speech, Amazon Polly, etc.</li> <li>CI pipelines -- use <code>SilenceSynthesizer</code> to test pipeline wiring without credentials</li> </ul>"},{"location":"examples/gemini-adapter/","title":"Gemini Adapters","text":"<p>Test Gemini models for tool-call accuracy using the Google GenAI SDK. russo provides two adapters:</p> <ul> <li><code>GeminiAgent</code> -- standard <code>generate_content</code> (request/response)</li> <li><code>GeminiLiveAgent</code> -- Live API over WebSocket (streaming/real-time)</li> </ul> <p>Source file</p> <p><code>examples/gemini_adapter.py</code></p>"},{"location":"examples/gemini-adapter/#prerequisites","title":"Prerequisites","text":"<pre><code>pip install russo\nexport GOOGLE_API_KEY=\"your-api-key\"\n</code></pre>"},{"location":"examples/gemini-adapter/#tool-declarations","title":"Tool declarations","text":"<p>Gemini uses the <code>function_declarations</code> format for tool definitions:</p> <pre><code>BOOK_FLIGHT_TOOL = {\n    \"function_declarations\": [\n        {\n            \"name\": \"book_flight\",\n            \"description\": \"Book a flight between two cities.\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"from_city\": {\"type\": \"string\", \"description\": \"Departure city\"},\n                    \"to_city\": {\"type\": \"string\", \"description\": \"Arrival city\"},\n                },\n                \"required\": [\"from_city\", \"to_city\"],\n            },\n        }\n    ]\n}\n</code></pre>"},{"location":"examples/gemini-adapter/#example-1-geminiagent-requestresponse","title":"Example 1: GeminiAgent (request/response)","text":"<p>Standard request/response via <code>generate_content</code>. Best for non-streaming use cases.</p> <pre><code>import os\nimport russo\nfrom google import genai\nfrom russo.adapters import GeminiAgent\nfrom russo.evaluators import ExactEvaluator\nfrom russo.synthesizers import GoogleSynthesizer\n\nclient = genai.Client(api_key=os.environ[\"GOOGLE_API_KEY\"])\n\nagent = GeminiAgent(\n    client=client,\n    model=\"gemini-2.0-flash\",\n    tools=[BOOK_FLIGHT_TOOL],\n    system_instruction=(\n        \"You are a travel assistant. When the user asks to book \"\n        \"a flight, call the book_flight function.\"\n    ),\n)\n\nsynthesizer = GoogleSynthesizer(api_key=os.environ[\"GOOGLE_API_KEY\"])\n\nresult = await russo.run(\n    prompt=\"Book a flight from Berlin to Rome for tomorrow\",\n    synthesizer=synthesizer,\n    agent=agent,\n    evaluator=ExactEvaluator(),\n    expect=[russo.tool_call(\"book_flight\", from_city=\"Berlin\", to_city=\"Rome\")],\n)\n</code></pre>"},{"location":"examples/gemini-adapter/#example-2-geminiliveagent-streaming","title":"Example 2: GeminiLiveAgent (streaming)","text":"<p>Real-time streaming via the Live API. Opens a WebSocket connection, sends audio, and collects function calls as they arrive.</p> <pre><code>from russo.adapters import GeminiLiveAgent\n\nagent = GeminiLiveAgent(\n    client=client,\n    model=\"gemini-live-2.5-flash-native-audio\",\n    tools=[BOOK_FLIGHT_TOOL],\n    system_instruction=(\n        \"You are a travel assistant. When the user asks to book \"\n        \"a flight, call the book_flight function.\"\n    ),\n)\n\nresult = await russo.run(\n    prompt=\"Book a flight from NYC to LA\",\n    synthesizer=synthesizer,\n    agent=agent,\n    evaluator=ExactEvaluator(),\n    expect=[russo.tool_call(\"book_flight\", from_city=\"NYC\", to_city=\"LA\")],\n)\n</code></pre> <p>Model</p> <p>Use <code>gemini-live-2.5-flash-native-audio</code> for both Google AI and Vertex AI.</p>"},{"location":"examples/gemini-adapter/#example-3-vertex-ai-authentication","title":"Example 3: Vertex AI authentication","text":"<p>Same adapters, but authenticated via Vertex AI using Application Default Credentials:</p> <pre><code># Vertex AI client \u2014 uses ADC\nclient = genai.Client(\n    vertexai=True,\n    project=os.environ.get(\"GOOGLE_CLOUD_PROJECT\", \"my-project\"),\n    location=os.environ.get(\"GOOGLE_CLOUD_LOCATION\", \"us-central1\"),\n)\n\nagent = GeminiLiveAgent(\n    client=client,\n    model=\"gemini-live-2.5-flash-native-audio\",\n    tools=[BOOK_FLIGHT_TOOL],\n)\n\nsynthesizer = GoogleSynthesizer(\n    vertexai=True,\n    project=os.environ.get(\"GOOGLE_CLOUD_PROJECT\", \"my-project\"),\n    location=os.environ.get(\"GOOGLE_CLOUD_LOCATION\", \"us-central1\"),\n)\n</code></pre> <p>Run whichever example matches your setup:</p> <pre><code>python examples/gemini_adapter.py\n</code></pre>"},{"location":"examples/http-agent/","title":"HTTP Agent","text":"<p>Test any HTTP endpoint for tool-call accuracy. <code>HttpAgent</code> sends audio as base64-encoded JSON and parses the response -- no SDK dependency needed on the server side.</p> <p>Source file</p> <p><code>examples/http_agent.py</code></p>"},{"location":"examples/http-agent/#default-protocol","title":"Default protocol","text":"<p><code>HttpAgent</code> uses a simple JSON protocol out of the box:</p> <p>Request:</p> <pre><code>POST /voice-agent\n{\n    \"audio\": \"&lt;base64-encoded audio&gt;\",\n    \"format\": \"wav\"\n}\n</code></pre> <p>Expected response:</p> <pre><code>{\n    \"tool_calls\": [\n        {\"name\": \"book_flight\", \"arguments\": {\"from_city\": \"NYC\", \"to_city\": \"LA\"}}\n    ]\n}\n</code></pre>"},{"location":"examples/http-agent/#example-1-basic-http-agent","title":"Example 1: Basic HTTP agent","text":"<p>Point russo at any HTTP endpoint:</p> <pre><code>import russo\nfrom russo.adapters import HttpAgent\nfrom russo.evaluators import ExactEvaluator\n\nagent = HttpAgent(\n    url=\"http://localhost:8000/voice-agent\",\n)\n\nresult = await russo.run(\n    prompt=\"Book a flight from NYC to LA\",\n    synthesizer=my_synthesizer,\n    agent=agent,\n    evaluator=ExactEvaluator(),\n    expect=[russo.tool_call(\"book_flight\", from_city=\"NYC\", to_city=\"LA\")],\n)\n</code></pre>"},{"location":"examples/http-agent/#example-2-custom-headers-and-response-parser","title":"Example 2: Custom headers and response parser","text":"<p>Add auth headers and use a built-in parser for provider-specific response formats:</p> <pre><code>from russo.parsers import GeminiResponseParser\n\nagent = HttpAgent(\n    url=\"https://my-api.example.com/v1/agent\",\n    headers={\n        \"Authorization\": \"Bearer my-token\",\n        \"X-Request-ID\": \"russo-test-001\",\n    },\n    parser=GeminiResponseParser(),  # parse Gemini-format responses\n    timeout=30.0,\n)\n</code></pre> <p>When a <code>parser</code> is provided, <code>HttpAgent</code> passes the raw HTTP response body to the parser instead of using the default JSON protocol.</p>"},{"location":"examples/http-agent/#example-3-custom-field-names","title":"Example 3: Custom field names","text":"<p>If your server expects different JSON field names:</p> <pre><code>agent = HttpAgent(\n    url=\"http://localhost:8000/api/voice\",\n    audio_field=\"audio_data\",     # sends \"audio_data\" instead of \"audio\"\n    format_field=\"audio_format\",  # sends \"audio_format\" instead of \"format\"\n)\n</code></pre> <p>This sends:</p> <pre><code>{\n    \"audio_data\": \"&lt;base64&gt;\",\n    \"audio_format\": \"wav\"\n}\n</code></pre> <pre><code>python examples/http_agent.py\n</code></pre> <p>Note</p> <p>These examples require a running HTTP server. Replace the URL with your actual endpoint.</p>"},{"location":"examples/openai-adapter/","title":"OpenAI Adapters","text":"<p>Test OpenAI models for tool-call accuracy. russo provides two adapters:</p> <ul> <li><code>OpenAIAgent</code> -- Chat Completions with audio input (<code>gpt-4o-audio-preview</code>)</li> <li><code>OpenAIRealtimeAgent</code> -- Realtime API over WebSocket (<code>gpt-4o-realtime-preview</code>)</li> </ul> <p>Source file</p> <p><code>examples/openai_adapter.py</code></p>"},{"location":"examples/openai-adapter/#prerequisites","title":"Prerequisites","text":"<pre><code>pip install \"russo[openai]\"\nexport OPENAI_API_KEY=\"your-api-key\"\nexport GOOGLE_API_KEY=\"your-google-key\"  # for TTS synthesizer\n</code></pre>"},{"location":"examples/openai-adapter/#tool-definitions","title":"Tool definitions","text":"<p>OpenAI uses slightly different formats for Chat Completions vs Realtime:</p> Chat CompletionsRealtime API <pre><code>BOOK_FLIGHT_TOOL = {\n    \"type\": \"function\",\n    \"function\": {\n        \"name\": \"book_flight\",\n        \"description\": \"Book a flight between two cities.\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"from_city\": {\"type\": \"string\", \"description\": \"Departure city\"},\n                \"to_city\": {\"type\": \"string\", \"description\": \"Arrival city\"},\n            },\n            \"required\": [\"from_city\", \"to_city\"],\n        },\n    },\n}\n</code></pre> <pre><code>BOOK_FLIGHT_REALTIME_TOOL = {\n    \"type\": \"function\",\n    \"name\": \"book_flight\",\n    \"description\": \"Book a flight between two cities.\",\n    \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n            \"from_city\": {\"type\": \"string\", \"description\": \"Departure city\"},\n            \"to_city\": {\"type\": \"string\", \"description\": \"Arrival city\"},\n        },\n        \"required\": [\"from_city\", \"to_city\"],\n    },\n}\n</code></pre>"},{"location":"examples/openai-adapter/#example-1-openaiagent-chat-completions","title":"Example 1: OpenAIAgent (Chat Completions)","text":"<p>Send audio via the Chat Completions API:</p> <pre><code>import os\nimport russo\nfrom openai import AsyncOpenAI\nfrom russo.adapters import OpenAIAgent\nfrom russo.evaluators import ExactEvaluator\nfrom russo.synthesizers import GoogleSynthesizer\n\nclient = AsyncOpenAI()  # reads OPENAI_API_KEY from env\n\nagent = OpenAIAgent(\n    client=client,\n    model=\"gpt-4o-audio-preview\",\n    tools=[BOOK_FLIGHT_TOOL],\n    system_prompt=(\n        \"You are a travel assistant. When the user asks to book \"\n        \"a flight, call the book_flight function.\"\n    ),\n)\n\nsynthesizer = GoogleSynthesizer(api_key=os.environ[\"GOOGLE_API_KEY\"])\n\nresult = await russo.run(\n    prompt=\"Book a flight from Berlin to Rome for tomorrow\",\n    synthesizer=synthesizer,\n    agent=agent,\n    evaluator=ExactEvaluator(),\n    expect=[russo.tool_call(\"book_flight\", from_city=\"Berlin\", to_city=\"Rome\")],\n)\n</code></pre>"},{"location":"examples/openai-adapter/#example-2-openairealtimeagent","title":"Example 2: OpenAIRealtimeAgent","text":"<p>Stream audio via the Realtime API:</p> <pre><code>from russo.adapters import OpenAIRealtimeAgent\n\nagent = OpenAIRealtimeAgent(\n    client=client,\n    model=\"gpt-4o-realtime-preview\",\n    tools=[BOOK_FLIGHT_REALTIME_TOOL],\n    response_timeout=30.0,\n)\n\nresult = await russo.run(\n    prompt=\"Book a flight from NYC to LA\",\n    synthesizer=synthesizer,\n    agent=agent,\n    evaluator=ExactEvaluator(),\n    expect=[russo.tool_call(\"book_flight\", from_city=\"NYC\", to_city=\"LA\")],\n)\n</code></pre> <p>Note</p> <p>The Realtime API expects pcm16 audio at 24 kHz mono by default. If you pass WAV audio, the adapter automatically strips the WAV header to extract raw PCM frames.</p>"},{"location":"examples/openai-adapter/#example-3-pre-existing-realtime-connection","title":"Example 3: Pre-existing Realtime connection","text":"<p>Reuse a single WebSocket connection for multiple tests:</p> <pre><code>async with client.beta.realtime.connect(model=\"gpt-4o-realtime-preview\") as conn:\n    agent = OpenAIRealtimeAgent(connection=conn)\n\n    result = await russo.run(\n        prompt=\"Book a flight from London to Paris\",\n        synthesizer=synthesizer,\n        agent=agent,\n        evaluator=ExactEvaluator(),\n        expect=[russo.tool_call(\"book_flight\", from_city=\"London\", to_city=\"Paris\")],\n    )\n</code></pre> <p>This avoids the overhead of opening a new WebSocket per test.</p> <pre><code>python examples/openai_adapter.py\n</code></pre>"},{"location":"examples/pytest-integration/","title":"pytest Integration","text":"<p>The most natural way to use russo -- declarative test scenarios using markers and fixtures.</p> <p>Source files</p> <p><code>examples/pytest_integration/</code></p>"},{"location":"examples/pytest-integration/#how-it-works","title":"How it works","text":"<p>The russo pytest plugin (auto-discovered via the <code>pytest11</code> entry point) provides:</p> <ul> <li><code>@pytest.mark.russo</code> -- marker to declare test scenarios</li> <li><code>russo_result</code> -- fixture that runs the full pipeline and returns an <code>EvalResult</code></li> <li>Overridable fixtures -- <code>russo_synthesizer</code>, <code>russo_agent</code>, <code>russo_evaluator</code></li> <li>CLI options -- caching, reporting, and more</li> </ul>"},{"location":"examples/pytest-integration/#step-1-configure-fixtures-in-conftestpy","title":"Step 1: Configure fixtures in <code>conftest.py</code>","text":"<p>Define your synthesizer and agent as pytest fixtures:</p> <pre><code># conftest.py\nimport os\nimport pytest\nimport russo\nfrom russo.evaluators import ExactEvaluator\n\n\n@pytest.fixture(scope=\"session\")\ndef russo_synthesizer():\n    \"\"\"TTS synthesizer for all russo tests.\"\"\"\n    api_key = os.environ.get(\"GOOGLE_API_KEY\")\n    if api_key:\n        from russo.synthesizers import GoogleSynthesizer\n        return GoogleSynthesizer(api_key=api_key)\n\n    # Fallback for CI / offline use\n    class FakeSynthesizer:\n        async def synthesize(self, text: str) -&gt; russo.Audio:\n            return russo.Audio(data=b\"\\x00\" * 4800, format=\"wav\", sample_rate=24000)\n\n    return FakeSynthesizer()\n\n\n@pytest.fixture(scope=\"session\")\ndef russo_agent():\n    \"\"\"The agent under test.\"\"\"\n    # Replace with your real agent:\n    #   from russo.adapters import GeminiLiveAgent\n    #   return GeminiLiveAgent(client=..., model=\"...\", tools=[...])\n\n    @russo.agent\n    async def fake_agent(audio: russo.Audio) -&gt; russo.AgentResponse:\n        return russo.AgentResponse(\n            tool_calls=[\n                russo.ToolCall(\n                    name=\"book_flight\",\n                    arguments={\"from_city\": \"NYC\", \"to_city\": \"LA\"},\n                ),\n            ]\n        )\n\n    return fake_agent\n\n\n@pytest.fixture\ndef russo_evaluator():\n    \"\"\"Override to use a custom evaluator (defaults to ExactEvaluator).\"\"\"\n    return ExactEvaluator()\n</code></pre>"},{"location":"examples/pytest-integration/#step-2-write-tests-using-the-marker","title":"Step 2: Write tests using the marker","text":"<p>The <code>@pytest.mark.russo</code> marker declares the prompt and expected tool calls. The <code>russo_result</code> fixture runs the full pipeline automatically.</p>"},{"location":"examples/pytest-integration/#basic-assertion","title":"Basic assertion","text":"<pre><code># test_flights.py\nimport pytest\nimport russo\n\n\n@pytest.mark.russo(\n    prompt=\"Book a flight from NYC to LA\",\n    expect=[russo.tool_call(\"book_flight\", from_city=\"NYC\", to_city=\"LA\")],\n)\nasync def test_book_flight(russo_result):\n    \"\"\"Verify the agent calls book_flight with the right arguments.\"\"\"\n    russo.assert_tool_calls(russo_result)\n</code></pre>"},{"location":"examples/pytest-integration/#match-rate-check","title":"Match rate check","text":"<pre><code>@pytest.mark.russo(\n    prompt=\"Book a flight from NYC to LA\",\n    expect=[russo.tool_call(\"book_flight\", from_city=\"NYC\", to_city=\"LA\")],\n)\nasync def test_match_rate(russo_result):\n    \"\"\"Check that every expected tool call was matched.\"\"\"\n    assert russo_result.passed\n    assert russo_result.match_rate == 1.0\n</code></pre>"},{"location":"examples/pytest-integration/#custom-failure-message","title":"Custom failure message","text":"<pre><code>@pytest.mark.russo(\n    prompt=\"Book a flight from NYC to LA\",\n    expect=[russo.tool_call(\"book_flight\", from_city=\"NYC\", to_city=\"LA\")],\n)\nasync def test_with_custom_message(russo_result):\n    russo.assert_tool_calls(russo_result, message=\"Flight booking agent failed\")\n</code></pre>"},{"location":"examples/pytest-integration/#detailed-inspection","title":"Detailed inspection","text":"<pre><code>@pytest.mark.russo(\n    prompt=\"Book a flight from NYC to LA\",\n    expect=[russo.tool_call(\"book_flight\", from_city=\"NYC\", to_city=\"LA\")],\n)\nasync def test_detailed_inspection(russo_result):\n    \"\"\"Access individual match details for richer assertions.\"\"\"\n    assert russo_result.passed\n\n    for match in russo_result.matches:\n        assert match.matched, f\"Expected {match.expected.name} was not matched\"\n        assert match.actual is not None\n        assert match.actual.name == match.expected.name\n\n    assert len(russo_result.actual) &gt;= 1\n    assert russo_result.actual[0].name == \"book_flight\"\n</code></pre>"},{"location":"examples/pytest-integration/#step-3-run-the-tests","title":"Step 3: Run the tests","text":"<pre><code>pytest examples/pytest_integration/ -v\n</code></pre> <p>Expected output:</p> <pre><code>test_flights.py::test_book_flight PASSED\ntest_flights.py::test_match_rate PASSED\ntest_flights.py::test_with_custom_message PASSED\ntest_flights.py::test_detailed_inspection PASSED\n</code></pre>"},{"location":"examples/pytest-integration/#concurrent-runs","title":"Concurrent runs","text":"<p>Run the same test multiple times or test multiple prompt variants \u2014 see Concurrent Runs for the full guide.</p>"},{"location":"examples/pytest-integration/#multiple-runs-per-test","title":"Multiple runs per test","text":"<pre><code>@pytest.mark.russo(\n    prompt=\"Book a flight from NYC to LA\",\n    expect=[russo.tool_call(\"book_flight\", from_city=\"NYC\", to_city=\"LA\")],\n    runs=5,\n)\nasync def test_reliability(russo_result):\n    \"\"\"Runs the prompt 5 times concurrently. Returns a BatchResult.\"\"\"\n    assert russo_result.pass_rate &gt;= 0.8\n</code></pre>"},{"location":"examples/pytest-integration/#multiple-prompts","title":"Multiple prompts","text":"<pre><code>@pytest.mark.russo(\n    prompts=[\n        \"Book a flight from NYC to LA\",\n        \"I need to fly from NYC to LA\",\n    ],\n    expect=[russo.tool_call(\"book_flight\", from_city=\"NYC\", to_city=\"LA\")],\n)\nasync def test_prompt_variants(russo_result):\n    assert russo_result.total == 2\n    assert russo_result.passed\n</code></pre>"},{"location":"examples/pytest-integration/#combined-prompts-runs","title":"Combined: prompts \u00d7 runs","text":"<pre><code>@pytest.mark.russo(\n    prompts=[\"Book from NYC to LA\", \"Fly NYC to LA\"],\n    expect=[russo.tool_call(\"book_flight\", from_city=\"NYC\", to_city=\"LA\")],\n    runs=3,\n    max_concurrency=4,\n)\nasync def test_full_matrix(russo_result):\n    assert russo_result.total == 6  # 2 prompts \u00d7 3 runs\n</code></pre> <p>Source file</p> <p><code>examples/pytest_integration/test_concurrent.py</code></p>"},{"location":"examples/pytest-integration/#cli-options","title":"CLI options","text":"<p>The russo plugin adds several command-line options:</p> <pre><code># Caching\npytest --russo-cache                # enable audio cache (default)\npytest --russo-no-cache             # disable caching\npytest --russo-clear-cache          # clear cache before running\npytest --russo-cache-dir .my_cache  # custom cache directory\n\n# Concurrent runs\npytest --russo-runs 5               # run each test 5 times (marker overrides this)\npytest --russo-max-concurrency 3    # limit parallel pipeline executions\n\n# Reporting\npytest --russo-report report.html   # generate HTML report\n</code></pre>"},{"location":"examples/websocket-agent/","title":"WebSocket Agent","text":"<p>Test WebSocket endpoints for tool-call accuracy. <code>WebSocketAgent</code> supports JSON mode, raw bytes mode, and fully custom protocols via hooks.</p> <p>Source file</p> <p><code>examples/websocket_agent.py</code></p>"},{"location":"examples/websocket-agent/#prerequisites","title":"Prerequisites","text":"<pre><code>pip install \"russo[ws]\"\n</code></pre>"},{"location":"examples/websocket-agent/#example-1-json-protocol-default","title":"Example 1: JSON protocol (default)","text":"<p>Send audio as base64 JSON, receive a JSON response:</p> <pre><code>import russo\nfrom russo.adapters import WebSocketAgent\nfrom russo.evaluators import ExactEvaluator\n\nagent = WebSocketAgent(\n    url=\"ws://localhost:8000/ws/agent\",\n    response_timeout=15.0,\n)\n\nresult = await russo.run(\n    prompt=\"Book a flight from NYC to LA\",\n    synthesizer=my_synthesizer,\n    agent=agent,\n    evaluator=ExactEvaluator(),\n    expect=[russo.tool_call(\"book_flight\", from_city=\"NYC\", to_city=\"LA\")],\n)\n</code></pre> <p>The default sends <code>{\"audio\": \"&lt;base64&gt;\", \"format\": \"wav\"}</code> and expects the same response format as <code>HttpAgent</code>.</p>"},{"location":"examples/websocket-agent/#example-2-raw-bytes-mode","title":"Example 2: Raw bytes mode","text":"<p>Send raw audio bytes directly on the wire -- useful for streaming PCM to servers that expect binary frames:</p> <pre><code>agent = WebSocketAgent(\n    url=\"ws://localhost:8000/ws/stream\",\n    send_bytes=True,\n    response_timeout=10.0,\n)\n</code></pre>"},{"location":"examples/websocket-agent/#example-3-custom-protocol-with-hooks","title":"Example 3: Custom protocol with hooks","text":"<p>Full control over the send/receive cycle using three hooks:</p>"},{"location":"examples/websocket-agent/#on_send-customize-the-outgoing-message","title":"<code>on_send</code> -- customize the outgoing message","text":"<pre><code>import base64\nimport json\n\ndef custom_send(audio: russo.Audio) -&gt; str:\n    \"\"\"Build a custom JSON message for your server.\"\"\"\n    return json.dumps({\n        \"type\": \"audio_input\",\n        \"pcm\": base64.b64encode(audio.data).decode(),\n        \"sample_rate\": audio.sample_rate,\n    })\n</code></pre>"},{"location":"examples/websocket-agent/#is_complete-decide-when-to-stop-collecting-responses","title":"<code>is_complete</code> -- decide when to stop collecting responses","text":"<pre><code>def is_done(messages: list) -&gt; bool:\n    \"\"\"Stop collecting when the server sends a 'done' message.\"\"\"\n    return any(\n        isinstance(m, dict) and m.get(\"type\") == \"done\"\n        for m in messages\n    )\n</code></pre>"},{"location":"examples/websocket-agent/#aggregate-combine-collected-messages-into-one-response","title":"<code>aggregate</code> -- combine collected messages into one response","text":"<pre><code>def aggregate_responses(messages: list):\n    \"\"\"Combine all tool_call messages into one response.\"\"\"\n    tool_calls = []\n    for msg in messages:\n        if isinstance(msg, dict) and msg.get(\"type\") == \"tool_call\":\n            tool_calls.append(msg)\n    return {\"tool_calls\": tool_calls}\n</code></pre>"},{"location":"examples/websocket-agent/#putting-it-together","title":"Putting it together","text":"<pre><code>agent = WebSocketAgent(\n    url=\"ws://localhost:8000/ws/custom\",\n    on_send=custom_send,\n    is_complete=is_done,\n    aggregate=aggregate_responses,\n    response_timeout=20.0,\n    max_messages=50,\n)\n</code></pre>"},{"location":"examples/websocket-agent/#example-4-with-a-response-parser","title":"Example 4: With a response parser","text":"<p>Use a built-in parser for provider-specific response formats:</p> <pre><code>from russo.parsers import GeminiResponseParser\n\nagent = WebSocketAgent(\n    url=\"ws://localhost:8000/ws/gemini\",\n    parser=GeminiResponseParser(),\n    headers={\"Authorization\": \"Bearer my-token\"},\n)\n</code></pre> <pre><code>python examples/websocket_agent.py\n</code></pre> <p>Note</p> <p>These examples require a running WebSocket server. Replace the URL with your actual endpoint.</p>"},{"location":"examples/websocket-testing/","title":"WebSocket Testing (End-to-End)","text":"<p>A complete end-to-end example: a WebSocket server wrapping a real Gemini model with tool declarations, tested using russo's <code>WebSocketAgent</code>, <code>GoogleSynthesizer</code>, and pytest plugin. No mocks -- real TTS, real LLM, real WebSocket transport.</p> <p>Source files</p> <p><code>examples/websocket_testing/</code></p>"},{"location":"examples/websocket-testing/#prerequisites","title":"Prerequisites","text":"<pre><code>pip install \"russo[ws]\"\n</code></pre> <p>You need one of:</p> <ul> <li>Google AI API key: <code>export GOOGLE_API_KEY=\"...\"</code></li> <li>Vertex AI credentials: <code>export GOOGLE_CLOUD_PROJECT=\"...\"</code> (or <code>GOOGLE_PROJECT_ID</code>) + Application Default Credentials</li> </ul>"},{"location":"examples/websocket-testing/#architecture","title":"Architecture","text":"<pre><code>sequenceDiagram\n    participant P as russo pipeline\n    participant S as GoogleSynthesizer\n    participant W as WebSocketAgent\n    participant Srv as WebSocket Server\n    participant G as Gemini API\n\n    P-&gt;&gt;S: synthesize(\"Book a flight...\")\n    S-&gt;&gt;P: Audio (WAV)\n    P-&gt;&gt;W: run(audio)\n    W-&gt;&gt;Srv: {\"audio\": \"&lt;base64&gt;\", \"format\": \"wav\"}\n    Srv-&gt;&gt;G: generate_content(audio + tools)\n    G-&gt;&gt;Srv: function_call(book_flight, ...)\n    Srv-&gt;&gt;W: {\"tool_calls\": [{name, arguments}]}\n    W-&gt;&gt;P: AgentResponse\n    P-&gt;&gt;P: ExactEvaluator compares expected vs actual</code></pre> <p>The server acts as a thin proxy: it receives audio over WebSocket, forwards it to Gemini with tool declarations, parses the function-call response, and returns structured JSON that russo's default <code>WebSocketAgent</code> protocol understands.</p>"},{"location":"examples/websocket-testing/#step-1-the-websocket-server","title":"Step 1: The WebSocket server","text":"<p>The server uses Python's <code>websockets</code> library (a russo dependency -- no FastAPI or uvicorn needed).</p>"},{"location":"examples/websocket-testing/#tool-declarations","title":"Tool declarations","text":"<p>Tools are declared in Gemini's <code>function_declarations</code> format:</p> <pre><code>TOOLS = [\n    {\n        \"function_declarations\": [\n            {\n                \"name\": \"book_flight\",\n                \"description\": \"Book a flight between two cities.\",\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"from_city\": {\"type\": \"string\", \"description\": \"Departure city\"},\n                        \"to_city\": {\"type\": \"string\", \"description\": \"Destination city\"},\n                    },\n                    \"required\": [\"from_city\", \"to_city\"],\n                },\n            },\n            {\n                \"name\": \"search_hotels\",\n                \"description\": \"Search for hotels in a city.\",\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"city\": {\"type\": \"string\", \"description\": \"City to search hotels in\"},\n                        \"checkin_date\": {\"type\": \"string\", \"description\": \"Check-in date\"},\n                    },\n                    \"required\": [\"city\"],\n                },\n            },\n            {\n                \"name\": \"get_weather\",\n                \"description\": \"Get current weather information for a city.\",\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"city\": {\"type\": \"string\", \"description\": \"City to get weather for\"},\n                    },\n                    \"required\": [\"city\"],\n                },\n            },\n        ]\n    }\n]\n</code></pre> <p>Gemini tool format</p> <p>Gemini expects tools wrapped as <code>{\"function_declarations\": [...]}</code>, not as bare <code>{name, description, parameters}</code> dicts. Passing bare dicts will silently produce text responses instead of function calls.</p>"},{"location":"examples/websocket-testing/#connection-handler","title":"Connection handler","text":"<p>Each WebSocket connection handles one audio-to-tool-call exchange:</p> <pre><code>async def _handle_connection(ws):\n    from google.genai import types\n\n    # 1. Receive base64-encoded audio\n    raw = json.loads(await ws.recv())\n    audio_bytes = base64.b64decode(raw[\"audio\"])\n\n    # 2. Wrap in WAV if needed, send to Gemini\n    data, mime_type = _ensure_wav(audio_bytes)\n    client = _make_client()\n    response = await client.aio.models.generate_content(\n        model=\"gemini-2.0-flash\",\n        contents=[types.Part.from_bytes(data=data, mime_type=mime_type)],\n        config=types.GenerateContentConfig(\n            tools=TOOLS,\n            system_instruction=SYSTEM_INSTRUCTION,\n        ),\n    )\n\n    # 3. Parse function calls and return\n    tool_calls = []\n    for candidate in (response.candidates or []):\n        for part in (candidate.content.parts or []):\n            if part.function_call:\n                fc = part.function_call\n                tool_calls.append({\n                    \"name\": fc.name,\n                    \"arguments\": dict(fc.args) if fc.args else {},\n                })\n\n    await ws.send(json.dumps({\"tool_calls\": tool_calls}))\n</code></pre>"},{"location":"examples/websocket-testing/#auth-resolution","title":"Auth resolution","text":"<p>The server auto-detects credentials from the environment:</p> <pre><code>def _make_client():\n    from google import genai\n\n    project = (\n        os.environ.get(\"GOOGLE_CLOUD_PROJECT\")\n        or os.environ.get(\"GOOGLE_PROJECT_ID\")\n    )\n    if project:\n        return genai.Client(\n            vertexai=True,\n            project=project,\n            location=os.environ.get(\"GOOGLE_CLOUD_LOCATION\", \"us-central1\"),\n        )\n    return genai.Client()  # uses GOOGLE_API_KEY\n</code></pre> <p>Tilde expansion</p> <p>The <code>google-auth</code> library does not expand <code>~</code> in <code>GOOGLE_APPLICATION_CREDENTIALS</code>. The example handles this automatically with <code>os.path.expanduser()</code>.</p>"},{"location":"examples/websocket-testing/#step-2-configure-fixtures-in-conftestpy","title":"Step 2: Configure fixtures in <code>conftest.py</code>","text":""},{"location":"examples/websocket-testing/#server-lifecycle","title":"Server lifecycle","text":"<p>A session-scoped fixture starts the server as a subprocess on a random port:</p> <pre><code>@pytest.fixture(scope=\"session\")\ndef travel_agent_server():\n    port = _find_free_port()\n    proc = subprocess.Popen(\n        [sys.executable, _SERVER_SCRIPT, \"--port\", str(port)],\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE,\n    )\n    try:\n        _wait_for_server(port)  # polls until accepting connections\n        yield port\n    finally:\n        proc.terminate()\n        proc.wait(timeout=5)\n</code></pre>"},{"location":"examples/websocket-testing/#russo-fixtures","title":"russo fixtures","text":"<pre><code>@pytest.fixture\ndef russo_synthesizer():\n    \"\"\"Google TTS -- Vertex AI or API key from environment.\"\"\"\n    project = _gcp_project()\n    if project:\n        return GoogleSynthesizer(\n            vertexai=True,\n            project=project,\n            location=os.environ.get(\"GOOGLE_CLOUD_LOCATION\", \"us-central1\"),\n        )\n    return GoogleSynthesizer()\n\n\n@pytest.fixture\ndef russo_agent(travel_agent_server):\n    \"\"\"WebSocketAgent pointing at the local server.\"\"\"\n    port = travel_agent_server\n    return WebSocketAgent(url=f\"ws://localhost:{port}\")\n\n\n@pytest.fixture\ndef russo_evaluator():\n    return ExactEvaluator()\n</code></pre> <p>Function-scoped synthesizer</p> <p><code>russo_synthesizer</code> is intentionally function-scoped (not session-scoped). The <code>genai.Client</code> created inside <code>GoogleSynthesizer</code> has internal <code>asyncio.Lock</code> objects that bind to whichever event loop first uses them. Since pytest-asyncio creates a new event loop per test by default, a session-scoped client would crash on the second test with <code>RuntimeError: is bound to a different event loop</code>. The russo plugin wraps the synthesizer in <code>CachedSynthesizer</code> anyway, so TTS results are still cached to disk.</p>"},{"location":"examples/websocket-testing/#step-3-write-tests","title":"Step 3: Write tests","text":"<p>Tests use <code>@pytest.mark.russo</code> -- the plugin handles synthesizing audio, running the agent, and evaluating the result.</p>"},{"location":"examples/websocket-testing/#single-run-tests","title":"Single-run tests","text":"<pre><code>@pytest.mark.russo(\n    prompt=\"Book a flight from Berlin to Rome\",\n    expect=[russo.tool_call(\"book_flight\", from_city=\"Berlin\", to_city=\"Rome\")],\n)\nasync def test_book_flight(russo_result):\n    russo.assert_tool_calls(russo_result)\n\n\n@pytest.mark.russo(\n    prompt=\"Search for hotels in Paris\",\n    expect=[russo.tool_call(\"search_hotels\", city=\"Paris\")],\n)\nasync def test_search_hotels(russo_result):\n    russo.assert_tool_calls(russo_result)\n\n\n@pytest.mark.russo(\n    prompt=\"What is the weather in Tokyo\",\n    expect=[russo.tool_call(\"get_weather\", city=\"Tokyo\")],\n)\nasync def test_get_weather(russo_result):\n    russo.assert_tool_calls(russo_result)\n</code></pre>"},{"location":"examples/websocket-testing/#reliability-testing","title":"Reliability testing","text":"<p>Run the same prompt multiple times and assert a minimum pass rate:</p> <pre><code>@pytest.mark.russo(\n    prompt=\"Book a flight from Berlin to Rome\",\n    expect=[russo.tool_call(\"book_flight\", from_city=\"Berlin\", to_city=\"Rome\")],\n    runs=3,\n)\nasync def test_flight_reliability(russo_result):\n    assert isinstance(russo_result, russo.BatchResult)\n    assert russo_result.pass_rate &gt;= 0.66\n</code></pre>"},{"location":"examples/websocket-testing/#prompt-variants","title":"Prompt variants","text":"<p>Test multiple phrasings of the same intent:</p> <pre><code>@pytest.mark.russo(\n    prompts=[\n        \"I need to fly from Berlin to Rome\",\n        \"Please book me a flight, departing Berlin, arriving Rome\",\n        \"Get me on a plane from Berlin to Rome\",\n    ],\n    expect=[russo.tool_call(\"book_flight\", from_city=\"Berlin\", to_city=\"Rome\")],\n)\nasync def test_prompt_variants(russo_result):\n    assert isinstance(russo_result, russo.BatchResult)\n    assert russo_result.pass_rate &gt;= 0.66\n</code></pre>"},{"location":"examples/websocket-testing/#step-4-run","title":"Step 4: Run","text":"<pre><code># Set credentials (one of these)\nexport GOOGLE_API_KEY=\"your-key\"\n# or\nexport GOOGLE_CLOUD_PROJECT=\"your-project\"\n\n# Run all tests\npytest examples/websocket_testing/ -v\n</code></pre> <p>Expected output:</p> <pre><code>test_agent.py::test_book_flight PASSED\ntest_agent.py::test_search_hotels PASSED\ntest_agent.py::test_get_weather PASSED\ntest_agent.py::test_flight_reliability PASSED\ntest_agent.py::test_prompt_variants PASSED\n</code></pre> <p>You can also start the server manually for debugging:</p> <pre><code>python examples/websocket_testing/server.py --port 8765\n</code></pre>"},{"location":"examples/websocket-testing/#how-it-works","title":"How it works","text":"<ol> <li> <p>Server subprocess -- <code>conftest.py</code> starts <code>server.py</code> on a random port before any tests run (session-scoped fixture). The server listens for WebSocket connections.</p> </li> <li> <p>TTS -- <code>GoogleSynthesizer</code> converts each prompt string to audio via Google's TTS API. Results are cached to disk by <code>CachedSynthesizer</code>.</p> </li> <li> <p>WebSocket transport -- <code>WebSocketAgent</code> connects to the server, sends <code>{\"audio\": \"&lt;base64&gt;\", \"format\": \"wav\"}</code>, and waits for the response. This is the default JSON protocol -- no custom hooks needed.</p> </li> <li> <p>Gemini inference -- The server decodes the audio, sends it to <code>gemini-2.0-flash</code> with tool declarations, and parses function calls from the response.</p> </li> <li> <p>Evaluation -- <code>ExactEvaluator</code> compares actual tool calls against expected ones. <code>russo.assert_tool_calls()</code> raises a descriptive error on mismatch.</p> </li> </ol>"},{"location":"examples/websocket-testing/#see-also","title":"See also","text":"<ul> <li>WebSocket Agent -- <code>WebSocketAgent</code> protocol options (bytes mode, custom hooks)</li> <li>pytest Integration -- markers, fixtures, and CLI options</li> <li>Gemini Adapters -- direct Gemini SDK usage without a server</li> <li>Concurrent Runs -- <code>runs</code> and <code>prompts</code> for reliability testing</li> </ul>"},{"location":"getting-started/first-test/","title":"First Test","text":"<p>This guide walks you through writing your first russo test. You'll need a Google AI API key for the synthesizer and an agent to test against.</p>"},{"location":"getting-started/first-test/#setup","title":"Setup","text":"<pre><code>pip install russo\nexport GOOGLE_API_KEY=\"your-api-key\"\n</code></pre>"},{"location":"getting-started/first-test/#the-pipeline","title":"The Pipeline","text":"<p>Every russo test follows the same flow:</p> <ol> <li>Synthesize \u2014 convert a text prompt to audio</li> <li>Run \u2014 send the audio to your agent</li> <li>Evaluate \u2014 compare the agent's tool calls against expectations</li> </ol>"},{"location":"getting-started/first-test/#writing-the-test","title":"Writing the Test","text":""},{"location":"getting-started/first-test/#step-1-define-your-agent","title":"Step 1: Define Your Agent","text":"<p>You can wrap any async function as an agent using the <code>@russo.agent</code> decorator:</p> <pre><code>import russo\n\n@russo.agent\nasync def my_agent(audio: russo.Audio) -&gt; russo.AgentResponse:\n    # Call your real agent here with audio.data\n    # For this example, we'll simulate a response\n    return russo.AgentResponse(\n        tool_calls=[\n            russo.ToolCall(name=\"book_flight\", arguments={\"from_city\": \"NYC\", \"to_city\": \"LA\"})\n        ]\n    )\n</code></pre>"},{"location":"getting-started/first-test/#step-2-run-the-pipeline","title":"Step 2: Run the Pipeline","text":"<pre><code>import asyncio\nfrom russo.synthesizers import GoogleSynthesizer\nfrom russo.evaluators import ExactEvaluator\n\nasync def main():\n    result = await russo.run(\n        prompt=\"Book a flight from New York to Los Angeles\",\n        synthesizer=GoogleSynthesizer(api_key=\"...\"),\n        agent=my_agent,\n        evaluator=ExactEvaluator(),\n        expect=[\n            russo.tool_call(\"book_flight\", from_city=\"NYC\", to_city=\"LA\"),\n        ],\n    )\n\n    print(result.summary())\n    # PASSED (100% match rate)\n    #   [+] book_flight({'from_city': 'NYC', 'to_city': 'LA'}) -&gt; book_flight(...)\n\nasyncio.run(main())\n</code></pre>"},{"location":"getting-started/first-test/#step-3-use-pytest","title":"Step 3: Use pytest","text":"<p>The most natural way to use russo is with pytest:</p> <pre><code># conftest.py\nimport pytest\nfrom russo.synthesizers import GoogleSynthesizer\nfrom russo.adapters import GeminiLiveAgent\n\n@pytest.fixture(scope=\"session\")\ndef russo_synthesizer():\n    return GoogleSynthesizer(api_key=\"...\")\n\n@pytest.fixture(scope=\"session\")\ndef russo_agent():\n    return GeminiLiveAgent(api_key=\"...\", model=\"gemini-live-2.5-flash-native-audio\", tools=[...])\n</code></pre> <pre><code># test_flights.py\nimport pytest\nimport russo\n\n@pytest.mark.russo(\n    prompt=\"Book a flight from NYC to LA\",\n    expect=[russo.tool_call(\"book_flight\", from_city=\"NYC\", to_city=\"LA\")],\n)\nasync def test_book_flight(russo_result):\n    russo.assert_tool_calls(russo_result)\n\n@pytest.mark.russo(\n    prompt=\"What's the weather in Berlin?\",\n    expect=[russo.tool_call(\"get_weather\", city=\"Berlin\")],\n)\nasync def test_weather(russo_result):\n    assert russo_result.passed\n    assert russo_result.match_rate == 1.0\n</code></pre> <p>Run it:</p> <pre><code>pytest -v\n</code></pre>"},{"location":"getting-started/first-test/#whats-next","title":"What's Next?","text":"<ul> <li>Learn about adapters for different agent types</li> <li>Explore caching to speed up repeated test runs</li> <li>See the full API reference</li> </ul>"},{"location":"getting-started/installation/","title":"Installation","text":""},{"location":"getting-started/installation/#requirements","title":"Requirements","text":"<ul> <li>Python 3.12+</li> </ul>"},{"location":"getting-started/installation/#install-from-pypi","title":"Install from PyPI","text":"<pre><code>pip install russo\n</code></pre> <p>Or with uv:</p> <pre><code>uv add russo\n</code></pre>"},{"location":"getting-started/installation/#optional-dependencies","title":"Optional Dependencies","text":"<p>russo has optional extras for different LLM providers:</p> OpenAIWebSocketAll <pre><code>pip install \"russo[openai]\"\n</code></pre> <p>Adds support for <code>OpenAIAgent</code> and <code>OpenAIRealtimeAgent</code>.</p> <pre><code>pip install \"russo[ws]\"\n</code></pre> <p>Adds support for <code>WebSocketAgent</code> (generic WebSocket connections).</p> <pre><code>pip install \"russo[all]\"\n</code></pre> <p>Installs all optional dependencies.</p>"},{"location":"getting-started/installation/#for-development","title":"For Development","text":"<pre><code>git clone https://github.com/mohit2152sharma/russo.git\ncd russo\nuv sync --all-extras\n</code></pre> <p>This installs all dependencies including dev tools (ruff, pytest, basedpyright, etc.) and documentation tools (mkdocs-material).</p>"},{"location":"getting-started/installation/#verify-installation","title":"Verify Installation","text":"<pre><code>import russo\nprint(russo.__doc__)\n# russo \u2014 testing framework for LLM tool-call accuracy.\n</code></pre>"},{"location":"reference/","title":"API Reference","text":"<p>Complete API documentation for russo, auto-generated from docstrings.</p>"},{"location":"reference/#core","title":"Core","text":"<p>The main public API surface:</p> <ul> <li><code>russo</code> \u2014 top-level exports</li> <li><code>Types</code> \u2014 <code>Audio</code>, <code>ToolCall</code>, <code>AgentResponse</code>, <code>EvalResult</code>, <code>ToolCallMatch</code></li> <li><code>Pipeline</code> \u2014 <code>russo.run()</code></li> <li><code>Protocols</code> \u2014 <code>Synthesizer</code>, <code>Agent</code>, <code>Evaluator</code>, <code>ResponseParser</code></li> <li><code>Cache</code> \u2014 <code>AudioCache</code>, <code>CachedSynthesizer</code></li> <li><code>Assertions</code> \u2014 <code>assert_tool_calls</code>, <code>ToolCallAssertionError</code></li> </ul>"},{"location":"reference/#adapters","title":"Adapters","text":"<p>Agent adapters for different invocation styles:</p> <ul> <li><code>Gemini</code> \u2014 <code>GeminiAgent</code>, <code>GeminiLiveAgent</code></li> <li><code>OpenAI</code> \u2014 <code>OpenAIAgent</code>, <code>OpenAIRealtimeAgent</code></li> <li><code>HTTP</code> \u2014 <code>HttpAgent</code></li> <li><code>WebSocket</code> \u2014 <code>WebSocketAgent</code></li> <li><code>Callable</code> \u2014 <code>CallableAgent</code>, <code>@agent</code> decorator</li> </ul>"},{"location":"reference/#synthesizers","title":"Synthesizers","text":"<ul> <li><code>Google</code> \u2014 <code>GoogleSynthesizer</code></li> </ul>"},{"location":"reference/#evaluators","title":"Evaluators","text":"<ul> <li><code>Exact</code> \u2014 <code>ExactEvaluator</code></li> </ul>"},{"location":"reference/#parsers","title":"Parsers","text":"<ul> <li><code>Gemini</code> \u2014 <code>GeminiResponseParser</code></li> <li><code>OpenAI</code> \u2014 <code>OpenAIResponseParser</code></li> </ul>"},{"location":"reference/#integrations","title":"Integrations","text":"<ul> <li><code>pytest Plugin</code> \u2014 markers, fixtures, CLI options</li> </ul>"},{"location":"reference/pytest-plugin/","title":"pytest Plugin","text":"<p>pytest plugin for russo \u2014 auto-discovered via the <code>pytest11</code> entry point.</p>"},{"location":"reference/pytest-plugin/#russo.pytest_plugin","title":"pytest_plugin","text":"<p>pytest plugin for russo \u2014 auto-discovered via the pytest11 entry point.</p> <p>Provides: - <code>russo</code> marker for declarative test scenarios - <code>russo_result</code> fixture that runs the full pipeline - Terminal summary via <code>pytest_terminal_summary</code> hook - <code>--russo-report</code> CLI option for HTML report output - <code>--russo-runs</code> for concurrent multi-run testing</p>"},{"location":"reference/pytest-plugin/#russo.pytest_plugin.pytest_sessionstart","title":"pytest_sessionstart","text":"<pre><code>pytest_sessionstart(session: Session) -&gt; None\n</code></pre> <p>Clear audio cache if --russo-clear-cache was passed.</p> Source code in <code>src/russo/pytest_plugin.py</code> <pre><code>def pytest_sessionstart(session: pytest.Session) -&gt; None:\n    \"\"\"Clear audio cache if --russo-clear-cache was passed.\"\"\"\n    if session.config.getoption(\"russo_clear_cache\", default=False):\n        from pathlib import Path\n\n        cache_dir = session.config.getoption(\"russo_cache_dir\", default=\".russo_cache\")\n        cache = AudioCache(Path(cache_dir))\n        n = cache.size()\n        cache.clear()\n        # Use write_line via terminal writer if available\n        tw = session.config.get_terminal_writer()\n        tw.line(f\"russo: cleared {n} cached audio entries from {cache_dir}\")\n</code></pre>"},{"location":"reference/pytest-plugin/#russo.pytest_plugin.russo_audio_cache","title":"russo_audio_cache","text":"<pre><code>russo_audio_cache(request: FixtureRequest) -&gt; AudioCache\n</code></pre> <p>Session-scoped audio cache. Override in conftest.py to customize.</p> Source code in <code>src/russo/pytest_plugin.py</code> <pre><code>@pytest.fixture(scope=\"session\")\ndef russo_audio_cache(request: pytest.FixtureRequest) -&gt; AudioCache:\n    \"\"\"Session-scoped audio cache. Override in conftest.py to customize.\"\"\"\n    from pathlib import Path\n\n    cache_dir = request.config.getoption(\"russo_cache_dir\", default=\".russo_cache\")\n    return AudioCache(Path(cache_dir))\n</code></pre>"},{"location":"reference/pytest-plugin/#russo.pytest_plugin.russo_evaluator","title":"russo_evaluator","text":"<pre><code>russo_evaluator() -&gt; ExactEvaluator\n</code></pre> <p>Default evaluator \u2014 exact match. Override in conftest.py to customize.</p> Source code in <code>src/russo/pytest_plugin.py</code> <pre><code>@pytest.fixture\ndef russo_evaluator() -&gt; ExactEvaluator:\n    \"\"\"Default evaluator \u2014 exact match. Override in conftest.py to customize.\"\"\"\n    return ExactEvaluator()\n</code></pre>"},{"location":"reference/pytest-plugin/#russo.pytest_plugin.russo_result","title":"russo_result  <code>async</code>","text":"<pre><code>russo_result(request: FixtureRequest) -&gt; EvalResult | BatchResult | None\n</code></pre> <p>Run the russo pipeline based on the <code>@pytest.mark.russo</code> marker.</p> <p>Reads marker kwargs, resolves synthesizer/agent/evaluator fixtures, runs the pipeline, and returns the result.</p> Marker kwargs <p>prompt (str): Single text prompt. prompts (list[str]): Multiple text prompts (runs all concurrently). expect (list): Expected tool calls. runs (int): Number of times to run each prompt (default 1).     Falls back to <code>--russo-runs</code> CLI option. max_concurrency (int | None): Cap on concurrent runs.     Falls back to <code>--russo-max-concurrency</code> CLI option.</p> RETURNS DESCRIPTION <code>EvalResult | BatchResult | None</code> <ul> <li><code>EvalResult</code> for single prompt + single run (backward compatible).</li> </ul> <code>EvalResult | BatchResult | None</code> <ul> <li><code>BatchResult</code> when using multiple prompts or <code>runs &gt; 1</code>.</li> </ul> <code>EvalResult | BatchResult | None</code> <ul> <li><code>None</code> if the test has no russo marker.</li> </ul> Source code in <code>src/russo/pytest_plugin.py</code> <pre><code>@pytest.fixture\nasync def russo_result(\n    request: pytest.FixtureRequest,\n) -&gt; EvalResult | BatchResult | None:\n    \"\"\"Run the russo pipeline based on the ``@pytest.mark.russo`` marker.\n\n    Reads marker kwargs, resolves synthesizer/agent/evaluator fixtures,\n    runs the pipeline, and returns the result.\n\n    Marker kwargs:\n        prompt (str): Single text prompt.\n        prompts (list[str]): Multiple text prompts (runs all concurrently).\n        expect (list): Expected tool calls.\n        runs (int): Number of times to run each prompt (default 1).\n            Falls back to ``--russo-runs`` CLI option.\n        max_concurrency (int | None): Cap on concurrent runs.\n            Falls back to ``--russo-max-concurrency`` CLI option.\n\n    Returns:\n        - ``EvalResult`` for single prompt + single run (backward compatible).\n        - ``BatchResult`` when using multiple prompts or ``runs &gt; 1``.\n        - ``None`` if the test has no russo marker.\n    \"\"\"\n    marker = request.node.get_closest_marker(\"russo\")\n    if marker is None:\n        return None\n\n    # --- extract marker arguments ---\n    prompt: str = marker.kwargs.get(\"prompt\", \"\")\n    if not prompt and marker.args:\n        prompt = marker.args[0]\n\n    prompts: list[str] = list(marker.kwargs.get(\"prompts\", []))\n\n    # runs: marker overrides CLI option, CLI option overrides default 1\n    runs: int = marker.kwargs.get(\"runs\", 0) or request.config.getoption(\"russo_runs\", default=None) or 1\n    max_concurrency: int | None = marker.kwargs.get(\"max_concurrency\") or request.config.getoption(\n        \"russo_max_concurrency\", default=None\n    )\n\n    expect_raw: list[Any] = marker.kwargs.get(\"expect\", [])\n    expect: list[ToolCall] = [tc if isinstance(tc, ToolCall) else ToolCall(**tc) for tc in expect_raw]\n\n    # --- resolve fixtures ---\n    synthesizer = request.getfixturevalue(\"russo_synthesizer\")\n    agent = request.getfixturevalue(\"russo_agent\")\n\n    cache_enabled = request.config.getoption(\"russo_cache\", default=True)\n    if cache_enabled and not isinstance(synthesizer, CachedSynthesizer):\n        cache = request.getfixturevalue(\"russo_audio_cache\")\n        synthesizer = CachedSynthesizer(synthesizer, cache=cache)\n    elif not cache_enabled and isinstance(synthesizer, CachedSynthesizer):\n        synthesizer.enabled = False\n\n    try:\n        evaluator = request.getfixturevalue(\"russo_evaluator\")\n    except pytest.FixtureLookupError:\n        evaluator = ExactEvaluator()\n\n    # --- decide execution mode ---\n    is_batch = bool(prompts) or runs &gt; 1\n\n    if is_batch:\n        effective_prompts = prompts if prompts else [prompt]\n        result: EvalResult | BatchResult = await run_concurrent(\n            prompts=effective_prompts,\n            synthesizer=synthesizer,\n            agent=agent,\n            evaluator=evaluator,\n            expect=expect,\n            runs=runs,\n            max_concurrency=max_concurrency,\n        )\n    else:\n        result = await run(\n            prompt=prompt,\n            synthesizer=synthesizer,\n            agent=agent,\n            evaluator=evaluator,\n            expect=expect,\n        )\n\n    _reporter.add(request.node.nodeid, result)\n    return result\n</code></pre>"},{"location":"reference/pytest-plugin/#russo.pytest_plugin.pytest_terminal_summary","title":"pytest_terminal_summary","text":"<pre><code>pytest_terminal_summary(terminalreporter: Any, exitstatus: int, config: Config) -&gt; None\n</code></pre> <p>Print russo results summary at the end of the test run.</p> Source code in <code>src/russo/pytest_plugin.py</code> <pre><code>def pytest_terminal_summary(\n    terminalreporter: Any,\n    exitstatus: int,  # noqa: ARG001\n    config: pytest.Config,\n) -&gt; None:\n    \"\"\"Print russo results summary at the end of the test run.\"\"\"\n    if _reporter.total == 0:\n        return\n\n    terminalreporter.write_line(_reporter.summary())\n\n    # Write HTML report if requested\n    report_path = config.getoption(\"--russo-report\", default=None)\n    if report_path:\n        _write_html_report(report_path)\n        terminalreporter.write_line(f\"\\nRusso HTML report written to: {report_path}\")\n</code></pre>"},{"location":"reference/pytest-plugin/#russo.pytest_plugin.pytest_sessionfinish","title":"pytest_sessionfinish","text":"<pre><code>pytest_sessionfinish(session: Session, exitstatus: int) -&gt; None\n</code></pre> <p>Reset global reporter state between sessions (relevant for xdist, etc.).</p> Source code in <code>src/russo/pytest_plugin.py</code> <pre><code>def pytest_sessionfinish(session: pytest.Session, exitstatus: int) -&gt; None:  # noqa: ARG001\n    \"\"\"Reset global reporter state between sessions (relevant for xdist, etc.).\"\"\"\n    global _reporter  # noqa: PLW0603\n    _reporter = TerminalReporter()\n</code></pre>"},{"location":"reference/adapters/","title":"Adapters","text":"<p>Built-in agent adapters for different invocation styles.</p>"},{"location":"reference/adapters/#russo.adapters","title":"adapters","text":"<p>Built-in agent adapters for different invocation styles.</p>"},{"location":"reference/adapters/#russo.adapters.GeminiAgent","title":"GeminiAgent","text":"<pre><code>GeminiAgent(*, client: Any, model: str = 'gemini-2.0-flash', tools: list[Any] | None = None, system_instruction: str | None = None, config: Any | None = None)\n</code></pre> <p>Agent adapter that wraps a <code>google.genai.Client</code> object directly.</p> <p>Sends audio to Gemini via <code>client.aio.models.generate_content()</code> and auto-parses function-call responses with :class:<code>GeminiResponseParser</code>.</p> <p>Usage::</p> <pre><code>from google import genai\n\nclient = genai.Client(api_key=\"...\")\nagent = GeminiAgent(\n    client=client,\n    model=\"gemini-2.0-flash\",\n    tools=[book_flight_declaration],\n)\nresponse = await agent.run(audio)\n</code></pre> <p>For Vertex AI::</p> <pre><code>client = genai.Client(vertexai=True, project=\"my-project\", location=\"us-central1\")\nagent = GeminiAgent(client=client, model=\"gemini-2.0-flash\", tools=[...])\n</code></pre> Source code in <code>src/russo/adapters/gemini.py</code> <pre><code>def __init__(\n    self,\n    *,\n    client: Any,\n    model: str = \"gemini-2.0-flash\",\n    tools: list[Any] | None = None,\n    system_instruction: str | None = None,\n    config: Any | None = None,\n) -&gt; None:\n    self.client = client\n    self.model = model\n    self.tools = tools\n    self.system_instruction = system_instruction\n    self.config = config\n    self._parser = GeminiResponseParser()\n</code></pre>"},{"location":"reference/adapters/#russo.adapters.GeminiAgent.run","title":"run  <code>async</code>","text":"<pre><code>run(audio: Audio) -&gt; AgentResponse\n</code></pre> <p>Send audio to Gemini and parse the tool-call response.</p> Source code in <code>src/russo/adapters/gemini.py</code> <pre><code>async def run(self, audio: Audio) -&gt; AgentResponse:\n    \"\"\"Send audio to Gemini and parse the tool-call response.\"\"\"\n    from google.genai import types\n\n    data, mime_type = AudioManager.prepare_for_generate_content(audio)\n    contents = [types.Part.from_bytes(data=data, mime_type=mime_type)]\n    config = self._build_config(types)\n\n    logger.debug(\"Sending %d bytes of %s audio to %s\", len(data), mime_type, self.model)\n\n    response = await self.client.aio.models.generate_content(\n        model=self.model,\n        contents=contents,\n        config=config,\n    )\n    return self._parser.parse(response)\n</code></pre>"},{"location":"reference/adapters/#russo.adapters.GeminiLiveAgent","title":"GeminiLiveAgent","text":"<pre><code>GeminiLiveAgent(*, client: Any | None = None, session: Any | None = None, model: str = 'gemini-live-2.5-flash-native-audio', tools: list[Any] | None = None, system_instruction: str | None = None, config: Any | None = None, response_timeout: float = 30.0)\n</code></pre> <p>Agent adapter for Gemini's Live API (streaming/real-time).</p> <p>Connects via <code>client.aio.live.connect()</code>, sends audio via <code>send_realtime_input</code>, and collects function-call responses.</p> <p>Accepts either a <code>google.genai.Client</code> (new session per run) or a pre-existing Live session.</p> Source code in <code>src/russo/adapters/gemini.py</code> <pre><code>def __init__(\n    self,\n    *,\n    client: Any | None = None,\n    session: Any | None = None,\n    model: str = \"gemini-live-2.5-flash-native-audio\",\n    tools: list[Any] | None = None,\n    system_instruction: str | None = None,\n    config: Any | None = None,\n    response_timeout: float = 30.0,\n) -&gt; None:\n    if client is None and session is None:\n        raise ValueError(\"Provide either 'client' (genai.Client) or 'session' (live session)\")\n    self.client = client\n    self.session = session\n    self.model = model\n    self.tools = tools\n    self.system_instruction = system_instruction\n    self.config = config\n    self.response_timeout = response_timeout\n</code></pre>"},{"location":"reference/adapters/#russo.adapters.GeminiLiveAgent.run","title":"run  <code>async</code>","text":"<pre><code>run(audio: Audio) -&gt; AgentResponse\n</code></pre> <p>Send audio to a Live session and collect function calls.</p> Source code in <code>src/russo/adapters/gemini.py</code> <pre><code>async def run(self, audio: Audio) -&gt; AgentResponse:\n    \"\"\"Send audio to a Live session and collect function calls.\"\"\"\n    if self.session is not None:\n        return await self._run_on(self.session, audio)\n\n    from google.genai import types\n\n    assert self.client is not None\n    config = self._build_config(types)\n    async with self.client.aio.live.connect(model=self.model, config=config) as session:\n        return await self._run_on(session, audio)\n</code></pre>"},{"location":"reference/adapters/#russo.adapters.HttpAgent","title":"HttpAgent","text":"<pre><code>HttpAgent(*, url: str, parser: ResponseParser | None = None, method: str = 'POST', headers: dict[str, str] | None = None, audio_field: str = 'audio', format_field: str = 'format', timeout: float = 60.0)\n</code></pre> <p>Agent adapter that sends audio to an HTTP endpoint.</p> <p>Sends audio as base64-encoded JSON and parses the response using an optional ResponseParser.</p> Usage <p>agent = HttpAgent(     url=\"http://localhost:8000/voice-agent\",     parser=russo.parsers.GeminiResponseParser(), ) response = await agent.run(audio)</p> Source code in <code>src/russo/adapters/http.py</code> <pre><code>def __init__(\n    self,\n    *,\n    url: str,\n    parser: ResponseParser | None = None,\n    method: str = \"POST\",\n    headers: dict[str, str] | None = None,\n    audio_field: str = \"audio\",\n    format_field: str = \"format\",\n    timeout: float = 60.0,\n) -&gt; None:\n    self.url = url\n    self.parser = parser\n    self.method = method\n    self.headers = headers or {}\n    self.audio_field = audio_field\n    self.format_field = format_field\n    self.timeout = timeout\n</code></pre>"},{"location":"reference/adapters/#russo.adapters.HttpAgent.run","title":"run  <code>async</code>","text":"<pre><code>run(audio: Audio) -&gt; AgentResponse\n</code></pre> <p>Send audio to the HTTP endpoint and parse the response.</p> Source code in <code>src/russo/adapters/http.py</code> <pre><code>async def run(self, audio: Audio) -&gt; AgentResponse:\n    \"\"\"Send audio to the HTTP endpoint and parse the response.\"\"\"\n    payload = {\n        self.audio_field: base64.b64encode(audio.data).decode(\"ascii\"),\n        self.format_field: audio.format,\n    }\n\n    raw_response = await self._send(payload)\n\n    if self.parser:\n        return self.parser.parse(raw_response)\n\n    return self._default_parse(raw_response)\n</code></pre>"},{"location":"reference/adapters/#russo.adapters.OpenAIAgent","title":"OpenAIAgent","text":"<pre><code>OpenAIAgent(*, client: Any, model: str = 'gpt-4o-audio-preview', tools: list[Any] | None = None, system_prompt: str | None = None, extra_create_kwargs: dict[str, Any] | None = None)\n</code></pre> <p>Agent adapter that wraps an <code>AsyncOpenAI</code> client for Chat Completions.</p> <p>Sends audio via the Chat Completions API and auto-parses tool-call responses with :class:<code>OpenAIResponseParser</code>.</p> <p>Usage::</p> <pre><code>from openai import AsyncOpenAI\n\nclient = AsyncOpenAI()\nagent = OpenAIAgent(\n    client=client,\n    model=\"gpt-4o-audio-preview\",\n    tools=[{\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"book_flight\",\n            \"parameters\": {\"type\": \"object\", \"properties\": {...}},\n        },\n    }],\n)\nresponse = await agent.run(audio)\n</code></pre> PARAMETER DESCRIPTION <code>client</code> <p>An <code>openai.AsyncOpenAI</code> instance.</p> <p> TYPE: <code>Any</code> </p> <code>model</code> <p>Model name supporting audio input.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'gpt-4o-audio-preview'</code> </p> <code>tools</code> <p>OpenAI tool definitions (function-calling format).</p> <p> TYPE: <code>list[Any] | None</code> DEFAULT: <code>None</code> </p> <code>system_prompt</code> <p>Optional system message prepended to the conversation.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>extra_create_kwargs</code> <p>Additional kwargs forwarded to <code>client.chat.completions.create()</code>.</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> Source code in <code>src/russo/adapters/openai.py</code> <pre><code>def __init__(\n    self,\n    *,\n    client: Any,\n    model: str = \"gpt-4o-audio-preview\",\n    tools: list[Any] | None = None,\n    system_prompt: str | None = None,\n    extra_create_kwargs: dict[str, Any] | None = None,\n) -&gt; None:\n    \"\"\"\n    Args:\n        client: An ``openai.AsyncOpenAI`` instance.\n        model: Model name supporting audio input.\n        tools: OpenAI tool definitions (function-calling format).\n        system_prompt: Optional system message prepended to the conversation.\n        extra_create_kwargs: Additional kwargs forwarded to\n            ``client.chat.completions.create()``.\n    \"\"\"\n    self.client = client\n    self.model = model\n    self.tools = tools\n    self.system_prompt = system_prompt\n    self.extra_create_kwargs = extra_create_kwargs or {}\n    self._parser = OpenAIResponseParser()\n</code></pre>"},{"location":"reference/adapters/#russo.adapters.OpenAIAgent.run","title":"run  <code>async</code>","text":"<pre><code>run(audio: Audio) -&gt; AgentResponse\n</code></pre> <p>Send audio via Chat Completions and parse the tool-call response.</p> Source code in <code>src/russo/adapters/openai.py</code> <pre><code>async def run(self, audio: Audio) -&gt; AgentResponse:\n    \"\"\"Send audio via Chat Completions and parse the tool-call response.\"\"\"\n    audio_b64 = base64.b64encode(audio.data).decode(\"ascii\")\n\n    messages: list[dict[str, Any]] = []\n    if self.system_prompt:\n        messages.append({\"role\": \"system\", \"content\": self.system_prompt})\n\n    messages.append(\n        {\n            \"role\": \"user\",\n            \"content\": [\n                {\n                    \"type\": \"input_audio\",\n                    \"input_audio\": {\"data\": audio_b64, \"format\": audio.format},\n                }\n            ],\n        }\n    )\n\n    kwargs: dict[str, Any] = {\n        \"model\": self.model,\n        \"messages\": messages,\n        **self.extra_create_kwargs,\n    }\n    if self.tools:\n        kwargs[\"tools\"] = self.tools\n\n    logger.debug(\n        \"Sending %d bytes of %s audio to %s\",\n        len(audio.data),\n        audio.format,\n        self.model,\n    )\n\n    response = await self.client.chat.completions.create(**kwargs)\n    return self._parser.parse(response)\n</code></pre>"},{"location":"reference/adapters/#russo.adapters.OpenAIRealtimeAgent","title":"OpenAIRealtimeAgent","text":"<pre><code>OpenAIRealtimeAgent(*, client: Any | None = None, connection: Any | None = None, model: str = 'gpt-4o-realtime-preview', tools: list[Any] | None = None, response_timeout: float = 30.0)\n</code></pre> <p>Agent adapter for OpenAI's Realtime API.</p> <p>Connects via the SDK's <code>client.beta.realtime.connect()</code> interface, sends audio, and collects <code>response.function_call_arguments.done</code> events.</p> <p>Accepts either:</p> <ul> <li>An <code>AsyncOpenAI</code> client (creates a new connection per <code>run()</code>)</li> <li>A pre-existing realtime connection (reuses it, no session config sent)</li> </ul> <p>Usage with client::</p> <pre><code>from openai import AsyncOpenAI\n\nclient = AsyncOpenAI()\nagent = OpenAIRealtimeAgent(\n    client=client,\n    model=\"gpt-4o-realtime-preview\",\n    tools=[{\n        \"type\": \"function\",\n        \"name\": \"book_flight\",\n        \"description\": \"Book a flight\",\n        \"parameters\": {\"type\": \"object\", \"properties\": {...}},\n    }],\n)\nresponse = await agent.run(audio)\n</code></pre> <p>Usage with pre-existing connection::</p> <pre><code>async with client.beta.realtime.connect(model=\"gpt-4o-realtime-preview\") as conn:\n    agent = OpenAIRealtimeAgent(connection=conn)\n    response = await agent.run(audio)\n</code></pre> Note <p>The Realtime API expects pcm16 audio at 24 kHz mono by default. If you pass WAV audio, the adapter automatically strips the WAV header to extract raw PCM frames.</p> PARAMETER DESCRIPTION <code>client</code> <p>An <code>openai.AsyncOpenAI</code> instance. Mutually preferred with connection.</p> <p> TYPE: <code>Any | None</code> DEFAULT: <code>None</code> </p> <code>connection</code> <p>A pre-existing realtime connection (from <code>client.beta.realtime.connect()</code>).</p> <p> TYPE: <code>Any | None</code> DEFAULT: <code>None</code> </p> <code>model</code> <p>Realtime model name.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'gpt-4o-realtime-preview'</code> </p> <code>tools</code> <p>Tool definitions sent during session configuration.</p> <p> TYPE: <code>list[Any] | None</code> DEFAULT: <code>None</code> </p> <code>response_timeout</code> <p>Max seconds to wait for a complete response.</p> <p> TYPE: <code>float</code> DEFAULT: <code>30.0</code> </p> Source code in <code>src/russo/adapters/openai.py</code> <pre><code>def __init__(\n    self,\n    *,\n    client: Any | None = None,\n    connection: Any | None = None,\n    model: str = \"gpt-4o-realtime-preview\",\n    tools: list[Any] | None = None,\n    response_timeout: float = 30.0,\n) -&gt; None:\n    \"\"\"\n    Args:\n        client: An ``openai.AsyncOpenAI`` instance. Mutually preferred with *connection*.\n        connection: A pre-existing realtime connection (from ``client.beta.realtime.connect()``).\n        model: Realtime model name.\n        tools: Tool definitions sent during session configuration.\n        response_timeout: Max seconds to wait for a complete response.\n    \"\"\"\n    if client is None and connection is None:\n        msg = \"Provide either 'client' (AsyncOpenAI) or 'connection' (realtime connection)\"\n        raise ValueError(msg)\n    self.client = client\n    self.connection = connection\n    self.model = model\n    self.tools = tools\n    self.response_timeout = response_timeout\n</code></pre>"},{"location":"reference/adapters/#russo.adapters.OpenAIRealtimeAgent.run","title":"run  <code>async</code>","text":"<pre><code>run(audio: Audio) -&gt; AgentResponse\n</code></pre> <p>Send audio via the Realtime API and collect function calls.</p> Source code in <code>src/russo/adapters/openai.py</code> <pre><code>async def run(self, audio: Audio) -&gt; AgentResponse:\n    \"\"\"Send audio via the Realtime API and collect function calls.\"\"\"\n    if self.connection is not None:\n        return await self._run_on(self.connection, audio, configure=False)\n\n    async with self.client.beta.realtime.connect(model=self.model) as conn:\n        return await self._run_on(conn, audio, configure=True)\n</code></pre>"},{"location":"reference/adapters/#russo.adapters.WebSocketAgent","title":"WebSocketAgent","text":"<pre><code>WebSocketAgent(*, url: str, parser: ResponseParser | None = None, headers: dict[str, str] | None = None, send_bytes: bool = False, audio_field: str = 'audio', format_field: str = 'format', response_timeout: float = 30.0, max_messages: int = 100, on_send: Callable[[Audio], str | bytes] | None = None, is_complete: Callable[[list[Any]], bool] | None = None, aggregate: Callable[[list[Any]], Any] | None = None, open_timeout: float = 10.0, close_timeout: float = 5.0, extra_ws_kwargs: dict[str, Any] | None = None)\n</code></pre> <p>Agent adapter that communicates over WebSocket.</p> <p>Connects to the endpoint, sends audio, collects response messages until a completion condition is met, then parses tool calls.</p> <p>Supports two send modes: - json (default): sends <code>{\"audio\": \"&lt;base64&gt;\", \"format\": \"wav\"}</code> - bytes: sends raw audio bytes directly on the wire</p> <p>And two ways to customize the protocol: - on_send: transform the Audio into whatever your server expects - is_complete: decide when to stop collecting response messages</p> Usage Source code in <code>src/russo/adapters/websocket.py</code> <pre><code>def __init__(\n    self,\n    *,\n    url: str,\n    parser: ResponseParser | None = None,\n    headers: dict[str, str] | None = None,\n    # Send options\n    send_bytes: bool = False,\n    audio_field: str = \"audio\",\n    format_field: str = \"format\",\n    # Response collection\n    response_timeout: float = 30.0,\n    max_messages: int = 100,\n    # Hooks\n    on_send: Callable[[Audio], str | bytes] | None = None,\n    is_complete: Callable[[list[Any]], bool] | None = None,\n    aggregate: Callable[[list[Any]], Any] | None = None,\n    # Connection\n    open_timeout: float = 10.0,\n    close_timeout: float = 5.0,\n    extra_ws_kwargs: dict[str, Any] | None = None,\n) -&gt; None:\n    if not _HAS_WEBSOCKETS:\n        msg = \"WebSocketAgent requires the 'websockets' package. Install with: pip install russo[ws]\"\n        raise ImportError(msg)\n\n    self.url = url\n    self.parser = parser\n    self.headers = headers or {}\n    self.send_bytes = send_bytes\n    self.audio_field = audio_field\n    self.format_field = format_field\n    self.response_timeout = response_timeout\n    self.max_messages = max_messages\n    self.on_send = on_send\n    self.is_complete = is_complete\n    self.aggregate = aggregate\n    self.open_timeout = open_timeout\n    self.close_timeout = close_timeout\n    self.extra_ws_kwargs = extra_ws_kwargs or {}\n</code></pre>"},{"location":"reference/adapters/#russo.adapters.WebSocketAgent--simple-json-protocol","title":"Simple JSON protocol","text":"<p>agent = WebSocketAgent(     url=\"ws://localhost:8000/ws/agent\",     parser=russo.parsers.GeminiResponseParser(), )</p>"},{"location":"reference/adapters/#russo.adapters.WebSocketAgent--raw-bytes-protocol-eg-streaming-pcm","title":"Raw bytes protocol (e.g. streaming PCM)","text":"<p>agent = WebSocketAgent(     url=\"ws://localhost:8000/ws/agent\",     send_bytes=True, )</p>"},{"location":"reference/adapters/#russo.adapters.WebSocketAgent--fully-custom-sendreceive","title":"Fully custom send/receive","text":"<p>agent = WebSocketAgent(     url=\"ws://localhost:8000/ws/agent\",     on_send=lambda audio: json.dumps({\"pcm\": base64.b64encode(audio.data).decode()}),     is_complete=lambda msgs: any('\"done\": true' in str(m) for m in msgs), )</p>"},{"location":"reference/adapters/#russo.adapters.WebSocketAgent.run","title":"run  <code>async</code>","text":"<pre><code>run(audio: Audio) -&gt; AgentResponse\n</code></pre> <p>Send audio over WebSocket and collect the response.</p> Source code in <code>src/russo/adapters/websocket.py</code> <pre><code>async def run(self, audio: Audio) -&gt; AgentResponse:\n    \"\"\"Send audio over WebSocket and collect the response.\"\"\"\n    import websockets\n\n    async with websockets.connect(\n        self.url,\n        additional_headers=self.headers or None,\n        open_timeout=self.open_timeout,\n        close_timeout=self.close_timeout,\n        **self.extra_ws_kwargs,\n    ) as ws:\n        # --- Send ---\n        message = self._prepare_message(audio)\n        if isinstance(message, bytes):\n            await ws.send(message)\n        else:\n            await ws.send(message)\n        logger.debug(\n            \"Sent %s message (%d bytes)\",\n            \"binary\" if isinstance(message, bytes) else \"text\",\n            len(message),\n        )\n\n        # --- Collect responses ---\n        messages = await self._collect_responses(ws)\n        logger.debug(\"Collected %d response messages\", len(messages))\n\n    # --- Parse ---\n    raw = self._aggregate(messages)\n\n    if self.parser:\n        return self.parser.parse(raw)\n    return self._default_parse(raw)\n</code></pre>"},{"location":"reference/adapters/#russo.adapters.callable","title":"callable","text":"<p>Callable agent adapter \u2014 wraps async functions as Agents.</p> <p>Re-exports from _helpers for organizational clarity. The actual implementation lives in russo._helpers to keep the public API flat (russo.agent decorator).</p>"},{"location":"reference/adapters/#russo.adapters.callable.agent","title":"agent","text":"<pre><code>agent(fn: Callable[[Audio], Coroutine[Any, Any, AgentResponse]]) -&gt; _CallableAgent\n</code></pre> <p>Decorator to turn an async function into an Agent.</p> Usage <p>@russo.agent async def my_agent(audio: russo.Audio) -&gt; russo.AgentResponse:     result = await call_my_api(audio.data)     return russo.AgentResponse(tool_calls=[...])</p> Source code in <code>src/russo/_helpers.py</code> <pre><code>def agent(fn: Callable[[Audio], Coroutine[Any, Any, AgentResponse]]) -&gt; _CallableAgent:\n    \"\"\"Decorator to turn an async function into an Agent.\n\n    Usage:\n        @russo.agent\n        async def my_agent(audio: russo.Audio) -&gt; russo.AgentResponse:\n            result = await call_my_api(audio.data)\n            return russo.AgentResponse(tool_calls=[...])\n    \"\"\"\n    return _CallableAgent(fn)\n</code></pre>"},{"location":"reference/adapters/#russo.adapters.gemini","title":"gemini","text":"<p>Gemini SDK agent adapters \u2014 wraps a google-genai Client as an Agent.</p> <p>Provides two adapters:</p> <ul> <li>GeminiAgent: standard <code>generate_content</code> (request/response)</li> <li>GeminiLiveAgent: Live API over WebSocket (streaming/real-time)</li> </ul> <p>Send audio directly to a Gemini model via the SDK, no HTTP endpoint needed. Requires the <code>google-genai</code> package (already a core dependency).</p>"},{"location":"reference/adapters/#russo.adapters.gemini.GeminiAgent","title":"GeminiAgent","text":"<pre><code>GeminiAgent(*, client: Any, model: str = 'gemini-2.0-flash', tools: list[Any] | None = None, system_instruction: str | None = None, config: Any | None = None)\n</code></pre> <p>Agent adapter that wraps a <code>google.genai.Client</code> object directly.</p> <p>Sends audio to Gemini via <code>client.aio.models.generate_content()</code> and auto-parses function-call responses with :class:<code>GeminiResponseParser</code>.</p> <p>Usage::</p> <pre><code>from google import genai\n\nclient = genai.Client(api_key=\"...\")\nagent = GeminiAgent(\n    client=client,\n    model=\"gemini-2.0-flash\",\n    tools=[book_flight_declaration],\n)\nresponse = await agent.run(audio)\n</code></pre> <p>For Vertex AI::</p> <pre><code>client = genai.Client(vertexai=True, project=\"my-project\", location=\"us-central1\")\nagent = GeminiAgent(client=client, model=\"gemini-2.0-flash\", tools=[...])\n</code></pre> Source code in <code>src/russo/adapters/gemini.py</code> <pre><code>def __init__(\n    self,\n    *,\n    client: Any,\n    model: str = \"gemini-2.0-flash\",\n    tools: list[Any] | None = None,\n    system_instruction: str | None = None,\n    config: Any | None = None,\n) -&gt; None:\n    self.client = client\n    self.model = model\n    self.tools = tools\n    self.system_instruction = system_instruction\n    self.config = config\n    self._parser = GeminiResponseParser()\n</code></pre>"},{"location":"reference/adapters/#russo.adapters.gemini.GeminiAgent.run","title":"run  <code>async</code>","text":"<pre><code>run(audio: Audio) -&gt; AgentResponse\n</code></pre> <p>Send audio to Gemini and parse the tool-call response.</p> Source code in <code>src/russo/adapters/gemini.py</code> <pre><code>async def run(self, audio: Audio) -&gt; AgentResponse:\n    \"\"\"Send audio to Gemini and parse the tool-call response.\"\"\"\n    from google.genai import types\n\n    data, mime_type = AudioManager.prepare_for_generate_content(audio)\n    contents = [types.Part.from_bytes(data=data, mime_type=mime_type)]\n    config = self._build_config(types)\n\n    logger.debug(\"Sending %d bytes of %s audio to %s\", len(data), mime_type, self.model)\n\n    response = await self.client.aio.models.generate_content(\n        model=self.model,\n        contents=contents,\n        config=config,\n    )\n    return self._parser.parse(response)\n</code></pre>"},{"location":"reference/adapters/#russo.adapters.gemini.GeminiLiveAgent","title":"GeminiLiveAgent","text":"<pre><code>GeminiLiveAgent(*, client: Any | None = None, session: Any | None = None, model: str = 'gemini-live-2.5-flash-native-audio', tools: list[Any] | None = None, system_instruction: str | None = None, config: Any | None = None, response_timeout: float = 30.0)\n</code></pre> <p>Agent adapter for Gemini's Live API (streaming/real-time).</p> <p>Connects via <code>client.aio.live.connect()</code>, sends audio via <code>send_realtime_input</code>, and collects function-call responses.</p> <p>Accepts either a <code>google.genai.Client</code> (new session per run) or a pre-existing Live session.</p> Source code in <code>src/russo/adapters/gemini.py</code> <pre><code>def __init__(\n    self,\n    *,\n    client: Any | None = None,\n    session: Any | None = None,\n    model: str = \"gemini-live-2.5-flash-native-audio\",\n    tools: list[Any] | None = None,\n    system_instruction: str | None = None,\n    config: Any | None = None,\n    response_timeout: float = 30.0,\n) -&gt; None:\n    if client is None and session is None:\n        raise ValueError(\"Provide either 'client' (genai.Client) or 'session' (live session)\")\n    self.client = client\n    self.session = session\n    self.model = model\n    self.tools = tools\n    self.system_instruction = system_instruction\n    self.config = config\n    self.response_timeout = response_timeout\n</code></pre>"},{"location":"reference/adapters/#russo.adapters.gemini.GeminiLiveAgent.run","title":"run  <code>async</code>","text":"<pre><code>run(audio: Audio) -&gt; AgentResponse\n</code></pre> <p>Send audio to a Live session and collect function calls.</p> Source code in <code>src/russo/adapters/gemini.py</code> <pre><code>async def run(self, audio: Audio) -&gt; AgentResponse:\n    \"\"\"Send audio to a Live session and collect function calls.\"\"\"\n    if self.session is not None:\n        return await self._run_on(self.session, audio)\n\n    from google.genai import types\n\n    assert self.client is not None\n    config = self._build_config(types)\n    async with self.client.aio.live.connect(model=self.model, config=config) as session:\n        return await self._run_on(session, audio)\n</code></pre>"},{"location":"reference/adapters/#russo.adapters.http","title":"http","text":"<p>HTTP agent adapter \u2014 sends audio to an API endpoint.</p>"},{"location":"reference/adapters/#russo.adapters.http.HttpAgent","title":"HttpAgent","text":"<pre><code>HttpAgent(*, url: str, parser: ResponseParser | None = None, method: str = 'POST', headers: dict[str, str] | None = None, audio_field: str = 'audio', format_field: str = 'format', timeout: float = 60.0)\n</code></pre> <p>Agent adapter that sends audio to an HTTP endpoint.</p> <p>Sends audio as base64-encoded JSON and parses the response using an optional ResponseParser.</p> Usage <p>agent = HttpAgent(     url=\"http://localhost:8000/voice-agent\",     parser=russo.parsers.GeminiResponseParser(), ) response = await agent.run(audio)</p> Source code in <code>src/russo/adapters/http.py</code> <pre><code>def __init__(\n    self,\n    *,\n    url: str,\n    parser: ResponseParser | None = None,\n    method: str = \"POST\",\n    headers: dict[str, str] | None = None,\n    audio_field: str = \"audio\",\n    format_field: str = \"format\",\n    timeout: float = 60.0,\n) -&gt; None:\n    self.url = url\n    self.parser = parser\n    self.method = method\n    self.headers = headers or {}\n    self.audio_field = audio_field\n    self.format_field = format_field\n    self.timeout = timeout\n</code></pre>"},{"location":"reference/adapters/#russo.adapters.http.HttpAgent.run","title":"run  <code>async</code>","text":"<pre><code>run(audio: Audio) -&gt; AgentResponse\n</code></pre> <p>Send audio to the HTTP endpoint and parse the response.</p> Source code in <code>src/russo/adapters/http.py</code> <pre><code>async def run(self, audio: Audio) -&gt; AgentResponse:\n    \"\"\"Send audio to the HTTP endpoint and parse the response.\"\"\"\n    payload = {\n        self.audio_field: base64.b64encode(audio.data).decode(\"ascii\"),\n        self.format_field: audio.format,\n    }\n\n    raw_response = await self._send(payload)\n\n    if self.parser:\n        return self.parser.parse(raw_response)\n\n    return self._default_parse(raw_response)\n</code></pre>"},{"location":"reference/adapters/#russo.adapters.openai","title":"openai","text":"<p>OpenAI SDK agent adapters \u2014 wraps OpenAI clients as Agents.</p> <p>Provides two adapters:</p> <ul> <li>OpenAIAgent: standard Chat Completions with audio input   (<code>gpt-4o-audio-preview</code> and similar models)</li> <li>OpenAIRealtimeAgent: Realtime API over WebSocket   (<code>gpt-4o-realtime-preview</code>)</li> </ul> <p>Requires the <code>openai</code> package: <code>pip install russo[openai]</code></p>"},{"location":"reference/adapters/#russo.adapters.openai.OpenAIAgent","title":"OpenAIAgent","text":"<pre><code>OpenAIAgent(*, client: Any, model: str = 'gpt-4o-audio-preview', tools: list[Any] | None = None, system_prompt: str | None = None, extra_create_kwargs: dict[str, Any] | None = None)\n</code></pre> <p>Agent adapter that wraps an <code>AsyncOpenAI</code> client for Chat Completions.</p> <p>Sends audio via the Chat Completions API and auto-parses tool-call responses with :class:<code>OpenAIResponseParser</code>.</p> <p>Usage::</p> <pre><code>from openai import AsyncOpenAI\n\nclient = AsyncOpenAI()\nagent = OpenAIAgent(\n    client=client,\n    model=\"gpt-4o-audio-preview\",\n    tools=[{\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"book_flight\",\n            \"parameters\": {\"type\": \"object\", \"properties\": {...}},\n        },\n    }],\n)\nresponse = await agent.run(audio)\n</code></pre> PARAMETER DESCRIPTION <code>client</code> <p>An <code>openai.AsyncOpenAI</code> instance.</p> <p> TYPE: <code>Any</code> </p> <code>model</code> <p>Model name supporting audio input.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'gpt-4o-audio-preview'</code> </p> <code>tools</code> <p>OpenAI tool definitions (function-calling format).</p> <p> TYPE: <code>list[Any] | None</code> DEFAULT: <code>None</code> </p> <code>system_prompt</code> <p>Optional system message prepended to the conversation.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>extra_create_kwargs</code> <p>Additional kwargs forwarded to <code>client.chat.completions.create()</code>.</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> Source code in <code>src/russo/adapters/openai.py</code> <pre><code>def __init__(\n    self,\n    *,\n    client: Any,\n    model: str = \"gpt-4o-audio-preview\",\n    tools: list[Any] | None = None,\n    system_prompt: str | None = None,\n    extra_create_kwargs: dict[str, Any] | None = None,\n) -&gt; None:\n    \"\"\"\n    Args:\n        client: An ``openai.AsyncOpenAI`` instance.\n        model: Model name supporting audio input.\n        tools: OpenAI tool definitions (function-calling format).\n        system_prompt: Optional system message prepended to the conversation.\n        extra_create_kwargs: Additional kwargs forwarded to\n            ``client.chat.completions.create()``.\n    \"\"\"\n    self.client = client\n    self.model = model\n    self.tools = tools\n    self.system_prompt = system_prompt\n    self.extra_create_kwargs = extra_create_kwargs or {}\n    self._parser = OpenAIResponseParser()\n</code></pre>"},{"location":"reference/adapters/#russo.adapters.openai.OpenAIAgent.run","title":"run  <code>async</code>","text":"<pre><code>run(audio: Audio) -&gt; AgentResponse\n</code></pre> <p>Send audio via Chat Completions and parse the tool-call response.</p> Source code in <code>src/russo/adapters/openai.py</code> <pre><code>async def run(self, audio: Audio) -&gt; AgentResponse:\n    \"\"\"Send audio via Chat Completions and parse the tool-call response.\"\"\"\n    audio_b64 = base64.b64encode(audio.data).decode(\"ascii\")\n\n    messages: list[dict[str, Any]] = []\n    if self.system_prompt:\n        messages.append({\"role\": \"system\", \"content\": self.system_prompt})\n\n    messages.append(\n        {\n            \"role\": \"user\",\n            \"content\": [\n                {\n                    \"type\": \"input_audio\",\n                    \"input_audio\": {\"data\": audio_b64, \"format\": audio.format},\n                }\n            ],\n        }\n    )\n\n    kwargs: dict[str, Any] = {\n        \"model\": self.model,\n        \"messages\": messages,\n        **self.extra_create_kwargs,\n    }\n    if self.tools:\n        kwargs[\"tools\"] = self.tools\n\n    logger.debug(\n        \"Sending %d bytes of %s audio to %s\",\n        len(audio.data),\n        audio.format,\n        self.model,\n    )\n\n    response = await self.client.chat.completions.create(**kwargs)\n    return self._parser.parse(response)\n</code></pre>"},{"location":"reference/adapters/#russo.adapters.openai.OpenAIRealtimeAgent","title":"OpenAIRealtimeAgent","text":"<pre><code>OpenAIRealtimeAgent(*, client: Any | None = None, connection: Any | None = None, model: str = 'gpt-4o-realtime-preview', tools: list[Any] | None = None, response_timeout: float = 30.0)\n</code></pre> <p>Agent adapter for OpenAI's Realtime API.</p> <p>Connects via the SDK's <code>client.beta.realtime.connect()</code> interface, sends audio, and collects <code>response.function_call_arguments.done</code> events.</p> <p>Accepts either:</p> <ul> <li>An <code>AsyncOpenAI</code> client (creates a new connection per <code>run()</code>)</li> <li>A pre-existing realtime connection (reuses it, no session config sent)</li> </ul> <p>Usage with client::</p> <pre><code>from openai import AsyncOpenAI\n\nclient = AsyncOpenAI()\nagent = OpenAIRealtimeAgent(\n    client=client,\n    model=\"gpt-4o-realtime-preview\",\n    tools=[{\n        \"type\": \"function\",\n        \"name\": \"book_flight\",\n        \"description\": \"Book a flight\",\n        \"parameters\": {\"type\": \"object\", \"properties\": {...}},\n    }],\n)\nresponse = await agent.run(audio)\n</code></pre> <p>Usage with pre-existing connection::</p> <pre><code>async with client.beta.realtime.connect(model=\"gpt-4o-realtime-preview\") as conn:\n    agent = OpenAIRealtimeAgent(connection=conn)\n    response = await agent.run(audio)\n</code></pre> Note <p>The Realtime API expects pcm16 audio at 24 kHz mono by default. If you pass WAV audio, the adapter automatically strips the WAV header to extract raw PCM frames.</p> PARAMETER DESCRIPTION <code>client</code> <p>An <code>openai.AsyncOpenAI</code> instance. Mutually preferred with connection.</p> <p> TYPE: <code>Any | None</code> DEFAULT: <code>None</code> </p> <code>connection</code> <p>A pre-existing realtime connection (from <code>client.beta.realtime.connect()</code>).</p> <p> TYPE: <code>Any | None</code> DEFAULT: <code>None</code> </p> <code>model</code> <p>Realtime model name.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'gpt-4o-realtime-preview'</code> </p> <code>tools</code> <p>Tool definitions sent during session configuration.</p> <p> TYPE: <code>list[Any] | None</code> DEFAULT: <code>None</code> </p> <code>response_timeout</code> <p>Max seconds to wait for a complete response.</p> <p> TYPE: <code>float</code> DEFAULT: <code>30.0</code> </p> Source code in <code>src/russo/adapters/openai.py</code> <pre><code>def __init__(\n    self,\n    *,\n    client: Any | None = None,\n    connection: Any | None = None,\n    model: str = \"gpt-4o-realtime-preview\",\n    tools: list[Any] | None = None,\n    response_timeout: float = 30.0,\n) -&gt; None:\n    \"\"\"\n    Args:\n        client: An ``openai.AsyncOpenAI`` instance. Mutually preferred with *connection*.\n        connection: A pre-existing realtime connection (from ``client.beta.realtime.connect()``).\n        model: Realtime model name.\n        tools: Tool definitions sent during session configuration.\n        response_timeout: Max seconds to wait for a complete response.\n    \"\"\"\n    if client is None and connection is None:\n        msg = \"Provide either 'client' (AsyncOpenAI) or 'connection' (realtime connection)\"\n        raise ValueError(msg)\n    self.client = client\n    self.connection = connection\n    self.model = model\n    self.tools = tools\n    self.response_timeout = response_timeout\n</code></pre>"},{"location":"reference/adapters/#russo.adapters.openai.OpenAIRealtimeAgent.run","title":"run  <code>async</code>","text":"<pre><code>run(audio: Audio) -&gt; AgentResponse\n</code></pre> <p>Send audio via the Realtime API and collect function calls.</p> Source code in <code>src/russo/adapters/openai.py</code> <pre><code>async def run(self, audio: Audio) -&gt; AgentResponse:\n    \"\"\"Send audio via the Realtime API and collect function calls.\"\"\"\n    if self.connection is not None:\n        return await self._run_on(self.connection, audio, configure=False)\n\n    async with self.client.beta.realtime.connect(model=self.model) as conn:\n        return await self._run_on(conn, audio, configure=True)\n</code></pre>"},{"location":"reference/adapters/#russo.adapters.websocket","title":"websocket","text":"<p>WebSocket agent adapter \u2014 sends audio to a WebSocket endpoint.</p> <p>Requires the <code>websockets</code> package: pip install russo[ws]</p>"},{"location":"reference/adapters/#russo.adapters.websocket.WebSocketAgent","title":"WebSocketAgent","text":"<pre><code>WebSocketAgent(*, url: str, parser: ResponseParser | None = None, headers: dict[str, str] | None = None, send_bytes: bool = False, audio_field: str = 'audio', format_field: str = 'format', response_timeout: float = 30.0, max_messages: int = 100, on_send: Callable[[Audio], str | bytes] | None = None, is_complete: Callable[[list[Any]], bool] | None = None, aggregate: Callable[[list[Any]], Any] | None = None, open_timeout: float = 10.0, close_timeout: float = 5.0, extra_ws_kwargs: dict[str, Any] | None = None)\n</code></pre> <p>Agent adapter that communicates over WebSocket.</p> <p>Connects to the endpoint, sends audio, collects response messages until a completion condition is met, then parses tool calls.</p> <p>Supports two send modes: - json (default): sends <code>{\"audio\": \"&lt;base64&gt;\", \"format\": \"wav\"}</code> - bytes: sends raw audio bytes directly on the wire</p> <p>And two ways to customize the protocol: - on_send: transform the Audio into whatever your server expects - is_complete: decide when to stop collecting response messages</p> Usage Source code in <code>src/russo/adapters/websocket.py</code> <pre><code>def __init__(\n    self,\n    *,\n    url: str,\n    parser: ResponseParser | None = None,\n    headers: dict[str, str] | None = None,\n    # Send options\n    send_bytes: bool = False,\n    audio_field: str = \"audio\",\n    format_field: str = \"format\",\n    # Response collection\n    response_timeout: float = 30.0,\n    max_messages: int = 100,\n    # Hooks\n    on_send: Callable[[Audio], str | bytes] | None = None,\n    is_complete: Callable[[list[Any]], bool] | None = None,\n    aggregate: Callable[[list[Any]], Any] | None = None,\n    # Connection\n    open_timeout: float = 10.0,\n    close_timeout: float = 5.0,\n    extra_ws_kwargs: dict[str, Any] | None = None,\n) -&gt; None:\n    if not _HAS_WEBSOCKETS:\n        msg = \"WebSocketAgent requires the 'websockets' package. Install with: pip install russo[ws]\"\n        raise ImportError(msg)\n\n    self.url = url\n    self.parser = parser\n    self.headers = headers or {}\n    self.send_bytes = send_bytes\n    self.audio_field = audio_field\n    self.format_field = format_field\n    self.response_timeout = response_timeout\n    self.max_messages = max_messages\n    self.on_send = on_send\n    self.is_complete = is_complete\n    self.aggregate = aggregate\n    self.open_timeout = open_timeout\n    self.close_timeout = close_timeout\n    self.extra_ws_kwargs = extra_ws_kwargs or {}\n</code></pre>"},{"location":"reference/adapters/#russo.adapters.websocket.WebSocketAgent--simple-json-protocol","title":"Simple JSON protocol","text":"<p>agent = WebSocketAgent(     url=\"ws://localhost:8000/ws/agent\",     parser=russo.parsers.GeminiResponseParser(), )</p>"},{"location":"reference/adapters/#russo.adapters.websocket.WebSocketAgent--raw-bytes-protocol-eg-streaming-pcm","title":"Raw bytes protocol (e.g. streaming PCM)","text":"<p>agent = WebSocketAgent(     url=\"ws://localhost:8000/ws/agent\",     send_bytes=True, )</p>"},{"location":"reference/adapters/#russo.adapters.websocket.WebSocketAgent--fully-custom-sendreceive","title":"Fully custom send/receive","text":"<p>agent = WebSocketAgent(     url=\"ws://localhost:8000/ws/agent\",     on_send=lambda audio: json.dumps({\"pcm\": base64.b64encode(audio.data).decode()}),     is_complete=lambda msgs: any('\"done\": true' in str(m) for m in msgs), )</p>"},{"location":"reference/adapters/#russo.adapters.websocket.WebSocketAgent.run","title":"run  <code>async</code>","text":"<pre><code>run(audio: Audio) -&gt; AgentResponse\n</code></pre> <p>Send audio over WebSocket and collect the response.</p> Source code in <code>src/russo/adapters/websocket.py</code> <pre><code>async def run(self, audio: Audio) -&gt; AgentResponse:\n    \"\"\"Send audio over WebSocket and collect the response.\"\"\"\n    import websockets\n\n    async with websockets.connect(\n        self.url,\n        additional_headers=self.headers or None,\n        open_timeout=self.open_timeout,\n        close_timeout=self.close_timeout,\n        **self.extra_ws_kwargs,\n    ) as ws:\n        # --- Send ---\n        message = self._prepare_message(audio)\n        if isinstance(message, bytes):\n            await ws.send(message)\n        else:\n            await ws.send(message)\n        logger.debug(\n            \"Sent %s message (%d bytes)\",\n            \"binary\" if isinstance(message, bytes) else \"text\",\n            len(message),\n        )\n\n        # --- Collect responses ---\n        messages = await self._collect_responses(ws)\n        logger.debug(\"Collected %d response messages\", len(messages))\n\n    # --- Parse ---\n    raw = self._aggregate(messages)\n\n    if self.parser:\n        return self.parser.parse(raw)\n    return self._default_parse(raw)\n</code></pre>"},{"location":"reference/adapters/callable/","title":"Callable Adapter","text":"<p>Callable agent adapter \u2014 wraps async functions as Agents.</p>"},{"location":"reference/adapters/callable/#russo.adapters.callable","title":"callable","text":"<p>Callable agent adapter \u2014 wraps async functions as Agents.</p> <p>Re-exports from _helpers for organizational clarity. The actual implementation lives in russo._helpers to keep the public API flat (russo.agent decorator).</p>"},{"location":"reference/adapters/callable/#russo.adapters.callable.agent","title":"agent","text":"<pre><code>agent(fn: Callable[[Audio], Coroutine[Any, Any, AgentResponse]]) -&gt; _CallableAgent\n</code></pre> <p>Decorator to turn an async function into an Agent.</p> Usage <p>@russo.agent async def my_agent(audio: russo.Audio) -&gt; russo.AgentResponse:     result = await call_my_api(audio.data)     return russo.AgentResponse(tool_calls=[...])</p> Source code in <code>src/russo/_helpers.py</code> <pre><code>def agent(fn: Callable[[Audio], Coroutine[Any, Any, AgentResponse]]) -&gt; _CallableAgent:\n    \"\"\"Decorator to turn an async function into an Agent.\n\n    Usage:\n        @russo.agent\n        async def my_agent(audio: russo.Audio) -&gt; russo.AgentResponse:\n            result = await call_my_api(audio.data)\n            return russo.AgentResponse(tool_calls=[...])\n    \"\"\"\n    return _CallableAgent(fn)\n</code></pre>"},{"location":"reference/adapters/gemini/","title":"Gemini Adapters","text":"<p>Gemini SDK agent adapters \u2014 wraps a <code>google-genai</code> Client as an Agent.</p>"},{"location":"reference/adapters/gemini/#russo.adapters.gemini","title":"gemini","text":"<p>Gemini SDK agent adapters \u2014 wraps a google-genai Client as an Agent.</p> <p>Provides two adapters:</p> <ul> <li>GeminiAgent: standard <code>generate_content</code> (request/response)</li> <li>GeminiLiveAgent: Live API over WebSocket (streaming/real-time)</li> </ul> <p>Send audio directly to a Gemini model via the SDK, no HTTP endpoint needed. Requires the <code>google-genai</code> package (already a core dependency).</p>"},{"location":"reference/adapters/gemini/#russo.adapters.gemini.GeminiAgent","title":"GeminiAgent","text":"<pre><code>GeminiAgent(*, client: Any, model: str = 'gemini-2.0-flash', tools: list[Any] | None = None, system_instruction: str | None = None, config: Any | None = None)\n</code></pre> <p>Agent adapter that wraps a <code>google.genai.Client</code> object directly.</p> <p>Sends audio to Gemini via <code>client.aio.models.generate_content()</code> and auto-parses function-call responses with :class:<code>GeminiResponseParser</code>.</p> <p>Usage::</p> <pre><code>from google import genai\n\nclient = genai.Client(api_key=\"...\")\nagent = GeminiAgent(\n    client=client,\n    model=\"gemini-2.0-flash\",\n    tools=[book_flight_declaration],\n)\nresponse = await agent.run(audio)\n</code></pre> <p>For Vertex AI::</p> <pre><code>client = genai.Client(vertexai=True, project=\"my-project\", location=\"us-central1\")\nagent = GeminiAgent(client=client, model=\"gemini-2.0-flash\", tools=[...])\n</code></pre> Source code in <code>src/russo/adapters/gemini.py</code> <pre><code>def __init__(\n    self,\n    *,\n    client: Any,\n    model: str = \"gemini-2.0-flash\",\n    tools: list[Any] | None = None,\n    system_instruction: str | None = None,\n    config: Any | None = None,\n) -&gt; None:\n    self.client = client\n    self.model = model\n    self.tools = tools\n    self.system_instruction = system_instruction\n    self.config = config\n    self._parser = GeminiResponseParser()\n</code></pre>"},{"location":"reference/adapters/gemini/#russo.adapters.gemini.GeminiAgent.run","title":"run  <code>async</code>","text":"<pre><code>run(audio: Audio) -&gt; AgentResponse\n</code></pre> <p>Send audio to Gemini and parse the tool-call response.</p> Source code in <code>src/russo/adapters/gemini.py</code> <pre><code>async def run(self, audio: Audio) -&gt; AgentResponse:\n    \"\"\"Send audio to Gemini and parse the tool-call response.\"\"\"\n    from google.genai import types\n\n    data, mime_type = AudioManager.prepare_for_generate_content(audio)\n    contents = [types.Part.from_bytes(data=data, mime_type=mime_type)]\n    config = self._build_config(types)\n\n    logger.debug(\"Sending %d bytes of %s audio to %s\", len(data), mime_type, self.model)\n\n    response = await self.client.aio.models.generate_content(\n        model=self.model,\n        contents=contents,\n        config=config,\n    )\n    return self._parser.parse(response)\n</code></pre>"},{"location":"reference/adapters/gemini/#russo.adapters.gemini.GeminiLiveAgent","title":"GeminiLiveAgent","text":"<pre><code>GeminiLiveAgent(*, client: Any | None = None, session: Any | None = None, model: str = 'gemini-live-2.5-flash-native-audio', tools: list[Any] | None = None, system_instruction: str | None = None, config: Any | None = None, response_timeout: float = 30.0)\n</code></pre> <p>Agent adapter for Gemini's Live API (streaming/real-time).</p> <p>Connects via <code>client.aio.live.connect()</code>, sends audio via <code>send_realtime_input</code>, and collects function-call responses.</p> <p>Accepts either a <code>google.genai.Client</code> (new session per run) or a pre-existing Live session.</p> Source code in <code>src/russo/adapters/gemini.py</code> <pre><code>def __init__(\n    self,\n    *,\n    client: Any | None = None,\n    session: Any | None = None,\n    model: str = \"gemini-live-2.5-flash-native-audio\",\n    tools: list[Any] | None = None,\n    system_instruction: str | None = None,\n    config: Any | None = None,\n    response_timeout: float = 30.0,\n) -&gt; None:\n    if client is None and session is None:\n        raise ValueError(\"Provide either 'client' (genai.Client) or 'session' (live session)\")\n    self.client = client\n    self.session = session\n    self.model = model\n    self.tools = tools\n    self.system_instruction = system_instruction\n    self.config = config\n    self.response_timeout = response_timeout\n</code></pre>"},{"location":"reference/adapters/gemini/#russo.adapters.gemini.GeminiLiveAgent.run","title":"run  <code>async</code>","text":"<pre><code>run(audio: Audio) -&gt; AgentResponse\n</code></pre> <p>Send audio to a Live session and collect function calls.</p> Source code in <code>src/russo/adapters/gemini.py</code> <pre><code>async def run(self, audio: Audio) -&gt; AgentResponse:\n    \"\"\"Send audio to a Live session and collect function calls.\"\"\"\n    if self.session is not None:\n        return await self._run_on(self.session, audio)\n\n    from google.genai import types\n\n    assert self.client is not None\n    config = self._build_config(types)\n    async with self.client.aio.live.connect(model=self.model, config=config) as session:\n        return await self._run_on(session, audio)\n</code></pre>"},{"location":"reference/adapters/http/","title":"HTTP Adapter","text":"<p>HTTP agent adapter \u2014 sends audio to an API endpoint.</p>"},{"location":"reference/adapters/http/#russo.adapters.http","title":"http","text":"<p>HTTP agent adapter \u2014 sends audio to an API endpoint.</p>"},{"location":"reference/adapters/http/#russo.adapters.http.HttpAgent","title":"HttpAgent","text":"<pre><code>HttpAgent(*, url: str, parser: ResponseParser | None = None, method: str = 'POST', headers: dict[str, str] | None = None, audio_field: str = 'audio', format_field: str = 'format', timeout: float = 60.0)\n</code></pre> <p>Agent adapter that sends audio to an HTTP endpoint.</p> <p>Sends audio as base64-encoded JSON and parses the response using an optional ResponseParser.</p> Usage <p>agent = HttpAgent(     url=\"http://localhost:8000/voice-agent\",     parser=russo.parsers.GeminiResponseParser(), ) response = await agent.run(audio)</p> Source code in <code>src/russo/adapters/http.py</code> <pre><code>def __init__(\n    self,\n    *,\n    url: str,\n    parser: ResponseParser | None = None,\n    method: str = \"POST\",\n    headers: dict[str, str] | None = None,\n    audio_field: str = \"audio\",\n    format_field: str = \"format\",\n    timeout: float = 60.0,\n) -&gt; None:\n    self.url = url\n    self.parser = parser\n    self.method = method\n    self.headers = headers or {}\n    self.audio_field = audio_field\n    self.format_field = format_field\n    self.timeout = timeout\n</code></pre>"},{"location":"reference/adapters/http/#russo.adapters.http.HttpAgent.run","title":"run  <code>async</code>","text":"<pre><code>run(audio: Audio) -&gt; AgentResponse\n</code></pre> <p>Send audio to the HTTP endpoint and parse the response.</p> Source code in <code>src/russo/adapters/http.py</code> <pre><code>async def run(self, audio: Audio) -&gt; AgentResponse:\n    \"\"\"Send audio to the HTTP endpoint and parse the response.\"\"\"\n    payload = {\n        self.audio_field: base64.b64encode(audio.data).decode(\"ascii\"),\n        self.format_field: audio.format,\n    }\n\n    raw_response = await self._send(payload)\n\n    if self.parser:\n        return self.parser.parse(raw_response)\n\n    return self._default_parse(raw_response)\n</code></pre>"},{"location":"reference/adapters/openai/","title":"OpenAI Adapters","text":"<p>OpenAI SDK agent adapters \u2014 wraps OpenAI clients as Agents.</p> <p>Note</p> <p>Requires the <code>openai</code> extra: <code>pip install \"russo[openai]\"</code></p>"},{"location":"reference/adapters/openai/#russo.adapters.openai","title":"openai","text":"<p>OpenAI SDK agent adapters \u2014 wraps OpenAI clients as Agents.</p> <p>Provides two adapters:</p> <ul> <li>OpenAIAgent: standard Chat Completions with audio input   (<code>gpt-4o-audio-preview</code> and similar models)</li> <li>OpenAIRealtimeAgent: Realtime API over WebSocket   (<code>gpt-4o-realtime-preview</code>)</li> </ul> <p>Requires the <code>openai</code> package: <code>pip install russo[openai]</code></p>"},{"location":"reference/adapters/openai/#russo.adapters.openai.OpenAIAgent","title":"OpenAIAgent","text":"<pre><code>OpenAIAgent(*, client: Any, model: str = 'gpt-4o-audio-preview', tools: list[Any] | None = None, system_prompt: str | None = None, extra_create_kwargs: dict[str, Any] | None = None)\n</code></pre> <p>Agent adapter that wraps an <code>AsyncOpenAI</code> client for Chat Completions.</p> <p>Sends audio via the Chat Completions API and auto-parses tool-call responses with :class:<code>OpenAIResponseParser</code>.</p> <p>Usage::</p> <pre><code>from openai import AsyncOpenAI\n\nclient = AsyncOpenAI()\nagent = OpenAIAgent(\n    client=client,\n    model=\"gpt-4o-audio-preview\",\n    tools=[{\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"book_flight\",\n            \"parameters\": {\"type\": \"object\", \"properties\": {...}},\n        },\n    }],\n)\nresponse = await agent.run(audio)\n</code></pre> PARAMETER DESCRIPTION <code>client</code> <p>An <code>openai.AsyncOpenAI</code> instance.</p> <p> TYPE: <code>Any</code> </p> <code>model</code> <p>Model name supporting audio input.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'gpt-4o-audio-preview'</code> </p> <code>tools</code> <p>OpenAI tool definitions (function-calling format).</p> <p> TYPE: <code>list[Any] | None</code> DEFAULT: <code>None</code> </p> <code>system_prompt</code> <p>Optional system message prepended to the conversation.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>extra_create_kwargs</code> <p>Additional kwargs forwarded to <code>client.chat.completions.create()</code>.</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> Source code in <code>src/russo/adapters/openai.py</code> <pre><code>def __init__(\n    self,\n    *,\n    client: Any,\n    model: str = \"gpt-4o-audio-preview\",\n    tools: list[Any] | None = None,\n    system_prompt: str | None = None,\n    extra_create_kwargs: dict[str, Any] | None = None,\n) -&gt; None:\n    \"\"\"\n    Args:\n        client: An ``openai.AsyncOpenAI`` instance.\n        model: Model name supporting audio input.\n        tools: OpenAI tool definitions (function-calling format).\n        system_prompt: Optional system message prepended to the conversation.\n        extra_create_kwargs: Additional kwargs forwarded to\n            ``client.chat.completions.create()``.\n    \"\"\"\n    self.client = client\n    self.model = model\n    self.tools = tools\n    self.system_prompt = system_prompt\n    self.extra_create_kwargs = extra_create_kwargs or {}\n    self._parser = OpenAIResponseParser()\n</code></pre>"},{"location":"reference/adapters/openai/#russo.adapters.openai.OpenAIAgent.run","title":"run  <code>async</code>","text":"<pre><code>run(audio: Audio) -&gt; AgentResponse\n</code></pre> <p>Send audio via Chat Completions and parse the tool-call response.</p> Source code in <code>src/russo/adapters/openai.py</code> <pre><code>async def run(self, audio: Audio) -&gt; AgentResponse:\n    \"\"\"Send audio via Chat Completions and parse the tool-call response.\"\"\"\n    audio_b64 = base64.b64encode(audio.data).decode(\"ascii\")\n\n    messages: list[dict[str, Any]] = []\n    if self.system_prompt:\n        messages.append({\"role\": \"system\", \"content\": self.system_prompt})\n\n    messages.append(\n        {\n            \"role\": \"user\",\n            \"content\": [\n                {\n                    \"type\": \"input_audio\",\n                    \"input_audio\": {\"data\": audio_b64, \"format\": audio.format},\n                }\n            ],\n        }\n    )\n\n    kwargs: dict[str, Any] = {\n        \"model\": self.model,\n        \"messages\": messages,\n        **self.extra_create_kwargs,\n    }\n    if self.tools:\n        kwargs[\"tools\"] = self.tools\n\n    logger.debug(\n        \"Sending %d bytes of %s audio to %s\",\n        len(audio.data),\n        audio.format,\n        self.model,\n    )\n\n    response = await self.client.chat.completions.create(**kwargs)\n    return self._parser.parse(response)\n</code></pre>"},{"location":"reference/adapters/openai/#russo.adapters.openai.OpenAIRealtimeAgent","title":"OpenAIRealtimeAgent","text":"<pre><code>OpenAIRealtimeAgent(*, client: Any | None = None, connection: Any | None = None, model: str = 'gpt-4o-realtime-preview', tools: list[Any] | None = None, response_timeout: float = 30.0)\n</code></pre> <p>Agent adapter for OpenAI's Realtime API.</p> <p>Connects via the SDK's <code>client.beta.realtime.connect()</code> interface, sends audio, and collects <code>response.function_call_arguments.done</code> events.</p> <p>Accepts either:</p> <ul> <li>An <code>AsyncOpenAI</code> client (creates a new connection per <code>run()</code>)</li> <li>A pre-existing realtime connection (reuses it, no session config sent)</li> </ul> <p>Usage with client::</p> <pre><code>from openai import AsyncOpenAI\n\nclient = AsyncOpenAI()\nagent = OpenAIRealtimeAgent(\n    client=client,\n    model=\"gpt-4o-realtime-preview\",\n    tools=[{\n        \"type\": \"function\",\n        \"name\": \"book_flight\",\n        \"description\": \"Book a flight\",\n        \"parameters\": {\"type\": \"object\", \"properties\": {...}},\n    }],\n)\nresponse = await agent.run(audio)\n</code></pre> <p>Usage with pre-existing connection::</p> <pre><code>async with client.beta.realtime.connect(model=\"gpt-4o-realtime-preview\") as conn:\n    agent = OpenAIRealtimeAgent(connection=conn)\n    response = await agent.run(audio)\n</code></pre> Note <p>The Realtime API expects pcm16 audio at 24 kHz mono by default. If you pass WAV audio, the adapter automatically strips the WAV header to extract raw PCM frames.</p> PARAMETER DESCRIPTION <code>client</code> <p>An <code>openai.AsyncOpenAI</code> instance. Mutually preferred with connection.</p> <p> TYPE: <code>Any | None</code> DEFAULT: <code>None</code> </p> <code>connection</code> <p>A pre-existing realtime connection (from <code>client.beta.realtime.connect()</code>).</p> <p> TYPE: <code>Any | None</code> DEFAULT: <code>None</code> </p> <code>model</code> <p>Realtime model name.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'gpt-4o-realtime-preview'</code> </p> <code>tools</code> <p>Tool definitions sent during session configuration.</p> <p> TYPE: <code>list[Any] | None</code> DEFAULT: <code>None</code> </p> <code>response_timeout</code> <p>Max seconds to wait for a complete response.</p> <p> TYPE: <code>float</code> DEFAULT: <code>30.0</code> </p> Source code in <code>src/russo/adapters/openai.py</code> <pre><code>def __init__(\n    self,\n    *,\n    client: Any | None = None,\n    connection: Any | None = None,\n    model: str = \"gpt-4o-realtime-preview\",\n    tools: list[Any] | None = None,\n    response_timeout: float = 30.0,\n) -&gt; None:\n    \"\"\"\n    Args:\n        client: An ``openai.AsyncOpenAI`` instance. Mutually preferred with *connection*.\n        connection: A pre-existing realtime connection (from ``client.beta.realtime.connect()``).\n        model: Realtime model name.\n        tools: Tool definitions sent during session configuration.\n        response_timeout: Max seconds to wait for a complete response.\n    \"\"\"\n    if client is None and connection is None:\n        msg = \"Provide either 'client' (AsyncOpenAI) or 'connection' (realtime connection)\"\n        raise ValueError(msg)\n    self.client = client\n    self.connection = connection\n    self.model = model\n    self.tools = tools\n    self.response_timeout = response_timeout\n</code></pre>"},{"location":"reference/adapters/openai/#russo.adapters.openai.OpenAIRealtimeAgent.run","title":"run  <code>async</code>","text":"<pre><code>run(audio: Audio) -&gt; AgentResponse\n</code></pre> <p>Send audio via the Realtime API and collect function calls.</p> Source code in <code>src/russo/adapters/openai.py</code> <pre><code>async def run(self, audio: Audio) -&gt; AgentResponse:\n    \"\"\"Send audio via the Realtime API and collect function calls.\"\"\"\n    if self.connection is not None:\n        return await self._run_on(self.connection, audio, configure=False)\n\n    async with self.client.beta.realtime.connect(model=self.model) as conn:\n        return await self._run_on(conn, audio, configure=True)\n</code></pre>"},{"location":"reference/adapters/websocket/","title":"WebSocket Adapter","text":"<p>WebSocket agent adapter \u2014 sends audio to a WebSocket endpoint.</p> <p>Note</p> <p>Requires the <code>ws</code> extra: <code>pip install \"russo[ws]\"</code></p>"},{"location":"reference/adapters/websocket/#russo.adapters.websocket","title":"websocket","text":"<p>WebSocket agent adapter \u2014 sends audio to a WebSocket endpoint.</p> <p>Requires the <code>websockets</code> package: pip install russo[ws]</p>"},{"location":"reference/adapters/websocket/#russo.adapters.websocket.WebSocketAgent","title":"WebSocketAgent","text":"<pre><code>WebSocketAgent(*, url: str, parser: ResponseParser | None = None, headers: dict[str, str] | None = None, send_bytes: bool = False, audio_field: str = 'audio', format_field: str = 'format', response_timeout: float = 30.0, max_messages: int = 100, on_send: Callable[[Audio], str | bytes] | None = None, is_complete: Callable[[list[Any]], bool] | None = None, aggregate: Callable[[list[Any]], Any] | None = None, open_timeout: float = 10.0, close_timeout: float = 5.0, extra_ws_kwargs: dict[str, Any] | None = None)\n</code></pre> <p>Agent adapter that communicates over WebSocket.</p> <p>Connects to the endpoint, sends audio, collects response messages until a completion condition is met, then parses tool calls.</p> <p>Supports two send modes: - json (default): sends <code>{\"audio\": \"&lt;base64&gt;\", \"format\": \"wav\"}</code> - bytes: sends raw audio bytes directly on the wire</p> <p>And two ways to customize the protocol: - on_send: transform the Audio into whatever your server expects - is_complete: decide when to stop collecting response messages</p> Usage Source code in <code>src/russo/adapters/websocket.py</code> <pre><code>def __init__(\n    self,\n    *,\n    url: str,\n    parser: ResponseParser | None = None,\n    headers: dict[str, str] | None = None,\n    # Send options\n    send_bytes: bool = False,\n    audio_field: str = \"audio\",\n    format_field: str = \"format\",\n    # Response collection\n    response_timeout: float = 30.0,\n    max_messages: int = 100,\n    # Hooks\n    on_send: Callable[[Audio], str | bytes] | None = None,\n    is_complete: Callable[[list[Any]], bool] | None = None,\n    aggregate: Callable[[list[Any]], Any] | None = None,\n    # Connection\n    open_timeout: float = 10.0,\n    close_timeout: float = 5.0,\n    extra_ws_kwargs: dict[str, Any] | None = None,\n) -&gt; None:\n    if not _HAS_WEBSOCKETS:\n        msg = \"WebSocketAgent requires the 'websockets' package. Install with: pip install russo[ws]\"\n        raise ImportError(msg)\n\n    self.url = url\n    self.parser = parser\n    self.headers = headers or {}\n    self.send_bytes = send_bytes\n    self.audio_field = audio_field\n    self.format_field = format_field\n    self.response_timeout = response_timeout\n    self.max_messages = max_messages\n    self.on_send = on_send\n    self.is_complete = is_complete\n    self.aggregate = aggregate\n    self.open_timeout = open_timeout\n    self.close_timeout = close_timeout\n    self.extra_ws_kwargs = extra_ws_kwargs or {}\n</code></pre>"},{"location":"reference/adapters/websocket/#russo.adapters.websocket.WebSocketAgent--simple-json-protocol","title":"Simple JSON protocol","text":"<p>agent = WebSocketAgent(     url=\"ws://localhost:8000/ws/agent\",     parser=russo.parsers.GeminiResponseParser(), )</p>"},{"location":"reference/adapters/websocket/#russo.adapters.websocket.WebSocketAgent--raw-bytes-protocol-eg-streaming-pcm","title":"Raw bytes protocol (e.g. streaming PCM)","text":"<p>agent = WebSocketAgent(     url=\"ws://localhost:8000/ws/agent\",     send_bytes=True, )</p>"},{"location":"reference/adapters/websocket/#russo.adapters.websocket.WebSocketAgent--fully-custom-sendreceive","title":"Fully custom send/receive","text":"<p>agent = WebSocketAgent(     url=\"ws://localhost:8000/ws/agent\",     on_send=lambda audio: json.dumps({\"pcm\": base64.b64encode(audio.data).decode()}),     is_complete=lambda msgs: any('\"done\": true' in str(m) for m in msgs), )</p>"},{"location":"reference/adapters/websocket/#russo.adapters.websocket.WebSocketAgent.run","title":"run  <code>async</code>","text":"<pre><code>run(audio: Audio) -&gt; AgentResponse\n</code></pre> <p>Send audio over WebSocket and collect the response.</p> Source code in <code>src/russo/adapters/websocket.py</code> <pre><code>async def run(self, audio: Audio) -&gt; AgentResponse:\n    \"\"\"Send audio over WebSocket and collect the response.\"\"\"\n    import websockets\n\n    async with websockets.connect(\n        self.url,\n        additional_headers=self.headers or None,\n        open_timeout=self.open_timeout,\n        close_timeout=self.close_timeout,\n        **self.extra_ws_kwargs,\n    ) as ws:\n        # --- Send ---\n        message = self._prepare_message(audio)\n        if isinstance(message, bytes):\n            await ws.send(message)\n        else:\n            await ws.send(message)\n        logger.debug(\n            \"Sent %s message (%d bytes)\",\n            \"binary\" if isinstance(message, bytes) else \"text\",\n            len(message),\n        )\n\n        # --- Collect responses ---\n        messages = await self._collect_responses(ws)\n        logger.debug(\"Collected %d response messages\", len(messages))\n\n    # --- Parse ---\n    raw = self._aggregate(messages)\n\n    if self.parser:\n        return self.parser.parse(raw)\n    return self._default_parse(raw)\n</code></pre>"},{"location":"reference/core/assertions/","title":"Assertions","text":"<p>Custom assertion helpers for russo test results.</p>"},{"location":"reference/core/assertions/#russo._assertions","title":"_assertions","text":"<p>Custom assertion helpers for russo test results.</p>"},{"location":"reference/core/assertions/#russo._assertions.ToolCallAssertionError","title":"ToolCallAssertionError","text":"<pre><code>ToolCallAssertionError(result: EvalResult, message: str = '')\n</code></pre> <p>               Bases: <code>AssertionError</code></p> <p>Rich assertion error with detailed tool call diff.</p> Source code in <code>src/russo/_assertions.py</code> <pre><code>def __init__(self, result: EvalResult, message: str = \"\") -&gt; None:\n    self.result = result\n    detail = result.summary()\n    full_message = f\"{message}\\n{detail}\" if message else detail\n    super().__init__(full_message)\n</code></pre>"},{"location":"reference/core/assertions/#russo._assertions.assert_tool_calls","title":"assert_tool_calls","text":"<pre><code>assert_tool_calls(result: EvalResult, *, message: str = '') -&gt; None\n</code></pre> <p>Assert that an EvalResult passed.</p> <p>Raises a ToolCallAssertionError with a rich diff if it didn't.</p> Usage <p>result = await russo.run(...) russo.assert_tool_calls(result)</p> Source code in <code>src/russo/_assertions.py</code> <pre><code>def assert_tool_calls(\n    result: EvalResult,\n    *,\n    message: str = \"\",\n) -&gt; None:\n    \"\"\"Assert that an EvalResult passed.\n\n    Raises a ToolCallAssertionError with a rich diff if it didn't.\n\n    Usage:\n        result = await russo.run(...)\n        russo.assert_tool_calls(result)\n\n        # Or with a custom message\n        russo.assert_tool_calls(result, message=\"Flight booking should work\")\n    \"\"\"\n    if not result.passed:\n        raise ToolCallAssertionError(result, message)\n</code></pre>"},{"location":"reference/core/assertions/#russo._assertions.assert_tool_calls--or-with-a-custom-message","title":"Or with a custom message","text":"<p>russo.assert_tool_calls(result, message=\"Flight booking should work\")</p>"},{"location":"reference/core/cache/","title":"Cache","text":"<p>Audio caching for synthesized prompts.</p>"},{"location":"reference/core/cache/#russo._cache","title":"_cache","text":"<p>Audio caching for synthesized prompts.</p> <p>Saves synthesized audio to disk keyed by a hash of the prompt text, so repeated test runs skip the TTS call entirely.</p>"},{"location":"reference/core/cache/#russo._cache.AudioCache","title":"AudioCache","text":"<pre><code>AudioCache(cache_dir: Path = _DEFAULT_CACHE_DIR)\n</code></pre> <p>File-system cache for synthesized audio.</p> Each entry is a pair of files <p>.audio  \u2014 raw audio bytes .meta   \u2014 JSON with format, sample_rate, prompt Usage <p>cache = AudioCache()                     # .russo_cache/ cache = AudioCache(Path(\"my_cache\"))     # custom dir cache.get(\"abc123\")                      # Audio | None cache.put(\"abc123\", audio) cache.clear()</p> Source code in <code>src/russo/_cache.py</code> <pre><code>def __init__(self, cache_dir: Path = _DEFAULT_CACHE_DIR) -&gt; None:\n    self.cache_dir = cache_dir\n</code></pre>"},{"location":"reference/core/cache/#russo._cache.AudioCache.cache_key","title":"cache_key","text":"<pre><code>cache_key(prompt: str, **extra: Any) -&gt; str\n</code></pre> <p>Deterministic key from prompt text + optional extra metadata.</p> <p>Extra kwargs (e.g. voice, model) are included so a change in synthesizer config invalidates the cache automatically.</p> Source code in <code>src/russo/_cache.py</code> <pre><code>def cache_key(self, prompt: str, **extra: Any) -&gt; str:\n    \"\"\"Deterministic key from prompt text + optional extra metadata.\n\n    Extra kwargs (e.g. voice, model) are included so a change in\n    synthesizer config invalidates the cache automatically.\n    \"\"\"\n    blob = json.dumps({\"prompt\": prompt, **extra}, sort_keys=True)\n    return hashlib.sha256(blob.encode()).hexdigest()[:24]\n</code></pre>"},{"location":"reference/core/cache/#russo._cache.AudioCache.get","title":"get","text":"<pre><code>get(key: str) -&gt; Audio | None\n</code></pre> <p>Load cached audio, or None if not cached.</p> Source code in <code>src/russo/_cache.py</code> <pre><code>def get(self, key: str) -&gt; Audio | None:\n    \"\"\"Load cached audio, or None if not cached.\"\"\"\n    audio_path = self.cache_dir / f\"{key}.audio\"\n    meta_path = self.cache_dir / f\"{key}.meta\"\n    if not audio_path.exists() or not meta_path.exists():\n        return None\n    try:\n        meta = json.loads(meta_path.read_text())\n        data = audio_path.read_bytes()\n        logger.debug(\"Cache hit: %s\", key)\n        return Audio(data=data, format=meta[\"format\"], sample_rate=meta[\"sample_rate\"])\n    except (json.JSONDecodeError, KeyError, OSError) as exc:\n        logger.warning(\"Corrupt cache entry %s, removing: %s\", key, exc)\n        self._remove_entry(key)\n        return None\n</code></pre>"},{"location":"reference/core/cache/#russo._cache.AudioCache.put","title":"put","text":"<pre><code>put(key: str, audio: Audio, *, prompt: str = '') -&gt; None\n</code></pre> <p>Write audio + metadata to cache.</p> Source code in <code>src/russo/_cache.py</code> <pre><code>def put(self, key: str, audio: Audio, *, prompt: str = \"\") -&gt; None:\n    \"\"\"Write audio + metadata to cache.\"\"\"\n    self._ensure_dir()\n    audio_path = self.cache_dir / f\"{key}.audio\"\n    meta_path = self.cache_dir / f\"{key}.meta\"\n    audio_path.write_bytes(audio.data)\n    meta = {\n        \"format\": audio.format,\n        \"sample_rate\": audio.sample_rate,\n        \"prompt\": prompt,\n    }\n    meta_path.write_text(json.dumps(meta, indent=2))\n    logger.debug(\"Cached: %s (%d bytes)\", key, len(audio.data))\n</code></pre>"},{"location":"reference/core/cache/#russo._cache.AudioCache.clear","title":"clear","text":"<pre><code>clear() -&gt; None\n</code></pre> <p>Remove all cached entries.</p> Source code in <code>src/russo/_cache.py</code> <pre><code>def clear(self) -&gt; None:\n    \"\"\"Remove all cached entries.\"\"\"\n    if not self.cache_dir.exists():\n        return\n    count = 0\n    for f in self.cache_dir.iterdir():\n        if f.suffix in (\".audio\", \".meta\"):\n            f.unlink()\n            count += 1\n    logger.info(\"Cleared %d cache files from %s\", count, self.cache_dir)\n</code></pre>"},{"location":"reference/core/cache/#russo._cache.AudioCache.size","title":"size","text":"<pre><code>size() -&gt; int\n</code></pre> <p>Number of cached audio entries.</p> Source code in <code>src/russo/_cache.py</code> <pre><code>def size(self) -&gt; int:\n    \"\"\"Number of cached audio entries.\"\"\"\n    if not self.cache_dir.exists():\n        return 0\n    return sum(1 for f in self.cache_dir.iterdir() if f.suffix == \".audio\")\n</code></pre>"},{"location":"reference/core/cache/#russo._cache.CachedSynthesizer","title":"CachedSynthesizer","text":"<pre><code>CachedSynthesizer(synthesizer: Synthesizer, *, cache: AudioCache | None = None, enabled: bool = True, cache_key_extra: dict[str, Any] | None = None)\n</code></pre> <p>Wraps any Synthesizer with local audio caching.</p> <p>Satisfies the Synthesizer protocol \u2014 drop-in replacement.</p> Usage <p>synth = CachedSynthesizer(GoogleSynthesizer(...))</p> Source code in <code>src/russo/_cache.py</code> <pre><code>def __init__(\n    self,\n    synthesizer: Synthesizer,\n    *,\n    cache: AudioCache | None = None,\n    enabled: bool = True,\n    cache_key_extra: dict[str, Any] | None = None,\n) -&gt; None:\n    self.inner = synthesizer\n    self.cache = cache or AudioCache()\n    self.enabled = enabled\n    self.cache_key_extra = cache_key_extra or {}\n</code></pre>"},{"location":"reference/core/cache/#russo._cache.CachedSynthesizer--disable-caching-at-runtime","title":"Disable caching at runtime","text":"<p>synth = CachedSynthesizer(GoogleSynthesizer(...), enabled=False)</p>"},{"location":"reference/core/cache/#russo._cache.CachedSynthesizer--custom-cache-directory","title":"Custom cache directory","text":"<p>synth = CachedSynthesizer(     GoogleSynthesizer(...),     cache=AudioCache(Path(\"/tmp/my_cache\")), )</p>"},{"location":"reference/core/cache/#russo._cache.CachedSynthesizer--include-synthesizer-config-in-cache-key-invalidates-on-config-change","title":"Include synthesizer config in cache key (invalidates on config change)","text":"<p>synth = CachedSynthesizer(     GoogleSynthesizer(voice=\"Kore\", model=\"gemini-2.5-flash-preview-tts\"),     cache_key_extra={\"voice\": \"Kore\", \"model\": \"gemini-2.5-flash-preview-tts\"}, )</p>"},{"location":"reference/core/cache/#russo._cache.CachedSynthesizer--clear-cache","title":"Clear cache","text":"<p>synth.cache.clear()</p>"},{"location":"reference/core/cache/#russo._cache.CachedSynthesizer.synthesize","title":"synthesize  <code>async</code>","text":"<pre><code>synthesize(text: str) -&gt; Audio\n</code></pre> <p>Synthesize with cache lookup/store.</p> Source code in <code>src/russo/_cache.py</code> <pre><code>async def synthesize(self, text: str) -&gt; Audio:\n    \"\"\"Synthesize with cache lookup/store.\"\"\"\n    if not self.enabled:\n        return await self.inner.synthesize(text)\n\n    key = self.cache.cache_key(text, **self.cache_key_extra)\n    cached = self.cache.get(key)\n    if cached is not None:\n        return cached\n\n    audio = await self.inner.synthesize(text)\n    self.cache.put(key, audio, prompt=text)\n    return audio\n</code></pre>"},{"location":"reference/core/init/","title":"russo","text":"<p>Top-level module exports.</p>"},{"location":"reference/core/init/#russo","title":"russo","text":"<p>russo \u2014 testing framework for LLM tool-call accuracy.</p>"},{"location":"reference/core/init/#russo.Audio","title":"Audio","text":"<p>               Bases: <code>BaseModel</code></p> <p>Audio data with format metadata.</p>"},{"location":"reference/core/init/#russo.Audio.save","title":"save","text":"<pre><code>save(path: str | Path) -&gt; Path\n</code></pre> <p>Save audio to a file. Wraps raw PCM in a WAV container if needed.</p> Usage <p>audio.save(\"output.wav\")</p> Source code in <code>src/russo/_types.py</code> <pre><code>def save(self, path: str | Path) -&gt; Path:\n    \"\"\"Save audio to a file. Wraps raw PCM in a WAV container if needed.\n\n    Usage:\n        audio.save(\"output.wav\")\n    \"\"\"\n    import wave\n\n    p = Path(path)\n    p.parent.mkdir(parents=True, exist_ok=True)\n\n    if p.suffix.lower() == \".wav\":\n        with wave.open(str(p), \"wb\") as wf:\n            wf.setnchannels(self.channels)\n            wf.setsampwidth(self.sample_width)\n            wf.setframerate(self.sample_rate)\n            wf.writeframes(self.data)\n    else:\n        # For non-WAV formats, write raw bytes\n        p.write_bytes(self.data)\n    return p\n</code></pre>"},{"location":"reference/core/init/#russo.ToolCall","title":"ToolCall","text":"<p>               Bases: <code>BaseModel</code></p> <p>A normalized tool/function call representation.</p> <p>Provider-agnostic \u2014 parsers convert provider-specific formats into this.</p>"},{"location":"reference/core/init/#russo.AgentResponse","title":"AgentResponse","text":"<p>               Bases: <code>BaseModel</code></p> <p>Normalized response from an agent, containing extracted tool calls.</p>"},{"location":"reference/core/init/#russo.AgentResponse.raw","title":"raw  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>raw: Any | None = None\n</code></pre> <p>The raw, unparsed response from the provider (for debugging).</p>"},{"location":"reference/core/init/#russo.EvalResult","title":"EvalResult","text":"<p>               Bases: <code>BaseModel</code></p> <p>Full evaluation result for a test scenario.</p>"},{"location":"reference/core/init/#russo.EvalResult.match_rate","title":"match_rate  <code>property</code>","text":"<pre><code>match_rate: float\n</code></pre> <p>Fraction of expected tool calls that matched.</p>"},{"location":"reference/core/init/#russo.EvalResult.summary","title":"summary","text":"<pre><code>summary() -&gt; str\n</code></pre> <p>Human-readable summary of the evaluation.</p> Source code in <code>src/russo/_types.py</code> <pre><code>def summary(self) -&gt; str:\n    \"\"\"Human-readable summary of the evaluation.\"\"\"\n    status = \"PASSED\" if self.passed else \"FAILED\"\n    lines = [f\"{status} ({self.match_rate:.0%} match rate)\"]\n    for m in self.matches:\n        icon = \"+\" if m.matched else \"-\"\n        actual_str = f\" -&gt; {m.actual.name}({m.actual.arguments})\" if m.actual else \" -&gt; (no match)\"\n        lines.append(f\"  [{icon}] {m.expected.name}({m.expected.arguments}){actual_str}\")\n        if m.details:\n            lines.append(f\"      {m.details}\")\n    return \"\\n\".join(lines)\n</code></pre>"},{"location":"reference/core/init/#russo.ToolCallMatch","title":"ToolCallMatch","text":"<p>               Bases: <code>BaseModel</code></p> <p>Result of comparing a single expected tool call against actuals.</p>"},{"location":"reference/core/init/#russo.AudioCache","title":"AudioCache","text":"<pre><code>AudioCache(cache_dir: Path = _DEFAULT_CACHE_DIR)\n</code></pre> <p>File-system cache for synthesized audio.</p> Each entry is a pair of files <p>.audio  \u2014 raw audio bytes .meta   \u2014 JSON with format, sample_rate, prompt Usage <p>cache = AudioCache()                     # .russo_cache/ cache = AudioCache(Path(\"my_cache\"))     # custom dir cache.get(\"abc123\")                      # Audio | None cache.put(\"abc123\", audio) cache.clear()</p> Source code in <code>src/russo/_cache.py</code> <pre><code>def __init__(self, cache_dir: Path = _DEFAULT_CACHE_DIR) -&gt; None:\n    self.cache_dir = cache_dir\n</code></pre>"},{"location":"reference/core/init/#russo.AudioCache.cache_key","title":"cache_key","text":"<pre><code>cache_key(prompt: str, **extra: Any) -&gt; str\n</code></pre> <p>Deterministic key from prompt text + optional extra metadata.</p> <p>Extra kwargs (e.g. voice, model) are included so a change in synthesizer config invalidates the cache automatically.</p> Source code in <code>src/russo/_cache.py</code> <pre><code>def cache_key(self, prompt: str, **extra: Any) -&gt; str:\n    \"\"\"Deterministic key from prompt text + optional extra metadata.\n\n    Extra kwargs (e.g. voice, model) are included so a change in\n    synthesizer config invalidates the cache automatically.\n    \"\"\"\n    blob = json.dumps({\"prompt\": prompt, **extra}, sort_keys=True)\n    return hashlib.sha256(blob.encode()).hexdigest()[:24]\n</code></pre>"},{"location":"reference/core/init/#russo.AudioCache.get","title":"get","text":"<pre><code>get(key: str) -&gt; Audio | None\n</code></pre> <p>Load cached audio, or None if not cached.</p> Source code in <code>src/russo/_cache.py</code> <pre><code>def get(self, key: str) -&gt; Audio | None:\n    \"\"\"Load cached audio, or None if not cached.\"\"\"\n    audio_path = self.cache_dir / f\"{key}.audio\"\n    meta_path = self.cache_dir / f\"{key}.meta\"\n    if not audio_path.exists() or not meta_path.exists():\n        return None\n    try:\n        meta = json.loads(meta_path.read_text())\n        data = audio_path.read_bytes()\n        logger.debug(\"Cache hit: %s\", key)\n        return Audio(data=data, format=meta[\"format\"], sample_rate=meta[\"sample_rate\"])\n    except (json.JSONDecodeError, KeyError, OSError) as exc:\n        logger.warning(\"Corrupt cache entry %s, removing: %s\", key, exc)\n        self._remove_entry(key)\n        return None\n</code></pre>"},{"location":"reference/core/init/#russo.AudioCache.put","title":"put","text":"<pre><code>put(key: str, audio: Audio, *, prompt: str = '') -&gt; None\n</code></pre> <p>Write audio + metadata to cache.</p> Source code in <code>src/russo/_cache.py</code> <pre><code>def put(self, key: str, audio: Audio, *, prompt: str = \"\") -&gt; None:\n    \"\"\"Write audio + metadata to cache.\"\"\"\n    self._ensure_dir()\n    audio_path = self.cache_dir / f\"{key}.audio\"\n    meta_path = self.cache_dir / f\"{key}.meta\"\n    audio_path.write_bytes(audio.data)\n    meta = {\n        \"format\": audio.format,\n        \"sample_rate\": audio.sample_rate,\n        \"prompt\": prompt,\n    }\n    meta_path.write_text(json.dumps(meta, indent=2))\n    logger.debug(\"Cached: %s (%d bytes)\", key, len(audio.data))\n</code></pre>"},{"location":"reference/core/init/#russo.AudioCache.clear","title":"clear","text":"<pre><code>clear() -&gt; None\n</code></pre> <p>Remove all cached entries.</p> Source code in <code>src/russo/_cache.py</code> <pre><code>def clear(self) -&gt; None:\n    \"\"\"Remove all cached entries.\"\"\"\n    if not self.cache_dir.exists():\n        return\n    count = 0\n    for f in self.cache_dir.iterdir():\n        if f.suffix in (\".audio\", \".meta\"):\n            f.unlink()\n            count += 1\n    logger.info(\"Cleared %d cache files from %s\", count, self.cache_dir)\n</code></pre>"},{"location":"reference/core/init/#russo.AudioCache.size","title":"size","text":"<pre><code>size() -&gt; int\n</code></pre> <p>Number of cached audio entries.</p> Source code in <code>src/russo/_cache.py</code> <pre><code>def size(self) -&gt; int:\n    \"\"\"Number of cached audio entries.\"\"\"\n    if not self.cache_dir.exists():\n        return 0\n    return sum(1 for f in self.cache_dir.iterdir() if f.suffix == \".audio\")\n</code></pre>"},{"location":"reference/core/init/#russo.CachedSynthesizer","title":"CachedSynthesizer","text":"<pre><code>CachedSynthesizer(synthesizer: Synthesizer, *, cache: AudioCache | None = None, enabled: bool = True, cache_key_extra: dict[str, Any] | None = None)\n</code></pre> <p>Wraps any Synthesizer with local audio caching.</p> <p>Satisfies the Synthesizer protocol \u2014 drop-in replacement.</p> Usage <p>synth = CachedSynthesizer(GoogleSynthesizer(...))</p> Source code in <code>src/russo/_cache.py</code> <pre><code>def __init__(\n    self,\n    synthesizer: Synthesizer,\n    *,\n    cache: AudioCache | None = None,\n    enabled: bool = True,\n    cache_key_extra: dict[str, Any] | None = None,\n) -&gt; None:\n    self.inner = synthesizer\n    self.cache = cache or AudioCache()\n    self.enabled = enabled\n    self.cache_key_extra = cache_key_extra or {}\n</code></pre>"},{"location":"reference/core/init/#russo.CachedSynthesizer--disable-caching-at-runtime","title":"Disable caching at runtime","text":"<p>synth = CachedSynthesizer(GoogleSynthesizer(...), enabled=False)</p>"},{"location":"reference/core/init/#russo.CachedSynthesizer--custom-cache-directory","title":"Custom cache directory","text":"<p>synth = CachedSynthesizer(     GoogleSynthesizer(...),     cache=AudioCache(Path(\"/tmp/my_cache\")), )</p>"},{"location":"reference/core/init/#russo.CachedSynthesizer--include-synthesizer-config-in-cache-key-invalidates-on-config-change","title":"Include synthesizer config in cache key (invalidates on config change)","text":"<p>synth = CachedSynthesizer(     GoogleSynthesizer(voice=\"Kore\", model=\"gemini-2.5-flash-preview-tts\"),     cache_key_extra={\"voice\": \"Kore\", \"model\": \"gemini-2.5-flash-preview-tts\"}, )</p>"},{"location":"reference/core/init/#russo.CachedSynthesizer--clear-cache","title":"Clear cache","text":"<p>synth.cache.clear()</p>"},{"location":"reference/core/init/#russo.CachedSynthesizer.synthesize","title":"synthesize  <code>async</code>","text":"<pre><code>synthesize(text: str) -&gt; Audio\n</code></pre> <p>Synthesize with cache lookup/store.</p> Source code in <code>src/russo/_cache.py</code> <pre><code>async def synthesize(self, text: str) -&gt; Audio:\n    \"\"\"Synthesize with cache lookup/store.\"\"\"\n    if not self.enabled:\n        return await self.inner.synthesize(text)\n\n    key = self.cache.cache_key(text, **self.cache_key_extra)\n    cached = self.cache.get(key)\n    if cached is not None:\n        return cached\n\n    audio = await self.inner.synthesize(text)\n    self.cache.put(key, audio, prompt=text)\n    return audio\n</code></pre>"},{"location":"reference/core/init/#russo.ToolCallAssertionError","title":"ToolCallAssertionError","text":"<pre><code>ToolCallAssertionError(result: EvalResult, message: str = '')\n</code></pre> <p>               Bases: <code>AssertionError</code></p> <p>Rich assertion error with detailed tool call diff.</p> Source code in <code>src/russo/_assertions.py</code> <pre><code>def __init__(self, result: EvalResult, message: str = \"\") -&gt; None:\n    self.result = result\n    detail = result.summary()\n    full_message = f\"{message}\\n{detail}\" if message else detail\n    super().__init__(full_message)\n</code></pre>"},{"location":"reference/core/init/#russo.tool_call","title":"tool_call","text":"<pre><code>tool_call(name: str, **arguments: Any) -&gt; ToolCall\n</code></pre> <p>Shorthand for creating a ToolCall.</p> Usage <p>russo.tool_call(\"book_flight\", from_city=\"NYC\", to_city=\"LA\")</p> Source code in <code>src/russo/_helpers.py</code> <pre><code>def tool_call(name: str, **arguments: Any) -&gt; ToolCall:\n    \"\"\"Shorthand for creating a ToolCall.\n\n    Usage:\n        russo.tool_call(\"book_flight\", from_city=\"NYC\", to_city=\"LA\")\n    \"\"\"\n    return ToolCall(name=name, arguments=arguments)\n</code></pre>"},{"location":"reference/core/init/#russo.agent","title":"agent","text":"<pre><code>agent(fn: Callable[[Audio], Coroutine[Any, Any, AgentResponse]]) -&gt; _CallableAgent\n</code></pre> <p>Decorator to turn an async function into an Agent.</p> Usage <p>@russo.agent async def my_agent(audio: russo.Audio) -&gt; russo.AgentResponse:     result = await call_my_api(audio.data)     return russo.AgentResponse(tool_calls=[...])</p> Source code in <code>src/russo/_helpers.py</code> <pre><code>def agent(fn: Callable[[Audio], Coroutine[Any, Any, AgentResponse]]) -&gt; _CallableAgent:\n    \"\"\"Decorator to turn an async function into an Agent.\n\n    Usage:\n        @russo.agent\n        async def my_agent(audio: russo.Audio) -&gt; russo.AgentResponse:\n            result = await call_my_api(audio.data)\n            return russo.AgentResponse(tool_calls=[...])\n    \"\"\"\n    return _CallableAgent(fn)\n</code></pre>"},{"location":"reference/core/init/#russo.run","title":"run  <code>async</code>","text":"<pre><code>run(*, prompt: str, synthesizer: Synthesizer, agent: Agent, evaluator: Evaluator, expect: list[ToolCall]) -&gt; EvalResult\n</code></pre> <p>Run the full russo pipeline.</p> <ol> <li>Synthesize audio from the text prompt.</li> <li>Pass audio to the agent under test.</li> <li>Evaluate the agent's tool calls against expectations.</li> </ol> PARAMETER DESCRIPTION <code>prompt</code> <p>The text prompt to synthesize into audio.</p> <p> TYPE: <code>str</code> </p> <code>synthesizer</code> <p>Converts text to audio.</p> <p> TYPE: <code>Synthesizer</code> </p> <code>agent</code> <p>The agent under test.</p> <p> TYPE: <code>Agent</code> </p> <code>evaluator</code> <p>Compares expected vs actual tool calls.</p> <p> TYPE: <code>Evaluator</code> </p> <code>expect</code> <p>The expected tool calls.</p> <p> TYPE: <code>list[ToolCall]</code> </p> RETURNS DESCRIPTION <code>EvalResult</code> <p>EvalResult with pass/fail and per-call match details.</p> Source code in <code>src/russo/_pipeline.py</code> <pre><code>async def run(\n    *,\n    prompt: str,\n    synthesizer: Synthesizer,\n    agent: Agent,\n    evaluator: Evaluator,\n    expect: list[ToolCall],\n) -&gt; EvalResult:\n    \"\"\"Run the full russo pipeline.\n\n    1. Synthesize audio from the text prompt.\n    2. Pass audio to the agent under test.\n    3. Evaluate the agent's tool calls against expectations.\n\n    Args:\n        prompt: The text prompt to synthesize into audio.\n        synthesizer: Converts text to audio.\n        agent: The agent under test.\n        evaluator: Compares expected vs actual tool calls.\n        expect: The expected tool calls.\n\n    Returns:\n        EvalResult with pass/fail and per-call match details.\n    \"\"\"\n    audio = await synthesizer.synthesize(prompt)\n    response = await agent.run(audio)\n    return evaluator.evaluate(expected=expect, actual=response.tool_calls)\n</code></pre>"},{"location":"reference/core/init/#russo.assert_tool_calls","title":"assert_tool_calls","text":"<pre><code>assert_tool_calls(result: EvalResult, *, message: str = '') -&gt; None\n</code></pre> <p>Assert that an EvalResult passed.</p> <p>Raises a ToolCallAssertionError with a rich diff if it didn't.</p> Usage <p>result = await russo.run(...) russo.assert_tool_calls(result)</p> Source code in <code>src/russo/_assertions.py</code> <pre><code>def assert_tool_calls(\n    result: EvalResult,\n    *,\n    message: str = \"\",\n) -&gt; None:\n    \"\"\"Assert that an EvalResult passed.\n\n    Raises a ToolCallAssertionError with a rich diff if it didn't.\n\n    Usage:\n        result = await russo.run(...)\n        russo.assert_tool_calls(result)\n\n        # Or with a custom message\n        russo.assert_tool_calls(result, message=\"Flight booking should work\")\n    \"\"\"\n    if not result.passed:\n        raise ToolCallAssertionError(result, message)\n</code></pre>"},{"location":"reference/core/init/#russo.assert_tool_calls--or-with-a-custom-message","title":"Or with a custom message","text":"<p>russo.assert_tool_calls(result, message=\"Flight booking should work\")</p>"},{"location":"reference/core/pipeline/","title":"Pipeline","text":"<p>The <code>run()</code> function orchestrates the full russo pipeline.</p>"},{"location":"reference/core/pipeline/#russo._pipeline","title":"_pipeline","text":"<p>Pipeline orchestrator \u2014 chains Synthesizer -&gt; Agent -&gt; Evaluator.</p>"},{"location":"reference/core/pipeline/#russo._pipeline.run","title":"run  <code>async</code>","text":"<pre><code>run(*, prompt: str, synthesizer: Synthesizer, agent: Agent, evaluator: Evaluator, expect: list[ToolCall]) -&gt; EvalResult\n</code></pre> <p>Run the full russo pipeline.</p> <ol> <li>Synthesize audio from the text prompt.</li> <li>Pass audio to the agent under test.</li> <li>Evaluate the agent's tool calls against expectations.</li> </ol> PARAMETER DESCRIPTION <code>prompt</code> <p>The text prompt to synthesize into audio.</p> <p> TYPE: <code>str</code> </p> <code>synthesizer</code> <p>Converts text to audio.</p> <p> TYPE: <code>Synthesizer</code> </p> <code>agent</code> <p>The agent under test.</p> <p> TYPE: <code>Agent</code> </p> <code>evaluator</code> <p>Compares expected vs actual tool calls.</p> <p> TYPE: <code>Evaluator</code> </p> <code>expect</code> <p>The expected tool calls.</p> <p> TYPE: <code>list[ToolCall]</code> </p> RETURNS DESCRIPTION <code>EvalResult</code> <p>EvalResult with pass/fail and per-call match details.</p> Source code in <code>src/russo/_pipeline.py</code> <pre><code>async def run(\n    *,\n    prompt: str,\n    synthesizer: Synthesizer,\n    agent: Agent,\n    evaluator: Evaluator,\n    expect: list[ToolCall],\n) -&gt; EvalResult:\n    \"\"\"Run the full russo pipeline.\n\n    1. Synthesize audio from the text prompt.\n    2. Pass audio to the agent under test.\n    3. Evaluate the agent's tool calls against expectations.\n\n    Args:\n        prompt: The text prompt to synthesize into audio.\n        synthesizer: Converts text to audio.\n        agent: The agent under test.\n        evaluator: Compares expected vs actual tool calls.\n        expect: The expected tool calls.\n\n    Returns:\n        EvalResult with pass/fail and per-call match details.\n    \"\"\"\n    audio = await synthesizer.synthesize(prompt)\n    response = await agent.run(audio)\n    return evaluator.evaluate(expected=expect, actual=response.tool_calls)\n</code></pre>"},{"location":"reference/core/pipeline/#russo._pipeline.run_concurrent","title":"run_concurrent  <code>async</code>","text":"<pre><code>run_concurrent(*, prompts: str | list[str], synthesizer: Synthesizer, agent: Agent, evaluator: Evaluator, expect: list[ToolCall], runs: int = 1, max_concurrency: int | None = None) -&gt; BatchResult\n</code></pre> <p>Run the pipeline concurrently for multiple prompts and/or multiple runs.</p> Three scenarios <ul> <li>Single prompt, N runs:  <code>prompts=\"text\", runs=N</code></li> <li>Multiple prompts, 1 run each:  <code>prompts=[\"a\", \"b\", \"c\"]</code></li> <li>Multiple prompts, N runs each:  <code>prompts=[\"a\", \"b\"], runs=N</code></li> </ul> PARAMETER DESCRIPTION <code>prompts</code> <p>One or more text prompts to test.</p> <p> TYPE: <code>str | list[str]</code> </p> <code>synthesizer</code> <p>Converts text to audio.</p> <p> TYPE: <code>Synthesizer</code> </p> <code>agent</code> <p>The agent under test.</p> <p> TYPE: <code>Agent</code> </p> <code>evaluator</code> <p>Compares expected vs actual tool calls.</p> <p> TYPE: <code>Evaluator</code> </p> <code>expect</code> <p>The expected tool calls (same for every prompt).</p> <p> TYPE: <code>list[ToolCall]</code> </p> <code>runs</code> <p>Number of times to run each prompt (default 1).</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>max_concurrency</code> <p>Cap on simultaneous pipeline runs (<code>None</code> = unlimited).</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>BatchResult</code> <p>BatchResult with per-run details and aggregate statistics.</p> Source code in <code>src/russo/_pipeline.py</code> <pre><code>async def run_concurrent(\n    *,\n    prompts: str | list[str],\n    synthesizer: Synthesizer,\n    agent: Agent,\n    evaluator: Evaluator,\n    expect: list[ToolCall],\n    runs: int = 1,\n    max_concurrency: int | None = None,\n) -&gt; BatchResult:\n    \"\"\"Run the pipeline concurrently for multiple prompts and/or multiple runs.\n\n    Three scenarios:\n        - Single prompt, N runs:  ``prompts=\"text\", runs=N``\n        - Multiple prompts, 1 run each:  ``prompts=[\"a\", \"b\", \"c\"]``\n        - Multiple prompts, N runs each:  ``prompts=[\"a\", \"b\"], runs=N``\n\n    Args:\n        prompts: One or more text prompts to test.\n        synthesizer: Converts text to audio.\n        agent: The agent under test.\n        evaluator: Compares expected vs actual tool calls.\n        expect: The expected tool calls (same for every prompt).\n        runs: Number of times to run each prompt (default 1).\n        max_concurrency: Cap on simultaneous pipeline runs (``None`` = unlimited).\n\n    Returns:\n        BatchResult with per-run details and aggregate statistics.\n    \"\"\"\n    if isinstance(prompts, str):\n        prompts = [prompts]\n\n    semaphore = asyncio.Semaphore(max_concurrency) if max_concurrency else None\n\n    async def _single_run(prompt: str, run_index: int) -&gt; SingleRunResult:\n        async def _do() -&gt; SingleRunResult:\n            result = await run(\n                prompt=prompt,\n                synthesizer=synthesizer,\n                agent=agent,\n                evaluator=evaluator,\n                expect=expect,\n            )\n            return SingleRunResult(prompt=prompt, run_index=run_index, eval_result=result)\n\n        if semaphore:\n            async with semaphore:\n                return await _do()\n        return await _do()\n\n    tasks = [_single_run(prompt, i) for prompt in prompts for i in range(runs)]\n    results = await asyncio.gather(*tasks)\n    return BatchResult(runs=list(results))\n</code></pre>"},{"location":"reference/core/protocols/","title":"Protocols","text":"<p>Protocol definitions for russo extension points.</p>"},{"location":"reference/core/protocols/#russo._protocols","title":"_protocols","text":"<p>Protocol definitions for russo extension points.</p> <p>All extension points use typing.Protocol (structural subtyping). Users never need to inherit \u2014 if the object has the right methods, it works.</p>"},{"location":"reference/core/protocols/#russo._protocols.Synthesizer","title":"Synthesizer","text":"<p>               Bases: <code>Protocol</code></p> <p>Converts text into audio.</p> <p>Implement this to plug in any TTS provider (Google, OpenAI, ElevenLabs, etc.).</p>"},{"location":"reference/core/protocols/#russo._protocols.Agent","title":"Agent","text":"<p>               Bases: <code>Protocol</code></p> <p>The agent under test.</p> <p>Takes audio input and returns a response containing tool calls.</p>"},{"location":"reference/core/protocols/#russo._protocols.Evaluator","title":"Evaluator","text":"<p>               Bases: <code>Protocol</code></p> <p>Compares expected tool calls against actual tool calls.</p> <p>Implement this for custom matching logic (exact, semantic, partial, etc.).</p>"},{"location":"reference/core/protocols/#russo._protocols.ResponseParser","title":"ResponseParser","text":"<p>               Bases: <code>Protocol</code></p> <p>Parses a provider-specific raw response into a normalized AgentResponse.</p> <p>Implement this for each LLM provider format (Gemini, OpenAI, Anthropic, etc.).</p>"},{"location":"reference/core/types/","title":"Types","text":"<p>Core data types for russo. All types are Pydantic models.</p>"},{"location":"reference/core/types/#russo._types","title":"_types","text":"<p>Core data types for russo.</p> <p>All data flowing through the pipeline is a Pydantic model, giving us validation, serialization, and rich repr for free.</p>"},{"location":"reference/core/types/#russo._types.Audio","title":"Audio","text":"<p>               Bases: <code>BaseModel</code></p> <p>Audio data with format metadata.</p>"},{"location":"reference/core/types/#russo._types.Audio.save","title":"save","text":"<pre><code>save(path: str | Path) -&gt; Path\n</code></pre> <p>Save audio to a file. Wraps raw PCM in a WAV container if needed.</p> Usage <p>audio.save(\"output.wav\")</p> Source code in <code>src/russo/_types.py</code> <pre><code>def save(self, path: str | Path) -&gt; Path:\n    \"\"\"Save audio to a file. Wraps raw PCM in a WAV container if needed.\n\n    Usage:\n        audio.save(\"output.wav\")\n    \"\"\"\n    import wave\n\n    p = Path(path)\n    p.parent.mkdir(parents=True, exist_ok=True)\n\n    if p.suffix.lower() == \".wav\":\n        with wave.open(str(p), \"wb\") as wf:\n            wf.setnchannels(self.channels)\n            wf.setsampwidth(self.sample_width)\n            wf.setframerate(self.sample_rate)\n            wf.writeframes(self.data)\n    else:\n        # For non-WAV formats, write raw bytes\n        p.write_bytes(self.data)\n    return p\n</code></pre>"},{"location":"reference/core/types/#russo._types.ToolCall","title":"ToolCall","text":"<p>               Bases: <code>BaseModel</code></p> <p>A normalized tool/function call representation.</p> <p>Provider-agnostic \u2014 parsers convert provider-specific formats into this.</p>"},{"location":"reference/core/types/#russo._types.AgentResponse","title":"AgentResponse","text":"<p>               Bases: <code>BaseModel</code></p> <p>Normalized response from an agent, containing extracted tool calls.</p>"},{"location":"reference/core/types/#russo._types.AgentResponse.raw","title":"raw  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>raw: Any | None = None\n</code></pre> <p>The raw, unparsed response from the provider (for debugging).</p>"},{"location":"reference/core/types/#russo._types.ToolCallMatch","title":"ToolCallMatch","text":"<p>               Bases: <code>BaseModel</code></p> <p>Result of comparing a single expected tool call against actuals.</p>"},{"location":"reference/core/types/#russo._types.EvalResult","title":"EvalResult","text":"<p>               Bases: <code>BaseModel</code></p> <p>Full evaluation result for a test scenario.</p>"},{"location":"reference/core/types/#russo._types.EvalResult.match_rate","title":"match_rate  <code>property</code>","text":"<pre><code>match_rate: float\n</code></pre> <p>Fraction of expected tool calls that matched.</p>"},{"location":"reference/core/types/#russo._types.EvalResult.summary","title":"summary","text":"<pre><code>summary() -&gt; str\n</code></pre> <p>Human-readable summary of the evaluation.</p> Source code in <code>src/russo/_types.py</code> <pre><code>def summary(self) -&gt; str:\n    \"\"\"Human-readable summary of the evaluation.\"\"\"\n    status = \"PASSED\" if self.passed else \"FAILED\"\n    lines = [f\"{status} ({self.match_rate:.0%} match rate)\"]\n    for m in self.matches:\n        icon = \"+\" if m.matched else \"-\"\n        actual_str = f\" -&gt; {m.actual.name}({m.actual.arguments})\" if m.actual else \" -&gt; (no match)\"\n        lines.append(f\"  [{icon}] {m.expected.name}({m.expected.arguments}){actual_str}\")\n        if m.details:\n            lines.append(f\"      {m.details}\")\n    return \"\\n\".join(lines)\n</code></pre>"},{"location":"reference/core/types/#russo._types.SingleRunResult","title":"SingleRunResult","text":"<p>               Bases: <code>BaseModel</code></p> <p>Result of a single pipeline run within a batch.</p>"},{"location":"reference/core/types/#russo._types.BatchResult","title":"BatchResult","text":"<p>               Bases: <code>BaseModel</code></p> <p>Aggregated results from running the pipeline multiple times.</p> <p>Covers three scenarios: - Single prompt, N runs (reliability testing) - Multiple prompts, 1 run each (variant testing) - Multiple prompts, N runs each (full matrix)</p>"},{"location":"reference/core/types/#russo._types.BatchResult.passed","title":"passed  <code>property</code>","text":"<pre><code>passed: bool\n</code></pre> <p>True only if every single run passed.</p>"},{"location":"reference/core/types/#russo._types.BatchResult.pass_rate","title":"pass_rate  <code>property</code>","text":"<pre><code>pass_rate: float\n</code></pre> <p>Fraction of runs that passed.</p>"},{"location":"reference/core/types/#russo._types.BatchResult.match_rate","title":"match_rate  <code>property</code>","text":"<pre><code>match_rate: float\n</code></pre> <p>Average match rate across all runs.</p>"},{"location":"reference/core/types/#russo._types.BatchResult.summary","title":"summary","text":"<pre><code>summary() -&gt; str\n</code></pre> <p>Human-readable summary grouped by prompt.</p> Source code in <code>src/russo/_types.py</code> <pre><code>def summary(self) -&gt; str:\n    \"\"\"Human-readable summary grouped by prompt.\"\"\"\n    status = \"PASSED\" if self.passed else \"FAILED\"\n    lines = [\n        f\"{status} ({self.pass_rate:.0%} pass rate, {self.total} runs)\",\n        f\"  Passed: {self.passed_count}/{self.total}\",\n    ]\n\n    prompts: dict[str, list[SingleRunResult]] = {}\n    for r in self.runs:\n        prompts.setdefault(r.prompt, []).append(r)\n\n    for prompt, results in prompts.items():\n        prompt_passed = sum(1 for r in results if r.eval_result.passed)\n        lines.append(f\"  Prompt: {prompt!r}\")\n        lines.append(f\"    {prompt_passed}/{len(results)} passed\")\n        for r in results:\n            icon = \"+\" if r.eval_result.passed else \"-\"\n            lines.append(f\"    [{icon}] run {r.run_index}: {r.eval_result.match_rate:.0%} match\")\n\n    return \"\\n\".join(lines)\n</code></pre>"},{"location":"reference/evaluators/","title":"Evaluators","text":"<p>Built-in evaluators for comparing expected vs actual tool calls.</p>"},{"location":"reference/evaluators/#russo.evaluators","title":"evaluators","text":"<p>Built-in evaluators for comparing expected vs actual tool calls.</p>"},{"location":"reference/evaluators/#russo.evaluators.ExactEvaluator","title":"ExactEvaluator","text":"<pre><code>ExactEvaluator(*, match_order: bool = False, ignore_extra_args: bool = False, ignore_extra_calls: bool = True)\n</code></pre> <p>Evaluates tool calls by exact name + arguments match.</p> <p>Supports optional config for relaxed matching: - match_order: If True, tool calls must appear in the same order. - ignore_extra_args: If True, actual calls may contain extra arguments. - ignore_extra_calls: If True, extra actual calls don't cause failure.</p> Usage <p>evaluator = ExactEvaluator() result = evaluator.evaluate(expected=[...], actual=[...])</p> Source code in <code>src/russo/evaluators/exact.py</code> <pre><code>def __init__(\n    self,\n    *,\n    match_order: bool = False,\n    ignore_extra_args: bool = False,\n    ignore_extra_calls: bool = True,\n) -&gt; None:\n    self.match_order = match_order\n    self.ignore_extra_args = ignore_extra_args\n    self.ignore_extra_calls = ignore_extra_calls\n</code></pre>"},{"location":"reference/evaluators/#russo.evaluators.ExactEvaluator.evaluate","title":"evaluate","text":"<pre><code>evaluate(expected: list[ToolCall], actual: list[ToolCall]) -&gt; EvalResult\n</code></pre> <p>Compare expected tool calls against actual ones.</p> Source code in <code>src/russo/evaluators/exact.py</code> <pre><code>def evaluate(self, expected: list[ToolCall], actual: list[ToolCall]) -&gt; EvalResult:\n    \"\"\"Compare expected tool calls against actual ones.\"\"\"\n    if not expected:\n        return EvalResult(passed=True, expected=expected, actual=actual, matches=[])\n\n    matches: list[ToolCallMatch] = []\n    remaining_actual = list(actual)\n\n    for i, exp in enumerate(expected):\n        match = self._find_match(exp, remaining_actual, index=i if self.match_order else None)\n        matches.append(match)\n        if match.matched and match.actual in remaining_actual:\n            remaining_actual.remove(match.actual)\n\n    all_matched = all(m.matched for m in matches)\n\n    extra_calls_ok = self.ignore_extra_calls or len(remaining_actual) == 0\n    passed = all_matched and extra_calls_ok\n\n    if not extra_calls_ok and all_matched:\n        for leftover in remaining_actual:\n            matches.append(\n                ToolCallMatch(\n                    expected=ToolCall(name=\"(none)\", arguments={}),\n                    actual=leftover,\n                    matched=False,\n                    details=f\"Unexpected extra tool call: {leftover.name}\",\n                )\n            )\n\n    return EvalResult(passed=passed, expected=expected, actual=actual, matches=matches)\n</code></pre>"},{"location":"reference/evaluators/exact/","title":"Exact Evaluator","text":"<p>Exact-match evaluator for tool calls.</p>"},{"location":"reference/evaluators/exact/#russo.evaluators.exact","title":"exact","text":"<p>Exact-match evaluator for tool calls.</p>"},{"location":"reference/evaluators/exact/#russo.evaluators.exact.ExactEvaluator","title":"ExactEvaluator","text":"<pre><code>ExactEvaluator(*, match_order: bool = False, ignore_extra_args: bool = False, ignore_extra_calls: bool = True)\n</code></pre> <p>Evaluates tool calls by exact name + arguments match.</p> <p>Supports optional config for relaxed matching: - match_order: If True, tool calls must appear in the same order. - ignore_extra_args: If True, actual calls may contain extra arguments. - ignore_extra_calls: If True, extra actual calls don't cause failure.</p> Usage <p>evaluator = ExactEvaluator() result = evaluator.evaluate(expected=[...], actual=[...])</p> Source code in <code>src/russo/evaluators/exact.py</code> <pre><code>def __init__(\n    self,\n    *,\n    match_order: bool = False,\n    ignore_extra_args: bool = False,\n    ignore_extra_calls: bool = True,\n) -&gt; None:\n    self.match_order = match_order\n    self.ignore_extra_args = ignore_extra_args\n    self.ignore_extra_calls = ignore_extra_calls\n</code></pre>"},{"location":"reference/evaluators/exact/#russo.evaluators.exact.ExactEvaluator.evaluate","title":"evaluate","text":"<pre><code>evaluate(expected: list[ToolCall], actual: list[ToolCall]) -&gt; EvalResult\n</code></pre> <p>Compare expected tool calls against actual ones.</p> Source code in <code>src/russo/evaluators/exact.py</code> <pre><code>def evaluate(self, expected: list[ToolCall], actual: list[ToolCall]) -&gt; EvalResult:\n    \"\"\"Compare expected tool calls against actual ones.\"\"\"\n    if not expected:\n        return EvalResult(passed=True, expected=expected, actual=actual, matches=[])\n\n    matches: list[ToolCallMatch] = []\n    remaining_actual = list(actual)\n\n    for i, exp in enumerate(expected):\n        match = self._find_match(exp, remaining_actual, index=i if self.match_order else None)\n        matches.append(match)\n        if match.matched and match.actual in remaining_actual:\n            remaining_actual.remove(match.actual)\n\n    all_matched = all(m.matched for m in matches)\n\n    extra_calls_ok = self.ignore_extra_calls or len(remaining_actual) == 0\n    passed = all_matched and extra_calls_ok\n\n    if not extra_calls_ok and all_matched:\n        for leftover in remaining_actual:\n            matches.append(\n                ToolCallMatch(\n                    expected=ToolCall(name=\"(none)\", arguments={}),\n                    actual=leftover,\n                    matched=False,\n                    details=f\"Unexpected extra tool call: {leftover.name}\",\n                )\n            )\n\n    return EvalResult(passed=passed, expected=expected, actual=actual, matches=matches)\n</code></pre>"},{"location":"reference/parsers/","title":"Parsers","text":"<p>Built-in response parsers for normalizing provider-specific tool call formats.</p>"},{"location":"reference/parsers/#russo.parsers","title":"parsers","text":"<p>Built-in response parsers for normalizing provider-specific tool call formats.</p>"},{"location":"reference/parsers/#russo.parsers.GeminiResponseParser","title":"GeminiResponseParser","text":"<p>Parses Gemini GenerateContentResponse into AgentResponse.</p> <p>Handles the Gemini response format where tool calls appear as function_call parts in response.candidates[].content.parts[].</p> <p>Works with both the raw dict format and the google-genai SDK objects.</p> Usage <p>parser = GeminiResponseParser() response = parser.parse(gemini_raw_response)</p>"},{"location":"reference/parsers/#russo.parsers.GeminiResponseParser.parse","title":"parse","text":"<pre><code>parse(raw_response: Any) -&gt; AgentResponse\n</code></pre> <p>Parse a Gemini response into a normalized AgentResponse.</p> Source code in <code>src/russo/parsers/gemini.py</code> <pre><code>def parse(self, raw_response: Any) -&gt; AgentResponse:\n    \"\"\"Parse a Gemini response into a normalized AgentResponse.\"\"\"\n    tool_calls: list[ToolCall] = []\n\n    # Handle google-genai SDK response objects\n    candidates = _get_attr_or_key(raw_response, \"candidates\", [])\n    for candidate in candidates:\n        content = _get_attr_or_key(candidate, \"content\", None)\n        if content is None:\n            continue\n        parts = _get_attr_or_key(content, \"parts\", [])\n        for part in parts:\n            fc = _get_attr_or_key(part, \"function_call\", None)\n            if fc is not None:\n                name = _get_attr_or_key(fc, \"name\", \"\")\n                args = _get_attr_or_key(fc, \"args\", {})\n                if isinstance(args, str):\n                    import json\n\n                    args = json.loads(args)\n                tool_calls.append(ToolCall(name=name, arguments=dict(args) if args else {}))\n\n    return AgentResponse(tool_calls=tool_calls, raw=raw_response)\n</code></pre>"},{"location":"reference/parsers/#russo.parsers.OpenAIResponseParser","title":"OpenAIResponseParser","text":"<p>Parses OpenAI ChatCompletion responses into AgentResponse.</p> <p>Handles the OpenAI format where tool calls appear at: response.choices[].message.tool_calls[]</p> <p>Each tool call has: {id, type, function: {name, arguments}}.</p> <p>Works with both the raw dict format and the openai SDK objects.</p> Usage <p>parser = OpenAIResponseParser() response = parser.parse(openai_raw_response)</p>"},{"location":"reference/parsers/#russo.parsers.OpenAIResponseParser.parse","title":"parse","text":"<pre><code>parse(raw_response: Any) -&gt; AgentResponse\n</code></pre> <p>Parse an OpenAI response into a normalized AgentResponse.</p> Source code in <code>src/russo/parsers/openai.py</code> <pre><code>def parse(self, raw_response: Any) -&gt; AgentResponse:\n    \"\"\"Parse an OpenAI response into a normalized AgentResponse.\"\"\"\n    tool_calls: list[ToolCall] = []\n\n    choices = _get_attr_or_key(raw_response, \"choices\", [])\n    for choice in choices:\n        message = _get_attr_or_key(choice, \"message\", None)\n        if message is None:\n            continue\n        raw_tool_calls = _get_attr_or_key(message, \"tool_calls\", [])\n        if not raw_tool_calls:\n            continue\n        for tc in raw_tool_calls:\n            function = _get_attr_or_key(tc, \"function\", None)\n            if function is None:\n                continue\n            name = _get_attr_or_key(function, \"name\", \"\")\n            arguments_raw = _get_attr_or_key(function, \"arguments\", \"{}\")\n            if isinstance(arguments_raw, str):\n                try:\n                    arguments = json.loads(arguments_raw)\n                except (json.JSONDecodeError, TypeError):\n                    arguments = {}\n            elif isinstance(arguments_raw, dict):\n                arguments = arguments_raw\n            else:\n                arguments = {}\n            tool_calls.append(ToolCall(name=name, arguments=arguments))\n\n    return AgentResponse(tool_calls=tool_calls, raw=raw_response)\n</code></pre>"},{"location":"reference/parsers/gemini/","title":"Gemini Parser","text":"<p>Parser for Google Gemini function call responses.</p>"},{"location":"reference/parsers/gemini/#russo.parsers.gemini","title":"gemini","text":"<p>Parser for Google Gemini function call responses.</p>"},{"location":"reference/parsers/gemini/#russo.parsers.gemini.GeminiResponseParser","title":"GeminiResponseParser","text":"<p>Parses Gemini GenerateContentResponse into AgentResponse.</p> <p>Handles the Gemini response format where tool calls appear as function_call parts in response.candidates[].content.parts[].</p> <p>Works with both the raw dict format and the google-genai SDK objects.</p> Usage <p>parser = GeminiResponseParser() response = parser.parse(gemini_raw_response)</p>"},{"location":"reference/parsers/gemini/#russo.parsers.gemini.GeminiResponseParser.parse","title":"parse","text":"<pre><code>parse(raw_response: Any) -&gt; AgentResponse\n</code></pre> <p>Parse a Gemini response into a normalized AgentResponse.</p> Source code in <code>src/russo/parsers/gemini.py</code> <pre><code>def parse(self, raw_response: Any) -&gt; AgentResponse:\n    \"\"\"Parse a Gemini response into a normalized AgentResponse.\"\"\"\n    tool_calls: list[ToolCall] = []\n\n    # Handle google-genai SDK response objects\n    candidates = _get_attr_or_key(raw_response, \"candidates\", [])\n    for candidate in candidates:\n        content = _get_attr_or_key(candidate, \"content\", None)\n        if content is None:\n            continue\n        parts = _get_attr_or_key(content, \"parts\", [])\n        for part in parts:\n            fc = _get_attr_or_key(part, \"function_call\", None)\n            if fc is not None:\n                name = _get_attr_or_key(fc, \"name\", \"\")\n                args = _get_attr_or_key(fc, \"args\", {})\n                if isinstance(args, str):\n                    import json\n\n                    args = json.loads(args)\n                tool_calls.append(ToolCall(name=name, arguments=dict(args) if args else {}))\n\n    return AgentResponse(tool_calls=tool_calls, raw=raw_response)\n</code></pre>"},{"location":"reference/parsers/openai/","title":"OpenAI Parser","text":"<p>Parser for OpenAI chat completion tool call responses.</p>"},{"location":"reference/parsers/openai/#russo.parsers.openai","title":"openai","text":"<p>Parser for OpenAI chat completion tool call responses.</p>"},{"location":"reference/parsers/openai/#russo.parsers.openai.OpenAIResponseParser","title":"OpenAIResponseParser","text":"<p>Parses OpenAI ChatCompletion responses into AgentResponse.</p> <p>Handles the OpenAI format where tool calls appear at: response.choices[].message.tool_calls[]</p> <p>Each tool call has: {id, type, function: {name, arguments}}.</p> <p>Works with both the raw dict format and the openai SDK objects.</p> Usage <p>parser = OpenAIResponseParser() response = parser.parse(openai_raw_response)</p>"},{"location":"reference/parsers/openai/#russo.parsers.openai.OpenAIResponseParser.parse","title":"parse","text":"<pre><code>parse(raw_response: Any) -&gt; AgentResponse\n</code></pre> <p>Parse an OpenAI response into a normalized AgentResponse.</p> Source code in <code>src/russo/parsers/openai.py</code> <pre><code>def parse(self, raw_response: Any) -&gt; AgentResponse:\n    \"\"\"Parse an OpenAI response into a normalized AgentResponse.\"\"\"\n    tool_calls: list[ToolCall] = []\n\n    choices = _get_attr_or_key(raw_response, \"choices\", [])\n    for choice in choices:\n        message = _get_attr_or_key(choice, \"message\", None)\n        if message is None:\n            continue\n        raw_tool_calls = _get_attr_or_key(message, \"tool_calls\", [])\n        if not raw_tool_calls:\n            continue\n        for tc in raw_tool_calls:\n            function = _get_attr_or_key(tc, \"function\", None)\n            if function is None:\n                continue\n            name = _get_attr_or_key(function, \"name\", \"\")\n            arguments_raw = _get_attr_or_key(function, \"arguments\", \"{}\")\n            if isinstance(arguments_raw, str):\n                try:\n                    arguments = json.loads(arguments_raw)\n                except (json.JSONDecodeError, TypeError):\n                    arguments = {}\n            elif isinstance(arguments_raw, dict):\n                arguments = arguments_raw\n            else:\n                arguments = {}\n            tool_calls.append(ToolCall(name=name, arguments=arguments))\n\n    return AgentResponse(tool_calls=tool_calls, raw=raw_response)\n</code></pre>"},{"location":"reference/synthesizers/","title":"Synthesizers","text":"<p>Built-in audio synthesizers.</p>"},{"location":"reference/synthesizers/#russo.synthesizers","title":"synthesizers","text":"<p>Built-in audio synthesizers.</p>"},{"location":"reference/synthesizers/#russo.synthesizers.GoogleSynthesizer","title":"GoogleSynthesizer","text":"<pre><code>GoogleSynthesizer(*, voice: str = 'Kore', model: str = 'gemini-2.5-flash-preview-tts', api_key: str | None = None, vertexai: bool = False, project: str | None = None, location: str | None = None, audio_format: Literal['wav', 'mp3', 'pcm', 'ogg'] = 'wav', sample_rate: int = 24000)\n</code></pre> <p>Synthesizes audio from text using Google Gemini's TTS.</p> <p>Supports two auth modes:</p> <ol> <li> <p>Google AI API (api_key):     synth = GoogleSynthesizer(api_key=\"AIza...\")</p> </li> <li> <p>Vertex AI (ADC / GOOGLE_APPLICATION_CREDENTIALS):     synth = GoogleSynthesizer(vertexai=True, project=\"my-proj\", location=\"us-central1\")</p> </li> </ol> Source code in <code>src/russo/synthesizers/google.py</code> <pre><code>def __init__(\n    self,\n    *,\n    voice: str = \"Kore\",\n    model: str = \"gemini-2.5-flash-preview-tts\",\n    api_key: str | None = None,\n    vertexai: bool = False,\n    project: str | None = None,\n    location: str | None = None,\n    audio_format: Literal[\"wav\", \"mp3\", \"pcm\", \"ogg\"] = \"wav\",\n    sample_rate: int = 24000,\n) -&gt; None:\n    self.voice = voice\n    self.model = model\n    self.audio_format = audio_format\n    self.sample_rate = sample_rate\n\n    if api_key:\n        self._client = genai.Client(api_key=api_key)\n    elif vertexai:\n        self._client = genai.Client(\n            vertexai=True,\n            project=project,\n            location=location or \"us-central1\",\n        )\n    else:\n        # Fall back: let the SDK resolve from env (GOOGLE_API_KEY, ADC, etc.)\n        self._client = genai.Client()\n</code></pre>"},{"location":"reference/synthesizers/#russo.synthesizers.GoogleSynthesizer.synthesize","title":"synthesize  <code>async</code>","text":"<pre><code>synthesize(text: str) -&gt; Audio\n</code></pre> <p>Convert text to audio using Gemini TTS.</p> Source code in <code>src/russo/synthesizers/google.py</code> <pre><code>async def synthesize(self, text: str) -&gt; Audio:\n    \"\"\"Convert text to audio using Gemini TTS.\"\"\"\n    # Use explicit Content with text Part so the backend treats this as text-to-speech\n    # (raw string can be interpreted as non-audio request and trigger 1007).\n    contents = types.Content(\n        role=\"user\",\n        parts=[types.Part.from_text(text=text)],\n    )\n    response = await self._client.aio.models.generate_content(\n        model=self.model,\n        contents=contents,\n        config=types.GenerateContentConfig(\n            response_modalities=[\"AUDIO\"],\n            speech_config=types.SpeechConfig(\n                voice_config=types.VoiceConfig(\n                    prebuilt_voice_config=types.PrebuiltVoiceConfig(voice_name=self.voice),\n                ),\n            ),\n        ),\n    )\n    audio_data = b\"\"\n    if response.candidates:\n        for part in response.candidates[0].content.parts:\n            if part.inline_data and part.inline_data.data:\n                audio_data += part.inline_data.data\n\n    return Audio(\n        data=audio_data,\n        format=self.audio_format,\n        sample_rate=self.sample_rate,\n    )\n</code></pre>"},{"location":"reference/synthesizers/google/","title":"Google Synthesizer","text":"<p>Google Gemini TTS synthesizer.</p>"},{"location":"reference/synthesizers/google/#russo.synthesizers.google","title":"google","text":"<p>Google Gemini TTS synthesizer.</p>"},{"location":"reference/synthesizers/google/#russo.synthesizers.google.GoogleSynthesizer","title":"GoogleSynthesizer","text":"<pre><code>GoogleSynthesizer(*, voice: str = 'Kore', model: str = 'gemini-2.5-flash-preview-tts', api_key: str | None = None, vertexai: bool = False, project: str | None = None, location: str | None = None, audio_format: Literal['wav', 'mp3', 'pcm', 'ogg'] = 'wav', sample_rate: int = 24000)\n</code></pre> <p>Synthesizes audio from text using Google Gemini's TTS.</p> <p>Supports two auth modes:</p> <ol> <li> <p>Google AI API (api_key):     synth = GoogleSynthesizer(api_key=\"AIza...\")</p> </li> <li> <p>Vertex AI (ADC / GOOGLE_APPLICATION_CREDENTIALS):     synth = GoogleSynthesizer(vertexai=True, project=\"my-proj\", location=\"us-central1\")</p> </li> </ol> Source code in <code>src/russo/synthesizers/google.py</code> <pre><code>def __init__(\n    self,\n    *,\n    voice: str = \"Kore\",\n    model: str = \"gemini-2.5-flash-preview-tts\",\n    api_key: str | None = None,\n    vertexai: bool = False,\n    project: str | None = None,\n    location: str | None = None,\n    audio_format: Literal[\"wav\", \"mp3\", \"pcm\", \"ogg\"] = \"wav\",\n    sample_rate: int = 24000,\n) -&gt; None:\n    self.voice = voice\n    self.model = model\n    self.audio_format = audio_format\n    self.sample_rate = sample_rate\n\n    if api_key:\n        self._client = genai.Client(api_key=api_key)\n    elif vertexai:\n        self._client = genai.Client(\n            vertexai=True,\n            project=project,\n            location=location or \"us-central1\",\n        )\n    else:\n        # Fall back: let the SDK resolve from env (GOOGLE_API_KEY, ADC, etc.)\n        self._client = genai.Client()\n</code></pre>"},{"location":"reference/synthesizers/google/#russo.synthesizers.google.GoogleSynthesizer.synthesize","title":"synthesize  <code>async</code>","text":"<pre><code>synthesize(text: str) -&gt; Audio\n</code></pre> <p>Convert text to audio using Gemini TTS.</p> Source code in <code>src/russo/synthesizers/google.py</code> <pre><code>async def synthesize(self, text: str) -&gt; Audio:\n    \"\"\"Convert text to audio using Gemini TTS.\"\"\"\n    # Use explicit Content with text Part so the backend treats this as text-to-speech\n    # (raw string can be interpreted as non-audio request and trigger 1007).\n    contents = types.Content(\n        role=\"user\",\n        parts=[types.Part.from_text(text=text)],\n    )\n    response = await self._client.aio.models.generate_content(\n        model=self.model,\n        contents=contents,\n        config=types.GenerateContentConfig(\n            response_modalities=[\"AUDIO\"],\n            speech_config=types.SpeechConfig(\n                voice_config=types.VoiceConfig(\n                    prebuilt_voice_config=types.PrebuiltVoiceConfig(voice_name=self.voice),\n                ),\n            ),\n        ),\n    )\n    audio_data = b\"\"\n    if response.candidates:\n        for part in response.candidates[0].content.parts:\n            if part.inline_data and part.inline_data.data:\n                audio_data += part.inline_data.data\n\n    return Audio(\n        data=audio_data,\n        format=self.audio_format,\n        sample_rate=self.sample_rate,\n    )\n</code></pre>"},{"location":"tutorial/","title":"Tutorial","text":"<p>This tutorial covers every major component of russo in detail. Work through it sequentially, or jump to the section you need.</p>"},{"location":"tutorial/#overview","title":"Overview","text":"<p>russo's architecture is a simple pipeline with pluggable components:</p> <pre><code>graph LR\n    A[\"Text Prompt\"] --&gt; B[\"Synthesizer\"]\n    B --&gt;|Audio| C[\"Agent\"]\n    C --&gt;|AgentResponse| D[\"Evaluator\"]\n    D --&gt;|EvalResult| E[\"Pass / Fail\"]</code></pre> <p>Each component is defined by a protocol (structural typing). You don't need to inherit from anything \u2014 just implement the right method signature.</p>"},{"location":"tutorial/#sections","title":"Sections","text":"Section What You'll Learn Pipeline How <code>russo.run()</code> orchestrates the full flow Adapters Connecting to Gemini, OpenAI, HTTP, WebSocket, or custom agents Synthesizers Converting text prompts to audio Evaluators Comparing expected vs actual tool calls Caching Skipping TTS calls on repeated test runs pytest Plugin Markers, fixtures, CLI options, and reporting"},{"location":"tutorial/adapters/","title":"Adapters","text":"<p>Adapters connect russo to your agent. Each adapter implements the <code>Agent</code> protocol:</p> <pre><code>class Agent(Protocol):\n    async def run(self, audio: Audio) -&gt; AgentResponse: ...\n</code></pre> <p>russo ships with adapters for the most common patterns.</p>"},{"location":"tutorial/adapters/#built-in-adapters","title":"Built-in Adapters","text":""},{"location":"tutorial/adapters/#gemini-sdk","title":"Gemini SDK","text":"<pre><code>from russo.adapters import GeminiAgent, GeminiLiveAgent\n</code></pre> <p><code>GeminiAgent</code> \u2014 standard <code>generate_content</code> (request/response):</p> <pre><code>agent = GeminiAgent(\n    api_key=\"...\",\n    model=\"gemini-2.0-flash\",\n    tools=[{\"function_declarations\": [...]}],\n)\n</code></pre> <p><code>GeminiLiveAgent</code> \u2014 Live API over WebSocket (streaming/real-time):</p> <pre><code>agent = GeminiLiveAgent(\n    api_key=\"...\",\n    model=\"gemini-live-2.5-flash-native-audio\",\n    tools=[{\"function_declarations\": [...]}],\n)\n</code></pre>"},{"location":"tutorial/adapters/#openai-sdk","title":"OpenAI SDK","text":"<p>Note</p> <p>Requires the <code>openai</code> extra: <code>pip install \"russo[openai]\"</code></p> <pre><code>from russo.adapters import OpenAIAgent, OpenAIRealtimeAgent\n</code></pre> <p><code>OpenAIAgent</code> \u2014 Chat Completions with audio input:</p> <pre><code>agent = OpenAIAgent(\n    api_key=\"...\",\n    model=\"gpt-4o-audio-preview\",\n    tools=[...],\n)\n</code></pre> <p><code>OpenAIRealtimeAgent</code> \u2014 Realtime API over WebSocket:</p> <pre><code>agent = OpenAIRealtimeAgent(\n    api_key=\"...\",\n    model=\"gpt-4o-realtime-preview\",\n    tools=[...],\n)\n</code></pre>"},{"location":"tutorial/adapters/#http","title":"HTTP","text":"<p>Send audio to any HTTP endpoint:</p> <pre><code>from russo.adapters import HttpAgent\nfrom russo.parsers import GeminiResponseParser\n\nagent = HttpAgent(\n    url=\"https://my-agent.example.com/audio\",\n    parser=GeminiResponseParser(),\n)\n</code></pre>"},{"location":"tutorial/adapters/#websocket","title":"WebSocket","text":"<p>Note</p> <p>Requires the <code>ws</code> extra: <code>pip install \"russo[ws]\"</code></p> <pre><code>from russo.adapters import WebSocketAgent\n\nagent = WebSocketAgent(\n    url=\"wss://my-agent.example.com/ws\",\n    parser=my_parser,\n)\n</code></pre>"},{"location":"tutorial/adapters/#callable-custom","title":"Callable (Custom)","text":"<p>Wrap any async function:</p> <pre><code>import russo\n\n@russo.agent\nasync def my_agent(audio: russo.Audio) -&gt; russo.AgentResponse:\n    # Your custom logic here\n    result = await call_my_api(audio.data)\n    return russo.AgentResponse(\n        tool_calls=[russo.ToolCall(name=\"...\", arguments={...})]\n    )\n</code></pre> <p>Or use the class directly:</p> <pre><code>from russo.adapters import CallableAgent\n\nagent = CallableAgent(my_async_function)\n</code></pre>"},{"location":"tutorial/adapters/#custom-adapters","title":"Custom Adapters","text":"<p>You don't need to inherit from anything. Just implement the <code>run</code> method:</p> <pre><code>class MyCustomAgent:\n    async def run(self, audio: russo.Audio) -&gt; russo.AgentResponse:\n        # Send audio to your service\n        raw = await my_service.process(audio.data)\n        # Parse and return\n        return russo.AgentResponse(\n            tool_calls=[russo.ToolCall(name=raw[\"tool\"], arguments=raw[\"args\"])]\n        )\n</code></pre> <p>russo uses structural typing \u2014 if your class has <code>async def run(self, audio: Audio) -&gt; AgentResponse</code>, it's an Agent.</p>"},{"location":"tutorial/adapters/#api-reference","title":"API Reference","text":"<p>See the Adapters reference for full API docs on each adapter.</p>"},{"location":"tutorial/caching/","title":"Caching","text":"<p>TTS calls are slow and cost money. russo's caching layer saves synthesized audio to disk so repeated test runs skip the TTS call entirely.</p>"},{"location":"tutorial/caching/#how-it-works","title":"How It Works","text":"<p>Audio is cached by a deterministic hash of the prompt text (plus optional metadata like voice/model). On subsequent runs, if the cache has a hit, the synthesizer is bypassed.</p> <pre><code>First run:  prompt \u2192 TTS API \u2192 audio \u2192 cache \u2192 agent\nNext runs:  prompt \u2192 cache hit \u2192 audio \u2192 agent   (TTS skipped)\n</code></pre>"},{"location":"tutorial/caching/#cachedsynthesizer","title":"CachedSynthesizer","text":"<p>Wrap any synthesizer with <code>CachedSynthesizer</code>:</p> <pre><code>from russo import CachedSynthesizer\nfrom russo.synthesizers import GoogleSynthesizer\n\nsynth = CachedSynthesizer(GoogleSynthesizer(api_key=\"...\"))\n</code></pre>"},{"location":"tutorial/caching/#include-config-in-cache-key","title":"Include Config in Cache Key","text":"<p>If you change the voice or model, you want the cache to invalidate:</p> <pre><code>synth = CachedSynthesizer(\n    GoogleSynthesizer(api_key=\"...\", voice=\"Kore\"),\n    cache_key_extra={\"voice\": \"Kore\", \"model\": \"gemini-2.5-flash-preview-tts\"},\n)\n</code></pre>"},{"location":"tutorial/caching/#custom-cache-directory","title":"Custom Cache Directory","text":"<pre><code>from russo import AudioCache, CachedSynthesizer\n\ncache = AudioCache(Path(\"/tmp/russo_audio_cache\"))\nsynth = CachedSynthesizer(GoogleSynthesizer(api_key=\"...\"), cache=cache)\n</code></pre>"},{"location":"tutorial/caching/#disable-at-runtime","title":"Disable at Runtime","text":"<pre><code>synth = CachedSynthesizer(GoogleSynthesizer(api_key=\"...\"), enabled=False)\n</code></pre>"},{"location":"tutorial/caching/#audiocache","title":"AudioCache","text":"<p>The low-level cache stores audio as file pairs:</p> <ul> <li><code>&lt;key&gt;.audio</code> \u2014 raw audio bytes</li> <li><code>&lt;key&gt;.meta</code> \u2014 JSON metadata (format, sample rate, prompt)</li> </ul> <pre><code>from russo import AudioCache\n\ncache = AudioCache()               # default: .russo_cache/\ncache = AudioCache(Path(\"custom\")) # custom directory\n\n# Manual operations\ncache.get(\"abc123\")       # Audio | None\ncache.put(\"abc123\", audio, prompt=\"hello\")\ncache.size()              # number of cached entries\ncache.clear()             # remove all entries\n</code></pre>"},{"location":"tutorial/caching/#pytest-integration","title":"pytest Integration","text":"<p>The pytest plugin automatically wraps your synthesizer with caching. Control it via CLI:</p> <pre><code># Caching is ON by default\npytest\n\n# Disable caching\npytest --russo-no-cache\n\n# Clear cache before running\npytest --russo-clear-cache\n\n# Custom cache directory\npytest --russo-cache-dir /tmp/my_cache\n</code></pre>"},{"location":"tutorial/caching/#api-reference","title":"API Reference","text":"<p>See <code>AudioCache</code> and <code>CachedSynthesizer</code> for the full API docs.</p>"},{"location":"tutorial/evaluators/","title":"Evaluators","text":"<p>Evaluators compare expected tool calls against the actual tool calls returned by the agent.</p>"},{"location":"tutorial/evaluators/#protocol","title":"Protocol","text":"<pre><code>class Evaluator(Protocol):\n    def evaluate(self, expected: list[ToolCall], actual: list[ToolCall]) -&gt; EvalResult: ...\n</code></pre>"},{"location":"tutorial/evaluators/#built-in-exactevaluator","title":"Built-in: ExactEvaluator","text":"<p>The default evaluator performs exact name + arguments matching:</p> <pre><code>from russo.evaluators import ExactEvaluator\n\nevaluator = ExactEvaluator()\n</code></pre>"},{"location":"tutorial/evaluators/#configuration","title":"Configuration","text":"<pre><code>evaluator = ExactEvaluator(\n    match_order=False,         # True = tool calls must match in order\n    ignore_extra_args=False,   # True = actual may have extra arguments\n    ignore_extra_calls=True,   # True = extra actual calls don't cause failure\n)\n</code></pre>"},{"location":"tutorial/evaluators/#examples","title":"Examples","text":"<pre><code>from russo._types import ToolCall\n\nexpected = [ToolCall(name=\"book_flight\", arguments={\"from\": \"NYC\", \"to\": \"LA\"})]\nactual = [ToolCall(name=\"book_flight\", arguments={\"from\": \"NYC\", \"to\": \"LA\"})]\n\nresult = evaluator.evaluate(expected=expected, actual=actual)\nassert result.passed  # True\nassert result.match_rate == 1.0\n</code></pre> <p>With <code>ignore_extra_args=True</code>:</p> <pre><code>evaluator = ExactEvaluator(ignore_extra_args=True)\n\nexpected = [ToolCall(name=\"book_flight\", arguments={\"from\": \"NYC\"})]\nactual = [ToolCall(name=\"book_flight\", arguments={\"from\": \"NYC\", \"to\": \"LA\", \"class\": \"economy\"})]\n\nresult = evaluator.evaluate(expected=expected, actual=actual)\nassert result.passed  # True \u2014 extra args are ignored\n</code></pre>"},{"location":"tutorial/evaluators/#custom-evaluators","title":"Custom Evaluators","text":"<p>Implement the protocol for custom matching logic:</p> <pre><code>class FuzzyEvaluator:\n    \"\"\"Evaluator that uses fuzzy string matching on argument values.\"\"\"\n\n    def evaluate(self, expected: list[ToolCall], actual: list[ToolCall]) -&gt; EvalResult:\n        # Your custom logic here\n        ...\n</code></pre>"},{"location":"tutorial/evaluators/#api-reference","title":"API Reference","text":"<p>See <code>ExactEvaluator</code> for the full API docs.</p>"},{"location":"tutorial/pipeline/","title":"Pipeline","text":"<p>The pipeline is the core of russo. It chains three components together: Synthesizer \u2192 Agent \u2192 Evaluator.</p>"},{"location":"tutorial/pipeline/#russorun","title":"<code>russo.run()</code>","text":"<p>The <code>run</code> function is the main entry point:</p> <pre><code>result = await russo.run(\n    prompt=\"Book a flight from Berlin to Rome\",\n    synthesizer=my_synthesizer,\n    agent=my_agent,\n    evaluator=ExactEvaluator(),\n    expect=[russo.tool_call(\"book_flight\", from_city=\"Berlin\", to_city=\"Rome\")],\n)\n</code></pre> <p>All arguments are keyword-only. Here's what each does:</p> Argument Type Purpose <code>prompt</code> <code>str</code> Text to synthesize into audio <code>synthesizer</code> <code>Synthesizer</code> Converts text \u2192 audio <code>agent</code> <code>Agent</code> The agent under test (audio \u2192 tool calls) <code>evaluator</code> <code>Evaluator</code> Compares expected vs actual tool calls <code>expect</code> <code>list[ToolCall]</code> The tool calls you expect the agent to make"},{"location":"tutorial/pipeline/#what-happens-inside","title":"What Happens Inside","text":"<pre><code>async def run(*, prompt, synthesizer, agent, evaluator, expect):\n    audio = await synthesizer.synthesize(prompt)    # 1. Text \u2192 Audio\n    response = await agent.run(audio)               # 2. Audio \u2192 AgentResponse\n    return evaluator.evaluate(                      # 3. Compare\n        expected=expect,\n        actual=response.tool_calls,\n    )\n</code></pre> <p>That's it. Three steps. Each step is pluggable.</p>"},{"location":"tutorial/pipeline/#the-result","title":"The Result","text":"<p><code>russo.run()</code> returns an <code>EvalResult</code>:</p> <pre><code>result.passed       # bool \u2014 did all expected tool calls match?\nresult.match_rate   # float \u2014 fraction of expected calls that matched (0.0\u20131.0)\nresult.expected     # list[ToolCall] \u2014 what you expected\nresult.actual       # list[ToolCall] \u2014 what the agent returned\nresult.matches      # list[ToolCallMatch] \u2014 per-call match details\nresult.summary()    # str \u2014 human-readable summary\n</code></pre>"},{"location":"tutorial/pipeline/#assertions","title":"Assertions","text":"<p>Use <code>russo.assert_tool_calls()</code> for rich error messages:</p> <pre><code>russo.assert_tool_calls(result)\n# Raises ToolCallAssertionError with detailed diff if it fails\n</code></pre> <p>Or use standard assertions:</p> <pre><code>assert result.passed\nassert result.match_rate &gt;= 0.8  # at least 80% match\n</code></pre>"},{"location":"tutorial/pipeline/#api-reference","title":"API Reference","text":"<p>See <code>russo.run()</code> for the full API docs.</p>"},{"location":"tutorial/pytest-plugin/","title":"pytest Plugin","text":"<p>russo ships with a pytest plugin that's auto-discovered via the <code>pytest11</code> entry point. No configuration needed \u2014 just install russo and it's available.</p>"},{"location":"tutorial/pytest-plugin/#markers","title":"Markers","text":"<p>Use <code>@pytest.mark.russo</code> to declare test scenarios:</p> <pre><code>import pytest\nimport russo\n\n@pytest.mark.russo(\n    prompt=\"Book a flight from NYC to LA\",\n    expect=[russo.tool_call(\"book_flight\", from_city=\"NYC\", to_city=\"LA\")],\n)\nasync def test_book_flight(russo_result):\n    russo.assert_tool_calls(russo_result)\n</code></pre>"},{"location":"tutorial/pytest-plugin/#marker-arguments","title":"Marker Arguments","text":"Argument Type Description <code>prompt</code> <code>str</code> Text prompt to synthesize <code>expect</code> <code>list[ToolCall]</code> Expected tool calls"},{"location":"tutorial/pytest-plugin/#fixtures","title":"Fixtures","text":""},{"location":"tutorial/pytest-plugin/#required-fixtures-you-provide","title":"Required Fixtures (You Provide)","text":"<p>You must define these in your <code>conftest.py</code>:</p> <pre><code># conftest.py\nimport pytest\nfrom russo.synthesizers import GoogleSynthesizer\nfrom russo.adapters import GeminiLiveAgent\n\n@pytest.fixture(scope=\"session\")\ndef russo_synthesizer():\n    \"\"\"The TTS synthesizer to use.\"\"\"\n    return GoogleSynthesizer(api_key=\"...\")\n\n@pytest.fixture(scope=\"session\")\ndef russo_agent():\n    \"\"\"The agent under test.\"\"\"\n    return GeminiLiveAgent(api_key=\"...\", tools=[...])\n</code></pre>"},{"location":"tutorial/pytest-plugin/#built-in-fixtures","title":"Built-in Fixtures","text":"Fixture Scope Description <code>russo_result</code> function Runs the pipeline, returns <code>EvalResult</code> <code>russo_evaluator</code> function Default <code>ExactEvaluator()</code> \u2014 override to customize <code>russo_audio_cache</code> session <code>AudioCache</code> instance \u2014 override for custom dir"},{"location":"tutorial/pytest-plugin/#override-the-evaluator","title":"Override the Evaluator","text":"<pre><code>@pytest.fixture\ndef russo_evaluator():\n    from russo.evaluators import ExactEvaluator\n    return ExactEvaluator(ignore_extra_args=True, match_order=True)\n</code></pre>"},{"location":"tutorial/pytest-plugin/#cli-options","title":"CLI Options","text":"<pre><code>pytest --russo-report report.html    # Generate HTML report\npytest --russo-no-cache              # Disable audio caching\npytest --russo-clear-cache           # Clear cache before running\npytest --russo-cache-dir ./cache     # Custom cache directory\n</code></pre>"},{"location":"tutorial/pytest-plugin/#terminal-summary","title":"Terminal Summary","text":"<p>After tests complete, russo prints a summary:</p> <pre><code>\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550 russo results \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\nPASSED  test_book_flight (100% match rate)\nFAILED  test_weather (0% match rate)\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nTotal: 2 | Passed: 1 | Failed: 1\n</code></pre>"},{"location":"tutorial/pytest-plugin/#html-report","title":"HTML Report","text":"<p>Use <code>--russo-report</code> to generate a standalone HTML report:</p> <pre><code>pytest --russo-report russo_report.html\n</code></pre>"},{"location":"tutorial/pytest-plugin/#api-reference","title":"API Reference","text":"<p>See the pytest plugin reference for full API docs.</p>"},{"location":"tutorial/synthesizers/","title":"Synthesizers","text":"<p>Synthesizers convert text prompts into audio. This is the first step of the russo pipeline.</p>"},{"location":"tutorial/synthesizers/#protocol","title":"Protocol","text":"<pre><code>class Synthesizer(Protocol):\n    async def synthesize(self, text: str) -&gt; Audio: ...\n</code></pre>"},{"location":"tutorial/synthesizers/#built-in-google-tts","title":"Built-in: Google TTS","text":"<pre><code>from russo.synthesizers import GoogleSynthesizer\n\nsynth = GoogleSynthesizer(\n    api_key=\"...\",\n    voice=\"Kore\",                              # optional\n    model=\"gemini-2.5-flash-preview-tts\",      # optional\n)\n\naudio = await synth.synthesize(\"Book a flight from Berlin to Rome\")\naudio.save(\"output.wav\")  # save to file\n</code></pre>"},{"location":"tutorial/synthesizers/#authentication-modes","title":"Authentication Modes","text":"API Key (Google AI)Vertex AI <pre><code>synth = GoogleSynthesizer(api_key=\"AIza...\")\n</code></pre> <pre><code>synth = GoogleSynthesizer(\n    project=\"my-gcp-project\",\n    location=\"us-central1\",\n)\n</code></pre>"},{"location":"tutorial/synthesizers/#custom-synthesizers","title":"Custom Synthesizers","text":"<p>Implement the protocol \u2014 no inheritance needed:</p> <pre><code>class ElevenLabsSynthesizer:\n    def __init__(self, api_key: str, voice_id: str = \"default\"):\n        self.api_key = api_key\n        self.voice_id = voice_id\n\n    async def synthesize(self, text: str) -&gt; russo.Audio:\n        # Call ElevenLabs API\n        audio_bytes = await eleven_labs_tts(text, self.voice_id, self.api_key)\n        return russo.Audio(data=audio_bytes, format=\"mp3\")\n</code></pre>"},{"location":"tutorial/synthesizers/#caching","title":"Caching","text":"<p>Wrap any synthesizer with <code>CachedSynthesizer</code> to avoid repeated TTS calls:</p> <pre><code>from russo import CachedSynthesizer\n\ncached = CachedSynthesizer(\n    GoogleSynthesizer(api_key=\"...\"),\n    cache_key_extra={\"voice\": \"Kore\"},  # invalidate cache on config change\n)\n</code></pre> <p>See Caching for details.</p>"},{"location":"tutorial/synthesizers/#api-reference","title":"API Reference","text":"<p>See <code>GoogleSynthesizer</code> for the full API docs.</p>"}]}