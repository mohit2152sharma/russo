{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"russo","text":"<p> Testing framework for LLM tool-call accuracy \u2014 audio &amp; text </p> <p> </p> <p>Documentation: https://mohit2152sharma.github.io/russo</p> <p>Source Code: https://github.com/mohit2152sharma/russo</p> <p>russo is a testing framework for verifying that LLM agents make the correct tool calls when given audio (or text) input. Think of it as pytest for voice AI tool-calling accuracy.</p>"},{"location":"#why-russo","title":"Why russo?","text":"<p>Voice AI agents powered by LLMs increasingly use tool calling (function calling) to take actions \u2014 booking flights, controlling smart homes, querying databases. But how do you verify the agent calls the right tool with the right arguments when it hears a spoken command?</p> <p>russo solves this with a simple pipeline:</p> <pre><code>Text Prompt \u2192 Synthesizer (TTS) \u2192 Agent Under Test \u2192 Evaluator \u2192 Pass/Fail\n</code></pre>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Provider-agnostic \u2014 works with Gemini, OpenAI, or any custom agent via structural typing (protocols)</li> <li>Audio-first \u2014 synthesize text prompts to audio, send to your agent, evaluate tool calls</li> <li>pytest integration \u2014 use markers, fixtures, and familiar test patterns</li> <li>Built-in caching \u2014 skip TTS on repeated runs, saving time and money</li> <li>Extensible \u2014 swap synthesizers, agents, evaluators, and parsers without inheritance</li> </ul>"},{"location":"#quick-example","title":"Quick Example","text":"<pre><code>import russo\nfrom russo.synthesizers import GoogleSynthesizer\nfrom russo.adapters import GeminiLiveAgent\nfrom russo.evaluators import ExactEvaluator\n\nresult = await russo.run(\n    prompt=\"Book a flight from Berlin to Rome for tomorrow\",\n    synthesizer=GoogleSynthesizer(api_key=\"...\"),\n    agent=GeminiLiveAgent(api_key=\"...\", tools=[...]),\n    evaluator=ExactEvaluator(),\n    expect=[\n        russo.tool_call(\"book_flight\", from_city=\"Berlin\", to_city=\"Rome\"),\n    ],\n)\n\nassert result.passed\n</code></pre> <p>Or with pytest:</p> <pre><code>import pytest\nimport russo\n\n@pytest.mark.russo(\n    prompt=\"Book a flight from NYC to LA\",\n    expect=[russo.tool_call(\"book_flight\", from_city=\"NYC\", to_city=\"LA\")],\n)\nasync def test_book_flight(russo_result):\n    russo.assert_tool_calls(russo_result)\n</code></pre>"},{"location":"#architecture","title":"Architecture","text":"<p>russo uses a protocol-based design. You never need to inherit from base classes \u2014 if your object has the right methods, it works:</p> <pre><code>graph LR\n    A[Text Prompt] --&gt; B[Synthesizer]\n    B --&gt; C[Audio]\n    C --&gt; D[Agent]\n    D --&gt; E[AgentResponse]\n    E --&gt; F[Evaluator]\n    F --&gt; G[EvalResult]</code></pre> Protocol Method Purpose <code>Synthesizer</code> <code>async synthesize(text) \u2192 Audio</code> Convert text to audio <code>Agent</code> <code>async run(audio) \u2192 AgentResponse</code> Run the agent under test <code>Evaluator</code> <code>evaluate(expected, actual) \u2192 EvalResult</code> Compare tool calls <code>ResponseParser</code> <code>parse(raw) \u2192 AgentResponse</code> Normalize provider responses"},{"location":"#next-steps","title":"Next Steps","text":"<ul> <li>Installation \u2014 install russo and optional dependencies</li> <li>First Test \u2014 write your first tool-call test</li> <li>Tutorial \u2014 deep dive into every component</li> <li>API Reference \u2014 full API documentation</li> </ul>"},{"location":"concepts/architecture/","title":"Architecture","text":"<p>russo is designed around a simple pipeline with pluggable components connected by protocols.</p>"},{"location":"concepts/architecture/#the-pipeline","title":"The Pipeline","text":"<pre><code>graph TD\n    P[\"Text Prompt\"]\n    S[\"Synthesizer\"]\n    C[\"Cache Layer\"]\n    AG[\"Agent Under Test\"]\n    PR[\"Response Parser\"]\n    E[\"Evaluator\"]\n    R[\"EvalResult\"]\n\n    P --&gt; S\n    S &lt;-.-&gt; C\n    S --&gt;|Audio| AG\n    AG --&gt;|Raw Response| PR\n    PR --&gt;|AgentResponse| E\n    E --&gt; R</code></pre>"},{"location":"concepts/architecture/#flow","title":"Flow","text":"<ol> <li>Text Prompt \u2192 The natural language instruction (e.g., \"Book a flight from Berlin to Rome\")</li> <li>Synthesizer \u2192 Converts text to audio using a TTS provider. The cache layer intercepts here to avoid redundant API calls.</li> <li>Agent \u2192 The LLM agent under test receives the audio and returns tool calls. Agents may use a ResponseParser internally to normalize provider-specific formats.</li> <li>Evaluator \u2192 Compares expected tool calls against actual ones, producing a detailed <code>EvalResult</code>.</li> </ol>"},{"location":"concepts/architecture/#data-types","title":"Data Types","text":"<p>All data flows through Pydantic models:</p> <pre><code>classDiagram\n    class Audio {\n        +bytes data\n        +str format\n        +int sample_rate\n        +int channels\n        +save(path)\n    }\n\n    class ToolCall {\n        +str name\n        +dict arguments\n    }\n\n    class AgentResponse {\n        +list~ToolCall~ tool_calls\n        +Any raw\n    }\n\n    class EvalResult {\n        +bool passed\n        +list~ToolCall~ expected\n        +list~ToolCall~ actual\n        +list~ToolCallMatch~ matches\n        +match_rate() float\n        +summary() str\n    }\n\n    class ToolCallMatch {\n        +ToolCall expected\n        +ToolCall actual\n        +bool matched\n        +str details\n    }\n\n    AgentResponse --&gt; ToolCall\n    EvalResult --&gt; ToolCall\n    EvalResult --&gt; ToolCallMatch\n    ToolCallMatch --&gt; ToolCall</code></pre>"},{"location":"concepts/architecture/#design-principles","title":"Design Principles","text":""},{"location":"concepts/architecture/#protocol-based-structural-typing","title":"Protocol-based (Structural Typing)","text":"<p>russo uses <code>typing.Protocol</code> for all extension points. You never inherit from a base class \u2014 if your object has the right methods, it works:</p> <pre><code># This is a valid Synthesizer \u2014 no inheritance needed\nclass MySynth:\n    async def synthesize(self, text: str) -&gt; Audio:\n        ...\n</code></pre>"},{"location":"concepts/architecture/#async-first","title":"Async-first","text":"<p>The pipeline is fully async. Synthesizers and agents are <code>async</code> methods, making it natural to call external APIs without blocking.</p>"},{"location":"concepts/architecture/#provider-agnostic","title":"Provider-agnostic","text":"<p>The core pipeline knows nothing about Gemini, OpenAI, or any specific provider. Provider-specific logic lives in adapters and parsers.</p>"},{"location":"concepts/architecture/#pydantic-models","title":"Pydantic Models","text":"<p>All data types are Pydantic models, giving you:</p> <ul> <li>Automatic validation</li> <li>Serialization / deserialization</li> <li>Rich <code>repr</code> for debugging</li> <li>Type safety</li> </ul>"},{"location":"concepts/architecture/#module-layout","title":"Module Layout","text":"<pre><code>russo/\n\u251c\u2500\u2500 __init__.py          # Public API surface\n\u251c\u2500\u2500 _types.py            # Pydantic data models\n\u251c\u2500\u2500 _protocols.py        # Protocol definitions\n\u251c\u2500\u2500 _pipeline.py         # The run() function\n\u251c\u2500\u2500 _cache.py            # AudioCache + CachedSynthesizer\n\u251c\u2500\u2500 _helpers.py          # tool_call() + @agent decorator\n\u251c\u2500\u2500 _assertions.py       # assert_tool_calls()\n\u251c\u2500\u2500 adapters/            # Agent adapters (Gemini, OpenAI, HTTP, WS)\n\u251c\u2500\u2500 synthesizers/        # TTS providers (Google)\n\u251c\u2500\u2500 evaluators/          # Matching logic (ExactEvaluator)\n\u251c\u2500\u2500 parsers/             # Response normalizers (Gemini, OpenAI)\n\u251c\u2500\u2500 report/              # Terminal + HTML reporting\n\u251c\u2500\u2500 pytest_plugin.py     # pytest integration\n\u251c\u2500\u2500 cli.py               # CLI runner\n\u251c\u2500\u2500 config.py            # Config file loading\n\u251c\u2500\u2500 models.py            # Extended models for CLI/config mode\n\u251c\u2500\u2500 interfaces.py        # ABC interfaces for CLI/config mode\n\u251c\u2500\u2500 pipeline.py          # CLI pipeline runner\n\u2514\u2500\u2500 registry.py          # Component registry for config mode\n</code></pre> <p>Private modules (prefixed with <code>_</code>) contain the core API. Public modules contain provider-specific implementations and integrations.</p>"},{"location":"concepts/protocols/","title":"Protocols","text":"<p>russo uses Python's <code>typing.Protocol</code> for all extension points. This means structural subtyping \u2014 you don't need to inherit from a base class. If your class has the right methods with the right signatures, it satisfies the protocol.</p>"},{"location":"concepts/protocols/#why-protocols","title":"Why Protocols?","text":"<ul> <li>No coupling \u2014 your code never depends on russo base classes</li> <li>Duck typing with type safety \u2014 mypy/pyright verify protocol conformance at check time</li> <li>Runtime checkable \u2014 all russo protocols are <code>@runtime_checkable</code>, so <code>isinstance()</code> works too</li> </ul>"},{"location":"concepts/protocols/#the-four-protocols","title":"The Four Protocols","text":""},{"location":"concepts/protocols/#synthesizer","title":"Synthesizer","text":"<p>Converts text to audio.</p> <pre><code>@runtime_checkable\nclass Synthesizer(Protocol):\n    async def synthesize(self, text: str) -&gt; Audio: ...\n</code></pre> <p>Implementations: <code>GoogleSynthesizer</code>, <code>CachedSynthesizer</code>, or any class with a matching <code>synthesize</code> method.</p>"},{"location":"concepts/protocols/#agent","title":"Agent","text":"<p>The agent under test. Takes audio, returns tool calls.</p> <pre><code>@runtime_checkable\nclass Agent(Protocol):\n    async def run(self, audio: Audio) -&gt; AgentResponse: ...\n</code></pre> <p>Implementations: <code>GeminiAgent</code>, <code>GeminiLiveAgent</code>, <code>OpenAIAgent</code>, <code>OpenAIRealtimeAgent</code>, <code>HttpAgent</code>, <code>WebSocketAgent</code>, <code>CallableAgent</code>, or any class with a matching <code>run</code> method.</p>"},{"location":"concepts/protocols/#evaluator","title":"Evaluator","text":"<p>Compares expected tool calls against actual ones.</p> <pre><code>@runtime_checkable\nclass Evaluator(Protocol):\n    def evaluate(self, expected: list[ToolCall], actual: list[ToolCall]) -&gt; EvalResult: ...\n</code></pre> <p>Implementations: <code>ExactEvaluator</code>, or any class with a matching <code>evaluate</code> method.</p>"},{"location":"concepts/protocols/#responseparser","title":"ResponseParser","text":"<p>Normalizes provider-specific raw responses into <code>AgentResponse</code>.</p> <pre><code>@runtime_checkable\nclass ResponseParser(Protocol):\n    def parse(self, raw_response: Any) -&gt; AgentResponse: ...\n</code></pre> <p>Implementations: <code>GeminiResponseParser</code>, <code>OpenAIResponseParser</code>, or any class with a matching <code>parse</code> method.</p>"},{"location":"concepts/protocols/#implementing-a-protocol","title":"Implementing a Protocol","text":"<p>Just write a class with the right method:</p> <pre><code>import russo\n\nclass MyEvaluator:\n    def evaluate(\n        self,\n        expected: list[russo.ToolCall],\n        actual: list[russo.ToolCall],\n    ) -&gt; russo.EvalResult:\n        # Your custom matching logic\n        passed = len(expected) == len(actual)\n        return russo.EvalResult(\n            passed=passed,\n            expected=expected,\n            actual=actual,\n        )\n\n# Works with russo.run() \u2014 no inheritance needed\nresult = await russo.run(\n    ...,\n    evaluator=MyEvaluator(),\n    ...,\n)\n</code></pre>"},{"location":"concepts/protocols/#runtime-checking","title":"Runtime Checking","text":"<pre><code>from russo._protocols import Synthesizer, Agent, Evaluator\n\nassert isinstance(my_synth, Synthesizer)    # True if it has .synthesize()\nassert isinstance(my_agent, Agent)          # True if it has .run()\nassert isinstance(my_eval, Evaluator)       # True if it has .evaluate()\n</code></pre>"},{"location":"concepts/protocols/#api-reference","title":"API Reference","text":"<p>See the Protocols reference for full API docs.</p>"},{"location":"getting-started/first-test/","title":"First Test","text":"<p>This guide walks you through writing your first russo test. You'll need a Google AI API key for the synthesizer and an agent to test against.</p>"},{"location":"getting-started/first-test/#setup","title":"Setup","text":"<pre><code>pip install russo\nexport GOOGLE_API_KEY=\"your-api-key\"\n</code></pre>"},{"location":"getting-started/first-test/#the-pipeline","title":"The Pipeline","text":"<p>Every russo test follows the same flow:</p> <ol> <li>Synthesize \u2014 convert a text prompt to audio</li> <li>Run \u2014 send the audio to your agent</li> <li>Evaluate \u2014 compare the agent's tool calls against expectations</li> </ol>"},{"location":"getting-started/first-test/#writing-the-test","title":"Writing the Test","text":""},{"location":"getting-started/first-test/#step-1-define-your-agent","title":"Step 1: Define Your Agent","text":"<p>You can wrap any async function as an agent using the <code>@russo.agent</code> decorator:</p> <pre><code>import russo\n\n@russo.agent\nasync def my_agent(audio: russo.Audio) -&gt; russo.AgentResponse:\n    # Call your real agent here with audio.data\n    # For this example, we'll simulate a response\n    return russo.AgentResponse(\n        tool_calls=[\n            russo.ToolCall(name=\"book_flight\", arguments={\"from_city\": \"NYC\", \"to_city\": \"LA\"})\n        ]\n    )\n</code></pre>"},{"location":"getting-started/first-test/#step-2-run-the-pipeline","title":"Step 2: Run the Pipeline","text":"<pre><code>import asyncio\nfrom russo.synthesizers import GoogleSynthesizer\nfrom russo.evaluators import ExactEvaluator\n\nasync def main():\n    result = await russo.run(\n        prompt=\"Book a flight from New York to Los Angeles\",\n        synthesizer=GoogleSynthesizer(api_key=\"...\"),\n        agent=my_agent,\n        evaluator=ExactEvaluator(),\n        expect=[\n            russo.tool_call(\"book_flight\", from_city=\"NYC\", to_city=\"LA\"),\n        ],\n    )\n\n    print(result.summary())\n    # PASSED (100% match rate)\n    #   [+] book_flight({'from_city': 'NYC', 'to_city': 'LA'}) -&gt; book_flight(...)\n\nasyncio.run(main())\n</code></pre>"},{"location":"getting-started/first-test/#step-3-use-pytest","title":"Step 3: Use pytest","text":"<p>The most natural way to use russo is with pytest:</p> <pre><code># conftest.py\nimport pytest\nfrom russo.synthesizers import GoogleSynthesizer\nfrom russo.adapters import GeminiLiveAgent\n\n@pytest.fixture(scope=\"session\")\ndef russo_synthesizer():\n    return GoogleSynthesizer(api_key=\"...\")\n\n@pytest.fixture(scope=\"session\")\ndef russo_agent():\n    return GeminiLiveAgent(api_key=\"...\", model=\"gemini-2.0-flash-live-001\", tools=[...])\n</code></pre> <pre><code># test_flights.py\nimport pytest\nimport russo\n\n@pytest.mark.russo(\n    prompt=\"Book a flight from NYC to LA\",\n    expect=[russo.tool_call(\"book_flight\", from_city=\"NYC\", to_city=\"LA\")],\n)\nasync def test_book_flight(russo_result):\n    russo.assert_tool_calls(russo_result)\n\n@pytest.mark.russo(\n    prompt=\"What's the weather in Berlin?\",\n    expect=[russo.tool_call(\"get_weather\", city=\"Berlin\")],\n)\nasync def test_weather(russo_result):\n    assert russo_result.passed\n    assert russo_result.match_rate == 1.0\n</code></pre> <p>Run it:</p> <pre><code>pytest -v\n</code></pre>"},{"location":"getting-started/first-test/#whats-next","title":"What's Next?","text":"<ul> <li>Learn about adapters for different agent types</li> <li>Explore caching to speed up repeated test runs</li> <li>See the full API reference</li> </ul>"},{"location":"getting-started/installation/","title":"Installation","text":""},{"location":"getting-started/installation/#requirements","title":"Requirements","text":"<ul> <li>Python 3.12+</li> </ul>"},{"location":"getting-started/installation/#install-from-pypi","title":"Install from PyPI","text":"<pre><code>pip install russo\n</code></pre> <p>Or with uv:</p> <pre><code>uv add russo\n</code></pre>"},{"location":"getting-started/installation/#optional-dependencies","title":"Optional Dependencies","text":"<p>russo has optional extras for different LLM providers:</p> OpenAIWebSocketAll <pre><code>pip install \"russo[openai]\"\n</code></pre> <p>Adds support for <code>OpenAIAgent</code> and <code>OpenAIRealtimeAgent</code>.</p> <pre><code>pip install \"russo[ws]\"\n</code></pre> <p>Adds support for <code>WebSocketAgent</code> (generic WebSocket connections).</p> <pre><code>pip install \"russo[all]\"\n</code></pre> <p>Installs all optional dependencies.</p>"},{"location":"getting-started/installation/#for-development","title":"For Development","text":"<pre><code>git clone https://github.com/mohit2152sharma/russo.git\ncd russo\nuv sync --all-extras\n</code></pre> <p>This installs all dependencies including dev tools (ruff, pytest, basedpyright, etc.) and documentation tools (mkdocs-material).</p>"},{"location":"getting-started/installation/#verify-installation","title":"Verify Installation","text":"<pre><code>import russo\nprint(russo.__doc__)\n# russo \u2014 testing framework for LLM tool-call accuracy.\n</code></pre>"},{"location":"reference/","title":"API Reference","text":"<p>Complete API documentation for russo, auto-generated from docstrings.</p>"},{"location":"reference/#core","title":"Core","text":"<p>The main public API surface:</p> <ul> <li><code>russo</code> \u2014 top-level exports</li> <li><code>Types</code> \u2014 <code>Audio</code>, <code>ToolCall</code>, <code>AgentResponse</code>, <code>EvalResult</code>, <code>ToolCallMatch</code></li> <li><code>Pipeline</code> \u2014 <code>russo.run()</code></li> <li><code>Protocols</code> \u2014 <code>Synthesizer</code>, <code>Agent</code>, <code>Evaluator</code>, <code>ResponseParser</code></li> <li><code>Cache</code> \u2014 <code>AudioCache</code>, <code>CachedSynthesizer</code></li> <li><code>Assertions</code> \u2014 <code>assert_tool_calls</code>, <code>ToolCallAssertionError</code></li> </ul>"},{"location":"reference/#adapters","title":"Adapters","text":"<p>Agent adapters for different invocation styles:</p> <ul> <li><code>Gemini</code> \u2014 <code>GeminiAgent</code>, <code>GeminiLiveAgent</code></li> <li><code>OpenAI</code> \u2014 <code>OpenAIAgent</code>, <code>OpenAIRealtimeAgent</code></li> <li><code>HTTP</code> \u2014 <code>HttpAgent</code></li> <li><code>WebSocket</code> \u2014 <code>WebSocketAgent</code></li> <li><code>Callable</code> \u2014 <code>CallableAgent</code>, <code>@agent</code> decorator</li> </ul>"},{"location":"reference/#synthesizers","title":"Synthesizers","text":"<ul> <li><code>Google</code> \u2014 <code>GoogleSynthesizer</code></li> </ul>"},{"location":"reference/#evaluators","title":"Evaluators","text":"<ul> <li><code>Exact</code> \u2014 <code>ExactEvaluator</code></li> </ul>"},{"location":"reference/#parsers","title":"Parsers","text":"<ul> <li><code>Gemini</code> \u2014 <code>GeminiResponseParser</code></li> <li><code>OpenAI</code> \u2014 <code>OpenAIResponseParser</code></li> </ul>"},{"location":"reference/#integrations","title":"Integrations","text":"<ul> <li><code>pytest Plugin</code> \u2014 markers, fixtures, CLI options</li> </ul>"},{"location":"reference/pytest-plugin/","title":"pytest Plugin","text":"<p>pytest plugin for russo \u2014 auto-discovered via the <code>pytest11</code> entry point.</p>"},{"location":"reference/pytest-plugin/#russo.pytest_plugin","title":"pytest_plugin","text":"<p>pytest plugin for russo \u2014 auto-discovered via the pytest11 entry point.</p> <p>Provides: - <code>russo</code> marker for declarative test scenarios - <code>russo_result</code> fixture that runs the full pipeline - Terminal summary via <code>pytest_terminal_summary</code> hook - <code>--russo-report</code> CLI option for HTML report output</p>"},{"location":"reference/pytest-plugin/#russo.pytest_plugin.pytest_sessionstart","title":"pytest_sessionstart","text":"<pre><code>pytest_sessionstart(session: Session) -&gt; None\n</code></pre> <p>Clear audio cache if --russo-clear-cache was passed.</p> Source code in <code>src/russo/pytest_plugin.py</code> <pre><code>def pytest_sessionstart(session: pytest.Session) -&gt; None:\n    \"\"\"Clear audio cache if --russo-clear-cache was passed.\"\"\"\n    if session.config.getoption(\"russo_clear_cache\", default=False):\n        from pathlib import Path\n\n        cache_dir = session.config.getoption(\"russo_cache_dir\", default=\".russo_cache\")\n        cache = AudioCache(Path(cache_dir))\n        n = cache.size()\n        cache.clear()\n        # Use write_line via terminal writer if available\n        tw = session.config.get_terminal_writer()\n        tw.line(f\"russo: cleared {n} cached audio entries from {cache_dir}\")\n</code></pre>"},{"location":"reference/pytest-plugin/#russo.pytest_plugin.russo_audio_cache","title":"russo_audio_cache","text":"<pre><code>russo_audio_cache(request: FixtureRequest) -&gt; AudioCache\n</code></pre> <p>Session-scoped audio cache. Override in conftest.py to customize.</p> Source code in <code>src/russo/pytest_plugin.py</code> <pre><code>@pytest.fixture(scope=\"session\")\ndef russo_audio_cache(request: pytest.FixtureRequest) -&gt; AudioCache:\n    \"\"\"Session-scoped audio cache. Override in conftest.py to customize.\"\"\"\n    from pathlib import Path\n\n    cache_dir = request.config.getoption(\"russo_cache_dir\", default=\".russo_cache\")\n    return AudioCache(Path(cache_dir))\n</code></pre>"},{"location":"reference/pytest-plugin/#russo.pytest_plugin.russo_evaluator","title":"russo_evaluator","text":"<pre><code>russo_evaluator() -&gt; ExactEvaluator\n</code></pre> <p>Default evaluator \u2014 exact match. Override in conftest.py to customize.</p> Source code in <code>src/russo/pytest_plugin.py</code> <pre><code>@pytest.fixture\ndef russo_evaluator() -&gt; ExactEvaluator:\n    \"\"\"Default evaluator \u2014 exact match. Override in conftest.py to customize.\"\"\"\n    return ExactEvaluator()\n</code></pre>"},{"location":"reference/pytest-plugin/#russo.pytest_plugin.russo_result","title":"russo_result  <code>async</code>","text":"<pre><code>russo_result(request: FixtureRequest) -&gt; EvalResult | None\n</code></pre> <p>Run the russo pipeline based on the @pytest.mark.russo marker.</p> <p>Reads marker kwargs, resolves synthesizer/agent/evaluator fixtures, runs the pipeline, and returns the EvalResult.</p> <p>Returns None if the test has no russo marker (allows manual usage).</p> Source code in <code>src/russo/pytest_plugin.py</code> <pre><code>@pytest.fixture\nasync def russo_result(request: pytest.FixtureRequest) -&gt; EvalResult | None:\n    \"\"\"Run the russo pipeline based on the @pytest.mark.russo marker.\n\n    Reads marker kwargs, resolves synthesizer/agent/evaluator fixtures,\n    runs the pipeline, and returns the EvalResult.\n\n    Returns None if the test has no russo marker (allows manual usage).\n    \"\"\"\n    marker = request.node.get_closest_marker(\"russo\")\n    if marker is None:\n        return None\n\n    # Extract marker arguments\n    prompt: str = marker.kwargs.get(\"prompt\", \"\")\n    if not prompt and marker.args:\n        prompt = marker.args[0]\n\n    expect_raw: list[Any] = marker.kwargs.get(\"expect\", [])\n    expect: list[ToolCall] = [\n        tc if isinstance(tc, ToolCall) else ToolCall(**tc) for tc in expect_raw\n    ]\n\n    # Resolve fixtures\n    synthesizer = request.getfixturevalue(\"russo_synthesizer\")\n    agent = request.getfixturevalue(\"russo_agent\")\n\n    # Wrap synthesizer with caching (unless it's already cached or caching is off)\n    cache_enabled = request.config.getoption(\"russo_cache\", default=True)\n    if cache_enabled and not isinstance(synthesizer, CachedSynthesizer):\n        cache = request.getfixturevalue(\"russo_audio_cache\")\n        synthesizer = CachedSynthesizer(synthesizer, cache=cache)\n    elif not cache_enabled and isinstance(synthesizer, CachedSynthesizer):\n        synthesizer.enabled = False\n\n    try:\n        evaluator = request.getfixturevalue(\"russo_evaluator\")\n    except pytest.FixtureLookupError:\n        evaluator = ExactEvaluator()\n\n    result = await run(\n        prompt=prompt,\n        synthesizer=synthesizer,\n        agent=agent,\n        evaluator=evaluator,\n        expect=expect,\n    )\n\n    # Collect for reporting\n    _reporter.add(request.node.nodeid, result)\n\n    return result\n</code></pre>"},{"location":"reference/pytest-plugin/#russo.pytest_plugin.pytest_terminal_summary","title":"pytest_terminal_summary","text":"<pre><code>pytest_terminal_summary(terminalreporter: Any, exitstatus: int, config: Config) -&gt; None\n</code></pre> <p>Print russo results summary at the end of the test run.</p> Source code in <code>src/russo/pytest_plugin.py</code> <pre><code>def pytest_terminal_summary(\n    terminalreporter: Any,\n    exitstatus: int,  # noqa: ARG001\n    config: pytest.Config,\n) -&gt; None:\n    \"\"\"Print russo results summary at the end of the test run.\"\"\"\n    if _reporter.total == 0:\n        return\n\n    terminalreporter.write_line(_reporter.summary())\n\n    # Write HTML report if requested\n    report_path = config.getoption(\"--russo-report\", default=None)\n    if report_path:\n        _write_html_report(report_path)\n        terminalreporter.write_line(f\"\\nRusso HTML report written to: {report_path}\")\n</code></pre>"},{"location":"reference/pytest-plugin/#russo.pytest_plugin.pytest_sessionfinish","title":"pytest_sessionfinish","text":"<pre><code>pytest_sessionfinish(session: Session, exitstatus: int) -&gt; None\n</code></pre> <p>Reset global reporter state between sessions (relevant for xdist, etc.).</p> Source code in <code>src/russo/pytest_plugin.py</code> <pre><code>def pytest_sessionfinish(\n    session: pytest.Session, exitstatus: int\n) -&gt; None:  # noqa: ARG001\n    \"\"\"Reset global reporter state between sessions (relevant for xdist, etc.).\"\"\"\n    global _reporter  # noqa: PLW0603\n    _reporter = TerminalReporter()\n</code></pre>"},{"location":"reference/adapters/","title":"Adapters","text":"<p>Built-in agent adapters for different invocation styles.</p>"},{"location":"reference/adapters/#russo.adapters","title":"adapters","text":"<p>Built-in agent adapters for different invocation styles.</p>"},{"location":"reference/adapters/#russo.adapters.GeminiAgent","title":"GeminiAgent","text":"<pre><code>GeminiAgent(*, client: Any, model: str = 'gemini-2.0-flash', tools: list[Any] | None = None, system_instruction: str | None = None, config: Any | None = None)\n</code></pre> <p>Agent adapter that wraps a <code>google.genai.Client</code> object directly.</p> <p>Sends audio to Gemini via <code>client.aio.models.generate_content()</code> and auto-parses function-call responses with :class:<code>GeminiResponseParser</code>.</p> <p>Usage::</p> <pre><code>from google import genai\n\nclient = genai.Client(api_key=\"...\")\nagent = GeminiAgent(\n    client=client,\n    model=\"gemini-2.0-flash\",\n    tools=[book_flight_declaration],\n)\nresponse = await agent.run(audio)\n</code></pre> <p>For Vertex AI::</p> <pre><code>client = genai.Client(vertexai=True, project=\"my-project\", location=\"us-central1\")\nagent = GeminiAgent(client=client, model=\"gemini-2.0-flash\", tools=[...])\n</code></pre> PARAMETER DESCRIPTION <code>client</code> <p>A <code>google.genai.Client</code> instance.</p> <p> TYPE: <code>Any</code> </p> <code>model</code> <p>Model name (e.g. <code>\"gemini-2.0-flash\"</code>).</p> <p> TYPE: <code>str</code> DEFAULT: <code>'gemini-2.0-flash'</code> </p> <code>tools</code> <p>Gemini tool declarations (dicts or <code>types.Tool</code> objects).</p> <p> TYPE: <code>list[Any] | None</code> DEFAULT: <code>None</code> </p> <code>system_instruction</code> <p>Optional system instruction prepended to the request.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>config</code> <p>Full <code>GenerateContentConfig</code> override. When provided,     <code>tools</code> and <code>system_instruction</code> are ignored.</p> <p> TYPE: <code>Any | None</code> DEFAULT: <code>None</code> </p> Source code in <code>src/russo/adapters/gemini.py</code> <pre><code>def __init__(\n    self,\n    *,\n    client: Any,\n    model: str = \"gemini-2.0-flash\",\n    tools: list[Any] | None = None,\n    system_instruction: str | None = None,\n    config: Any | None = None,\n) -&gt; None:\n    \"\"\"\n    Args:\n        client: A ``google.genai.Client`` instance.\n        model: Model name (e.g. ``\"gemini-2.0-flash\"``).\n        tools: Gemini tool declarations (dicts or ``types.Tool`` objects).\n        system_instruction: Optional system instruction prepended to the request.\n        config: Full ``GenerateContentConfig`` override. When provided,\n                ``tools`` and ``system_instruction`` are ignored.\n    \"\"\"\n    self.client = client\n    self.model = model\n    self.tools = tools\n    self.system_instruction = system_instruction\n    self.config = config\n    self._parser = GeminiResponseParser()\n</code></pre>"},{"location":"reference/adapters/#russo.adapters.GeminiAgent.run","title":"run  <code>async</code>","text":"<pre><code>run(audio: Audio) -&gt; AgentResponse\n</code></pre> <p>Send audio to Gemini and parse the tool-call response.</p> Source code in <code>src/russo/adapters/gemini.py</code> <pre><code>async def run(self, audio: Audio) -&gt; AgentResponse:\n    \"\"\"Send audio to Gemini and parse the tool-call response.\"\"\"\n    from google.genai import types\n\n    data, mime_type = _prepare_audio(audio)\n    contents = [types.Part.from_bytes(data=data, mime_type=mime_type)]\n\n    config = self._build_config(types)\n    logger.debug(\n        \"Sending %d bytes of %s audio to %s\", len(data), mime_type, self.model\n    )\n\n    response = await self.client.aio.models.generate_content(\n        model=self.model,\n        contents=contents,\n        config=config,\n    )\n\n    return self._parser.parse(response)\n</code></pre>"},{"location":"reference/adapters/#russo.adapters.GeminiLiveAgent","title":"GeminiLiveAgent","text":"<pre><code>GeminiLiveAgent(*, client: Any | None = None, session: Any | None = None, model: str = 'gemini-2.0-flash-live-preview-04-09', tools: list[Any] | None = None, system_instruction: str | None = None, config: Any | None = None, response_timeout: float = 30.0)\n</code></pre> <p>Agent adapter for Gemini's Live API (streaming/real-time).</p> <p>Connects via <code>client.aio.live.connect()</code>, sends audio as a turn-based content message, and collects function-call responses.</p> <p>Accepts either:</p> <ul> <li>A <code>google.genai.Client</code> (opens a new session per <code>run()</code>)</li> <li>A pre-existing Live session (reuses it)</li> </ul> <p>Usage with client::</p> <pre><code>from google import genai\n\nclient = genai.Client(vertexai=True, project=\"my-project\", location=\"us-central1\")\nagent = GeminiLiveAgent(\n    client=client,\n    model=\"gemini-2.0-flash-live-preview-04-09\",\n    tools=[book_flight_declaration],\n)\nresponse = await agent.run(audio)\n</code></pre> <p>Usage with pre-existing session::</p> <pre><code>config = types.LiveConnectConfig(tools=[...], response_modalities=[\"TEXT\"])\nasync with client.aio.live.connect(model=\"...\", config=config) as session:\n    agent = GeminiLiveAgent(session=session)\n    response = await agent.run(audio)\n</code></pre> Note <p>Model names differ by backend:</p> <ul> <li>Vertex AI: <code>gemini-2.0-flash-live-preview-04-09</code></li> <li>Google AI: <code>gemini-live-2.5-flash-preview</code></li> </ul> PARAMETER DESCRIPTION <code>client</code> <p>A <code>google.genai.Client</code> instance. Creates a new session per <code>run()</code>.</p> <p> TYPE: <code>Any | None</code> DEFAULT: <code>None</code> </p> <code>session</code> <p>A pre-existing Live session (from <code>client.aio.live.connect()</code>). When provided, <code>tools</code>/<code>system_instruction</code>/<code>config</code> are ignored (the session was already configured at connect time).</p> <p> TYPE: <code>Any | None</code> DEFAULT: <code>None</code> </p> <code>model</code> <p>Live model name.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'gemini-2.0-flash-live-preview-04-09'</code> </p> <code>tools</code> <p>Gemini tool declarations.</p> <p> TYPE: <code>list[Any] | None</code> DEFAULT: <code>None</code> </p> <code>system_instruction</code> <p>System instruction for the session.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>config</code> <p>Full <code>LiveConnectConfig</code> override.  When provided, <code>tools</code>, <code>system_instruction</code>, and <code>response_modalities</code> are ignored.</p> <p> TYPE: <code>Any | None</code> DEFAULT: <code>None</code> </p> <code>response_timeout</code> <p>Max seconds to wait for a complete response turn.</p> <p> TYPE: <code>float</code> DEFAULT: <code>30.0</code> </p> Source code in <code>src/russo/adapters/gemini.py</code> <pre><code>def __init__(\n    self,\n    *,\n    client: Any | None = None,\n    session: Any | None = None,\n    model: str = \"gemini-2.0-flash-live-preview-04-09\",\n    tools: list[Any] | None = None,\n    system_instruction: str | None = None,\n    config: Any | None = None,\n    response_timeout: float = 30.0,\n) -&gt; None:\n    \"\"\"\n    Args:\n        client: A ``google.genai.Client`` instance. Creates a new session per ``run()``.\n        session: A pre-existing Live session (from ``client.aio.live.connect()``).\n            When provided, ``tools``/``system_instruction``/``config`` are ignored\n            (the session was already configured at connect time).\n        model: Live model name.\n        tools: Gemini tool declarations.\n        system_instruction: System instruction for the session.\n        config: Full ``LiveConnectConfig`` override.  When provided,\n            ``tools``, ``system_instruction``, and ``response_modalities`` are ignored.\n        response_timeout: Max seconds to wait for a complete response turn.\n    \"\"\"\n    if client is None and session is None:\n        msg = \"Provide either 'client' (genai.Client) or 'session' (live session)\"\n        raise ValueError(msg)\n    self.client = client\n    self.session = session\n    self.model = model\n    self.tools = tools\n    self.system_instruction = system_instruction\n    self.config = config\n    self.response_timeout = response_timeout\n</code></pre>"},{"location":"reference/adapters/#russo.adapters.GeminiLiveAgent.run","title":"run  <code>async</code>","text":"<pre><code>run(audio: Audio) -&gt; AgentResponse\n</code></pre> <p>Send audio to a Live session and collect function calls.</p> Source code in <code>src/russo/adapters/gemini.py</code> <pre><code>async def run(self, audio: Audio) -&gt; AgentResponse:\n    \"\"\"Send audio to a Live session and collect function calls.\"\"\"\n    if self.session is not None:\n        return await self._run_on(self.session, audio)\n\n    from google.genai import types\n\n    assert self.client is not None  # guaranteed by __init__\n    config = self._build_config(types)\n    async with self.client.aio.live.connect(\n        model=self.model, config=config\n    ) as session:\n        return await self._run_on(session, audio)\n</code></pre>"},{"location":"reference/adapters/#russo.adapters.HttpAgent","title":"HttpAgent","text":"<pre><code>HttpAgent(*, url: str, parser: ResponseParser | None = None, method: str = 'POST', headers: dict[str, str] | None = None, audio_field: str = 'audio', format_field: str = 'format', timeout: float = 60.0)\n</code></pre> <p>Agent adapter that sends audio to an HTTP endpoint.</p> <p>Sends audio as base64-encoded JSON and parses the response using an optional ResponseParser.</p> Usage <p>agent = HttpAgent(     url=\"http://localhost:8000/voice-agent\",     parser=russo.parsers.GeminiResponseParser(), ) response = await agent.run(audio)</p> Source code in <code>src/russo/adapters/http.py</code> <pre><code>def __init__(\n    self,\n    *,\n    url: str,\n    parser: ResponseParser | None = None,\n    method: str = \"POST\",\n    headers: dict[str, str] | None = None,\n    audio_field: str = \"audio\",\n    format_field: str = \"format\",\n    timeout: float = 60.0,\n) -&gt; None:\n    self.url = url\n    self.parser = parser\n    self.method = method\n    self.headers = headers or {}\n    self.audio_field = audio_field\n    self.format_field = format_field\n    self.timeout = timeout\n</code></pre>"},{"location":"reference/adapters/#russo.adapters.HttpAgent.run","title":"run  <code>async</code>","text":"<pre><code>run(audio: Audio) -&gt; AgentResponse\n</code></pre> <p>Send audio to the HTTP endpoint and parse the response.</p> Source code in <code>src/russo/adapters/http.py</code> <pre><code>async def run(self, audio: Audio) -&gt; AgentResponse:\n    \"\"\"Send audio to the HTTP endpoint and parse the response.\"\"\"\n    payload = {\n        self.audio_field: base64.b64encode(audio.data).decode(\"ascii\"),\n        self.format_field: audio.format,\n    }\n\n    raw_response = await self._send(payload)\n\n    if self.parser:\n        return self.parser.parse(raw_response)\n\n    return self._default_parse(raw_response)\n</code></pre>"},{"location":"reference/adapters/#russo.adapters.OpenAIAgent","title":"OpenAIAgent","text":"<pre><code>OpenAIAgent(*, client: Any, model: str = 'gpt-4o-audio-preview', tools: list[Any] | None = None, system_prompt: str | None = None, extra_create_kwargs: dict[str, Any] | None = None)\n</code></pre> <p>Agent adapter that wraps an <code>AsyncOpenAI</code> client for Chat Completions.</p> <p>Sends audio via the Chat Completions API and auto-parses tool-call responses with :class:<code>OpenAIResponseParser</code>.</p> <p>Usage::</p> <pre><code>from openai import AsyncOpenAI\n\nclient = AsyncOpenAI()\nagent = OpenAIAgent(\n    client=client,\n    model=\"gpt-4o-audio-preview\",\n    tools=[{\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"book_flight\",\n            \"parameters\": {\"type\": \"object\", \"properties\": {...}},\n        },\n    }],\n)\nresponse = await agent.run(audio)\n</code></pre> PARAMETER DESCRIPTION <code>client</code> <p>An <code>openai.AsyncOpenAI</code> instance.</p> <p> TYPE: <code>Any</code> </p> <code>model</code> <p>Model name supporting audio input.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'gpt-4o-audio-preview'</code> </p> <code>tools</code> <p>OpenAI tool definitions (function-calling format).</p> <p> TYPE: <code>list[Any] | None</code> DEFAULT: <code>None</code> </p> <code>system_prompt</code> <p>Optional system message prepended to the conversation.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>extra_create_kwargs</code> <p>Additional kwargs forwarded to <code>client.chat.completions.create()</code>.</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> Source code in <code>src/russo/adapters/openai.py</code> <pre><code>def __init__(\n    self,\n    *,\n    client: Any,\n    model: str = \"gpt-4o-audio-preview\",\n    tools: list[Any] | None = None,\n    system_prompt: str | None = None,\n    extra_create_kwargs: dict[str, Any] | None = None,\n) -&gt; None:\n    \"\"\"\n    Args:\n        client: An ``openai.AsyncOpenAI`` instance.\n        model: Model name supporting audio input.\n        tools: OpenAI tool definitions (function-calling format).\n        system_prompt: Optional system message prepended to the conversation.\n        extra_create_kwargs: Additional kwargs forwarded to\n            ``client.chat.completions.create()``.\n    \"\"\"\n    self.client = client\n    self.model = model\n    self.tools = tools\n    self.system_prompt = system_prompt\n    self.extra_create_kwargs = extra_create_kwargs or {}\n    self._parser = OpenAIResponseParser()\n</code></pre>"},{"location":"reference/adapters/#russo.adapters.OpenAIAgent.run","title":"run  <code>async</code>","text":"<pre><code>run(audio: Audio) -&gt; AgentResponse\n</code></pre> <p>Send audio via Chat Completions and parse the tool-call response.</p> Source code in <code>src/russo/adapters/openai.py</code> <pre><code>async def run(self, audio: Audio) -&gt; AgentResponse:\n    \"\"\"Send audio via Chat Completions and parse the tool-call response.\"\"\"\n    audio_b64 = base64.b64encode(audio.data).decode(\"ascii\")\n\n    messages: list[dict[str, Any]] = []\n    if self.system_prompt:\n        messages.append({\"role\": \"system\", \"content\": self.system_prompt})\n\n    messages.append(\n        {\n            \"role\": \"user\",\n            \"content\": [\n                {\n                    \"type\": \"input_audio\",\n                    \"input_audio\": {\"data\": audio_b64, \"format\": audio.format},\n                }\n            ],\n        }\n    )\n\n    kwargs: dict[str, Any] = {\n        \"model\": self.model,\n        \"messages\": messages,\n        **self.extra_create_kwargs,\n    }\n    if self.tools:\n        kwargs[\"tools\"] = self.tools\n\n    logger.debug(\"Sending %d bytes of %s audio to %s\", len(audio.data), audio.format, self.model)\n\n    response = await self.client.chat.completions.create(**kwargs)\n    return self._parser.parse(response)\n</code></pre>"},{"location":"reference/adapters/#russo.adapters.OpenAIRealtimeAgent","title":"OpenAIRealtimeAgent","text":"<pre><code>OpenAIRealtimeAgent(*, client: Any | None = None, connection: Any | None = None, model: str = 'gpt-4o-realtime-preview', tools: list[Any] | None = None, response_timeout: float = 30.0)\n</code></pre> <p>Agent adapter for OpenAI's Realtime API.</p> <p>Connects via the SDK's <code>client.beta.realtime.connect()</code> interface, sends audio, and collects <code>response.function_call_arguments.done</code> events.</p> <p>Accepts either:</p> <ul> <li>An <code>AsyncOpenAI</code> client (creates a new connection per <code>run()</code>)</li> <li>A pre-existing realtime connection (reuses it, no session config sent)</li> </ul> <p>Usage with client::</p> <pre><code>from openai import AsyncOpenAI\n\nclient = AsyncOpenAI()\nagent = OpenAIRealtimeAgent(\n    client=client,\n    model=\"gpt-4o-realtime-preview\",\n    tools=[{\n        \"type\": \"function\",\n        \"name\": \"book_flight\",\n        \"description\": \"Book a flight\",\n        \"parameters\": {\"type\": \"object\", \"properties\": {...}},\n    }],\n)\nresponse = await agent.run(audio)\n</code></pre> <p>Usage with pre-existing connection::</p> <pre><code>async with client.beta.realtime.connect(model=\"gpt-4o-realtime-preview\") as conn:\n    agent = OpenAIRealtimeAgent(connection=conn)\n    response = await agent.run(audio)\n</code></pre> Note <p>The Realtime API expects pcm16 audio at 24 kHz mono by default. If you pass WAV audio, the adapter automatically strips the WAV header to extract raw PCM frames.</p> PARAMETER DESCRIPTION <code>client</code> <p>An <code>openai.AsyncOpenAI</code> instance. Mutually preferred with connection.</p> <p> TYPE: <code>Any | None</code> DEFAULT: <code>None</code> </p> <code>connection</code> <p>A pre-existing realtime connection (from <code>client.beta.realtime.connect()</code>).</p> <p> TYPE: <code>Any | None</code> DEFAULT: <code>None</code> </p> <code>model</code> <p>Realtime model name.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'gpt-4o-realtime-preview'</code> </p> <code>tools</code> <p>Tool definitions sent during session configuration.</p> <p> TYPE: <code>list[Any] | None</code> DEFAULT: <code>None</code> </p> <code>response_timeout</code> <p>Max seconds to wait for a complete response.</p> <p> TYPE: <code>float</code> DEFAULT: <code>30.0</code> </p> Source code in <code>src/russo/adapters/openai.py</code> <pre><code>def __init__(\n    self,\n    *,\n    client: Any | None = None,\n    connection: Any | None = None,\n    model: str = \"gpt-4o-realtime-preview\",\n    tools: list[Any] | None = None,\n    response_timeout: float = 30.0,\n) -&gt; None:\n    \"\"\"\n    Args:\n        client: An ``openai.AsyncOpenAI`` instance. Mutually preferred with *connection*.\n        connection: A pre-existing realtime connection (from ``client.beta.realtime.connect()``).\n        model: Realtime model name.\n        tools: Tool definitions sent during session configuration.\n        response_timeout: Max seconds to wait for a complete response.\n    \"\"\"\n    if client is None and connection is None:\n        msg = \"Provide either 'client' (AsyncOpenAI) or 'connection' (realtime connection)\"\n        raise ValueError(msg)\n    self.client = client\n    self.connection = connection\n    self.model = model\n    self.tools = tools\n    self.response_timeout = response_timeout\n</code></pre>"},{"location":"reference/adapters/#russo.adapters.OpenAIRealtimeAgent.run","title":"run  <code>async</code>","text":"<pre><code>run(audio: Audio) -&gt; AgentResponse\n</code></pre> <p>Send audio via the Realtime API and collect function calls.</p> Source code in <code>src/russo/adapters/openai.py</code> <pre><code>async def run(self, audio: Audio) -&gt; AgentResponse:\n    \"\"\"Send audio via the Realtime API and collect function calls.\"\"\"\n    if self.connection is not None:\n        return await self._run_on(self.connection, audio, configure=False)\n\n    async with self.client.beta.realtime.connect(model=self.model) as conn:\n        return await self._run_on(conn, audio, configure=True)\n</code></pre>"},{"location":"reference/adapters/#russo.adapters.WebSocketAgent","title":"WebSocketAgent","text":"<pre><code>WebSocketAgent(*, url: str, parser: ResponseParser | None = None, headers: dict[str, str] | None = None, send_bytes: bool = False, audio_field: str = 'audio', format_field: str = 'format', response_timeout: float = 30.0, max_messages: int = 100, on_send: Callable[[Audio], str | bytes] | None = None, is_complete: Callable[[list[Any]], bool] | None = None, aggregate: Callable[[list[Any]], Any] | None = None, open_timeout: float = 10.0, close_timeout: float = 5.0, extra_ws_kwargs: dict[str, Any] | None = None)\n</code></pre> <p>Agent adapter that communicates over WebSocket.</p> <p>Connects to the endpoint, sends audio, collects response messages until a completion condition is met, then parses tool calls.</p> <p>Supports two send modes: - json (default): sends <code>{\"audio\": \"&lt;base64&gt;\", \"format\": \"wav\"}</code> - bytes: sends raw audio bytes directly on the wire</p> <p>And two ways to customize the protocol: - on_send: transform the Audio into whatever your server expects - is_complete: decide when to stop collecting response messages</p> Usage Source code in <code>src/russo/adapters/websocket.py</code> <pre><code>def __init__(\n    self,\n    *,\n    url: str,\n    parser: ResponseParser | None = None,\n    headers: dict[str, str] | None = None,\n    # Send options\n    send_bytes: bool = False,\n    audio_field: str = \"audio\",\n    format_field: str = \"format\",\n    # Response collection\n    response_timeout: float = 30.0,\n    max_messages: int = 100,\n    # Hooks\n    on_send: Callable[[Audio], str | bytes] | None = None,\n    is_complete: Callable[[list[Any]], bool] | None = None,\n    aggregate: Callable[[list[Any]], Any] | None = None,\n    # Connection\n    open_timeout: float = 10.0,\n    close_timeout: float = 5.0,\n    extra_ws_kwargs: dict[str, Any] | None = None,\n) -&gt; None:\n    if not _HAS_WEBSOCKETS:\n        msg = \"WebSocketAgent requires the 'websockets' package. Install with: pip install russo[ws]\"\n        raise ImportError(msg)\n\n    self.url = url\n    self.parser = parser\n    self.headers = headers or {}\n    self.send_bytes = send_bytes\n    self.audio_field = audio_field\n    self.format_field = format_field\n    self.response_timeout = response_timeout\n    self.max_messages = max_messages\n    self.on_send = on_send\n    self.is_complete = is_complete\n    self.aggregate = aggregate\n    self.open_timeout = open_timeout\n    self.close_timeout = close_timeout\n    self.extra_ws_kwargs = extra_ws_kwargs or {}\n</code></pre>"},{"location":"reference/adapters/#russo.adapters.WebSocketAgent--simple-json-protocol","title":"Simple JSON protocol","text":"<p>agent = WebSocketAgent(     url=\"ws://localhost:8000/ws/agent\",     parser=russo.parsers.GeminiResponseParser(), )</p>"},{"location":"reference/adapters/#russo.adapters.WebSocketAgent--raw-bytes-protocol-eg-streaming-pcm","title":"Raw bytes protocol (e.g. streaming PCM)","text":"<p>agent = WebSocketAgent(     url=\"ws://localhost:8000/ws/agent\",     send_bytes=True, )</p>"},{"location":"reference/adapters/#russo.adapters.WebSocketAgent--fully-custom-sendreceive","title":"Fully custom send/receive","text":"<p>agent = WebSocketAgent(     url=\"ws://localhost:8000/ws/agent\",     on_send=lambda audio: json.dumps({\"pcm\": base64.b64encode(audio.data).decode()}),     is_complete=lambda msgs: any('\"done\": true' in str(m) for m in msgs), )</p>"},{"location":"reference/adapters/#russo.adapters.WebSocketAgent.run","title":"run  <code>async</code>","text":"<pre><code>run(audio: Audio) -&gt; AgentResponse\n</code></pre> <p>Send audio over WebSocket and collect the response.</p> Source code in <code>src/russo/adapters/websocket.py</code> <pre><code>async def run(self, audio: Audio) -&gt; AgentResponse:\n    \"\"\"Send audio over WebSocket and collect the response.\"\"\"\n    import websockets\n\n    async with websockets.connect(\n        self.url,\n        additional_headers=self.headers or None,\n        open_timeout=self.open_timeout,\n        close_timeout=self.close_timeout,\n        **self.extra_ws_kwargs,\n    ) as ws:\n        # --- Send ---\n        message = self._prepare_message(audio)\n        if isinstance(message, bytes):\n            await ws.send(message)\n        else:\n            await ws.send(message)\n        logger.debug(\n            \"Sent %s message (%d bytes)\",\n            \"binary\" if isinstance(message, bytes) else \"text\",\n            len(message),\n        )\n\n        # --- Collect responses ---\n        messages = await self._collect_responses(ws)\n        logger.debug(\"Collected %d response messages\", len(messages))\n\n    # --- Parse ---\n    raw = self._aggregate(messages)\n\n    if self.parser:\n        return self.parser.parse(raw)\n    return self._default_parse(raw)\n</code></pre>"},{"location":"reference/adapters/#russo.adapters.callable","title":"callable","text":"<p>Callable agent adapter \u2014 wraps async functions as Agents.</p> <p>Re-exports from _helpers for organizational clarity. The actual implementation lives in russo._helpers to keep the public API flat (russo.agent decorator).</p>"},{"location":"reference/adapters/#russo.adapters.callable.agent","title":"agent","text":"<pre><code>agent(fn: Callable[[Audio], Coroutine[Any, Any, AgentResponse]]) -&gt; _CallableAgent\n</code></pre> <p>Decorator to turn an async function into an Agent.</p> Usage <p>@russo.agent async def my_agent(audio: russo.Audio) -&gt; russo.AgentResponse:     result = await call_my_api(audio.data)     return russo.AgentResponse(tool_calls=[...])</p> Source code in <code>src/russo/_helpers.py</code> <pre><code>def agent(fn: Callable[[Audio], Coroutine[Any, Any, AgentResponse]]) -&gt; _CallableAgent:\n    \"\"\"Decorator to turn an async function into an Agent.\n\n    Usage:\n        @russo.agent\n        async def my_agent(audio: russo.Audio) -&gt; russo.AgentResponse:\n            result = await call_my_api(audio.data)\n            return russo.AgentResponse(tool_calls=[...])\n    \"\"\"\n    return _CallableAgent(fn)\n</code></pre>"},{"location":"reference/adapters/#russo.adapters.gemini","title":"gemini","text":"<p>Gemini SDK agent adapters \u2014 wraps a google-genai Client as an Agent.</p> <p>Provides two adapters:</p> <ul> <li>GeminiAgent: standard <code>generate_content</code> (request/response)</li> <li>GeminiLiveAgent: Live API over WebSocket (streaming/real-time)</li> </ul> <p>Send audio directly to a Gemini model via the SDK, no HTTP endpoint needed. Requires the <code>google-genai</code> package (already a core dependency).</p>"},{"location":"reference/adapters/#russo.adapters.gemini.GeminiAgent","title":"GeminiAgent","text":"<pre><code>GeminiAgent(*, client: Any, model: str = 'gemini-2.0-flash', tools: list[Any] | None = None, system_instruction: str | None = None, config: Any | None = None)\n</code></pre> <p>Agent adapter that wraps a <code>google.genai.Client</code> object directly.</p> <p>Sends audio to Gemini via <code>client.aio.models.generate_content()</code> and auto-parses function-call responses with :class:<code>GeminiResponseParser</code>.</p> <p>Usage::</p> <pre><code>from google import genai\n\nclient = genai.Client(api_key=\"...\")\nagent = GeminiAgent(\n    client=client,\n    model=\"gemini-2.0-flash\",\n    tools=[book_flight_declaration],\n)\nresponse = await agent.run(audio)\n</code></pre> <p>For Vertex AI::</p> <pre><code>client = genai.Client(vertexai=True, project=\"my-project\", location=\"us-central1\")\nagent = GeminiAgent(client=client, model=\"gemini-2.0-flash\", tools=[...])\n</code></pre> PARAMETER DESCRIPTION <code>client</code> <p>A <code>google.genai.Client</code> instance.</p> <p> TYPE: <code>Any</code> </p> <code>model</code> <p>Model name (e.g. <code>\"gemini-2.0-flash\"</code>).</p> <p> TYPE: <code>str</code> DEFAULT: <code>'gemini-2.0-flash'</code> </p> <code>tools</code> <p>Gemini tool declarations (dicts or <code>types.Tool</code> objects).</p> <p> TYPE: <code>list[Any] | None</code> DEFAULT: <code>None</code> </p> <code>system_instruction</code> <p>Optional system instruction prepended to the request.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>config</code> <p>Full <code>GenerateContentConfig</code> override. When provided,     <code>tools</code> and <code>system_instruction</code> are ignored.</p> <p> TYPE: <code>Any | None</code> DEFAULT: <code>None</code> </p> Source code in <code>src/russo/adapters/gemini.py</code> <pre><code>def __init__(\n    self,\n    *,\n    client: Any,\n    model: str = \"gemini-2.0-flash\",\n    tools: list[Any] | None = None,\n    system_instruction: str | None = None,\n    config: Any | None = None,\n) -&gt; None:\n    \"\"\"\n    Args:\n        client: A ``google.genai.Client`` instance.\n        model: Model name (e.g. ``\"gemini-2.0-flash\"``).\n        tools: Gemini tool declarations (dicts or ``types.Tool`` objects).\n        system_instruction: Optional system instruction prepended to the request.\n        config: Full ``GenerateContentConfig`` override. When provided,\n                ``tools`` and ``system_instruction`` are ignored.\n    \"\"\"\n    self.client = client\n    self.model = model\n    self.tools = tools\n    self.system_instruction = system_instruction\n    self.config = config\n    self._parser = GeminiResponseParser()\n</code></pre>"},{"location":"reference/adapters/#russo.adapters.gemini.GeminiAgent.run","title":"run  <code>async</code>","text":"<pre><code>run(audio: Audio) -&gt; AgentResponse\n</code></pre> <p>Send audio to Gemini and parse the tool-call response.</p> Source code in <code>src/russo/adapters/gemini.py</code> <pre><code>async def run(self, audio: Audio) -&gt; AgentResponse:\n    \"\"\"Send audio to Gemini and parse the tool-call response.\"\"\"\n    from google.genai import types\n\n    data, mime_type = _prepare_audio(audio)\n    contents = [types.Part.from_bytes(data=data, mime_type=mime_type)]\n\n    config = self._build_config(types)\n    logger.debug(\n        \"Sending %d bytes of %s audio to %s\", len(data), mime_type, self.model\n    )\n\n    response = await self.client.aio.models.generate_content(\n        model=self.model,\n        contents=contents,\n        config=config,\n    )\n\n    return self._parser.parse(response)\n</code></pre>"},{"location":"reference/adapters/#russo.adapters.gemini.GeminiLiveAgent","title":"GeminiLiveAgent","text":"<pre><code>GeminiLiveAgent(*, client: Any | None = None, session: Any | None = None, model: str = 'gemini-2.0-flash-live-preview-04-09', tools: list[Any] | None = None, system_instruction: str | None = None, config: Any | None = None, response_timeout: float = 30.0)\n</code></pre> <p>Agent adapter for Gemini's Live API (streaming/real-time).</p> <p>Connects via <code>client.aio.live.connect()</code>, sends audio as a turn-based content message, and collects function-call responses.</p> <p>Accepts either:</p> <ul> <li>A <code>google.genai.Client</code> (opens a new session per <code>run()</code>)</li> <li>A pre-existing Live session (reuses it)</li> </ul> <p>Usage with client::</p> <pre><code>from google import genai\n\nclient = genai.Client(vertexai=True, project=\"my-project\", location=\"us-central1\")\nagent = GeminiLiveAgent(\n    client=client,\n    model=\"gemini-2.0-flash-live-preview-04-09\",\n    tools=[book_flight_declaration],\n)\nresponse = await agent.run(audio)\n</code></pre> <p>Usage with pre-existing session::</p> <pre><code>config = types.LiveConnectConfig(tools=[...], response_modalities=[\"TEXT\"])\nasync with client.aio.live.connect(model=\"...\", config=config) as session:\n    agent = GeminiLiveAgent(session=session)\n    response = await agent.run(audio)\n</code></pre> Note <p>Model names differ by backend:</p> <ul> <li>Vertex AI: <code>gemini-2.0-flash-live-preview-04-09</code></li> <li>Google AI: <code>gemini-live-2.5-flash-preview</code></li> </ul> PARAMETER DESCRIPTION <code>client</code> <p>A <code>google.genai.Client</code> instance. Creates a new session per <code>run()</code>.</p> <p> TYPE: <code>Any | None</code> DEFAULT: <code>None</code> </p> <code>session</code> <p>A pre-existing Live session (from <code>client.aio.live.connect()</code>). When provided, <code>tools</code>/<code>system_instruction</code>/<code>config</code> are ignored (the session was already configured at connect time).</p> <p> TYPE: <code>Any | None</code> DEFAULT: <code>None</code> </p> <code>model</code> <p>Live model name.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'gemini-2.0-flash-live-preview-04-09'</code> </p> <code>tools</code> <p>Gemini tool declarations.</p> <p> TYPE: <code>list[Any] | None</code> DEFAULT: <code>None</code> </p> <code>system_instruction</code> <p>System instruction for the session.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>config</code> <p>Full <code>LiveConnectConfig</code> override.  When provided, <code>tools</code>, <code>system_instruction</code>, and <code>response_modalities</code> are ignored.</p> <p> TYPE: <code>Any | None</code> DEFAULT: <code>None</code> </p> <code>response_timeout</code> <p>Max seconds to wait for a complete response turn.</p> <p> TYPE: <code>float</code> DEFAULT: <code>30.0</code> </p> Source code in <code>src/russo/adapters/gemini.py</code> <pre><code>def __init__(\n    self,\n    *,\n    client: Any | None = None,\n    session: Any | None = None,\n    model: str = \"gemini-2.0-flash-live-preview-04-09\",\n    tools: list[Any] | None = None,\n    system_instruction: str | None = None,\n    config: Any | None = None,\n    response_timeout: float = 30.0,\n) -&gt; None:\n    \"\"\"\n    Args:\n        client: A ``google.genai.Client`` instance. Creates a new session per ``run()``.\n        session: A pre-existing Live session (from ``client.aio.live.connect()``).\n            When provided, ``tools``/``system_instruction``/``config`` are ignored\n            (the session was already configured at connect time).\n        model: Live model name.\n        tools: Gemini tool declarations.\n        system_instruction: System instruction for the session.\n        config: Full ``LiveConnectConfig`` override.  When provided,\n            ``tools``, ``system_instruction``, and ``response_modalities`` are ignored.\n        response_timeout: Max seconds to wait for a complete response turn.\n    \"\"\"\n    if client is None and session is None:\n        msg = \"Provide either 'client' (genai.Client) or 'session' (live session)\"\n        raise ValueError(msg)\n    self.client = client\n    self.session = session\n    self.model = model\n    self.tools = tools\n    self.system_instruction = system_instruction\n    self.config = config\n    self.response_timeout = response_timeout\n</code></pre>"},{"location":"reference/adapters/#russo.adapters.gemini.GeminiLiveAgent.run","title":"run  <code>async</code>","text":"<pre><code>run(audio: Audio) -&gt; AgentResponse\n</code></pre> <p>Send audio to a Live session and collect function calls.</p> Source code in <code>src/russo/adapters/gemini.py</code> <pre><code>async def run(self, audio: Audio) -&gt; AgentResponse:\n    \"\"\"Send audio to a Live session and collect function calls.\"\"\"\n    if self.session is not None:\n        return await self._run_on(self.session, audio)\n\n    from google.genai import types\n\n    assert self.client is not None  # guaranteed by __init__\n    config = self._build_config(types)\n    async with self.client.aio.live.connect(\n        model=self.model, config=config\n    ) as session:\n        return await self._run_on(session, audio)\n</code></pre>"},{"location":"reference/adapters/#russo.adapters.http","title":"http","text":"<p>HTTP agent adapter \u2014 sends audio to an API endpoint.</p>"},{"location":"reference/adapters/#russo.adapters.http.HttpAgent","title":"HttpAgent","text":"<pre><code>HttpAgent(*, url: str, parser: ResponseParser | None = None, method: str = 'POST', headers: dict[str, str] | None = None, audio_field: str = 'audio', format_field: str = 'format', timeout: float = 60.0)\n</code></pre> <p>Agent adapter that sends audio to an HTTP endpoint.</p> <p>Sends audio as base64-encoded JSON and parses the response using an optional ResponseParser.</p> Usage <p>agent = HttpAgent(     url=\"http://localhost:8000/voice-agent\",     parser=russo.parsers.GeminiResponseParser(), ) response = await agent.run(audio)</p> Source code in <code>src/russo/adapters/http.py</code> <pre><code>def __init__(\n    self,\n    *,\n    url: str,\n    parser: ResponseParser | None = None,\n    method: str = \"POST\",\n    headers: dict[str, str] | None = None,\n    audio_field: str = \"audio\",\n    format_field: str = \"format\",\n    timeout: float = 60.0,\n) -&gt; None:\n    self.url = url\n    self.parser = parser\n    self.method = method\n    self.headers = headers or {}\n    self.audio_field = audio_field\n    self.format_field = format_field\n    self.timeout = timeout\n</code></pre>"},{"location":"reference/adapters/#russo.adapters.http.HttpAgent.run","title":"run  <code>async</code>","text":"<pre><code>run(audio: Audio) -&gt; AgentResponse\n</code></pre> <p>Send audio to the HTTP endpoint and parse the response.</p> Source code in <code>src/russo/adapters/http.py</code> <pre><code>async def run(self, audio: Audio) -&gt; AgentResponse:\n    \"\"\"Send audio to the HTTP endpoint and parse the response.\"\"\"\n    payload = {\n        self.audio_field: base64.b64encode(audio.data).decode(\"ascii\"),\n        self.format_field: audio.format,\n    }\n\n    raw_response = await self._send(payload)\n\n    if self.parser:\n        return self.parser.parse(raw_response)\n\n    return self._default_parse(raw_response)\n</code></pre>"},{"location":"reference/adapters/#russo.adapters.openai","title":"openai","text":"<p>OpenAI SDK agent adapters \u2014 wraps OpenAI clients as Agents.</p> <p>Provides two adapters:</p> <ul> <li>OpenAIAgent: standard Chat Completions with audio input   (<code>gpt-4o-audio-preview</code> and similar models)</li> <li>OpenAIRealtimeAgent: Realtime API over WebSocket   (<code>gpt-4o-realtime-preview</code>)</li> </ul> <p>Requires the <code>openai</code> package: <code>pip install russo[openai]</code></p>"},{"location":"reference/adapters/#russo.adapters.openai.OpenAIAgent","title":"OpenAIAgent","text":"<pre><code>OpenAIAgent(*, client: Any, model: str = 'gpt-4o-audio-preview', tools: list[Any] | None = None, system_prompt: str | None = None, extra_create_kwargs: dict[str, Any] | None = None)\n</code></pre> <p>Agent adapter that wraps an <code>AsyncOpenAI</code> client for Chat Completions.</p> <p>Sends audio via the Chat Completions API and auto-parses tool-call responses with :class:<code>OpenAIResponseParser</code>.</p> <p>Usage::</p> <pre><code>from openai import AsyncOpenAI\n\nclient = AsyncOpenAI()\nagent = OpenAIAgent(\n    client=client,\n    model=\"gpt-4o-audio-preview\",\n    tools=[{\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"book_flight\",\n            \"parameters\": {\"type\": \"object\", \"properties\": {...}},\n        },\n    }],\n)\nresponse = await agent.run(audio)\n</code></pre> PARAMETER DESCRIPTION <code>client</code> <p>An <code>openai.AsyncOpenAI</code> instance.</p> <p> TYPE: <code>Any</code> </p> <code>model</code> <p>Model name supporting audio input.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'gpt-4o-audio-preview'</code> </p> <code>tools</code> <p>OpenAI tool definitions (function-calling format).</p> <p> TYPE: <code>list[Any] | None</code> DEFAULT: <code>None</code> </p> <code>system_prompt</code> <p>Optional system message prepended to the conversation.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>extra_create_kwargs</code> <p>Additional kwargs forwarded to <code>client.chat.completions.create()</code>.</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> Source code in <code>src/russo/adapters/openai.py</code> <pre><code>def __init__(\n    self,\n    *,\n    client: Any,\n    model: str = \"gpt-4o-audio-preview\",\n    tools: list[Any] | None = None,\n    system_prompt: str | None = None,\n    extra_create_kwargs: dict[str, Any] | None = None,\n) -&gt; None:\n    \"\"\"\n    Args:\n        client: An ``openai.AsyncOpenAI`` instance.\n        model: Model name supporting audio input.\n        tools: OpenAI tool definitions (function-calling format).\n        system_prompt: Optional system message prepended to the conversation.\n        extra_create_kwargs: Additional kwargs forwarded to\n            ``client.chat.completions.create()``.\n    \"\"\"\n    self.client = client\n    self.model = model\n    self.tools = tools\n    self.system_prompt = system_prompt\n    self.extra_create_kwargs = extra_create_kwargs or {}\n    self._parser = OpenAIResponseParser()\n</code></pre>"},{"location":"reference/adapters/#russo.adapters.openai.OpenAIAgent.run","title":"run  <code>async</code>","text":"<pre><code>run(audio: Audio) -&gt; AgentResponse\n</code></pre> <p>Send audio via Chat Completions and parse the tool-call response.</p> Source code in <code>src/russo/adapters/openai.py</code> <pre><code>async def run(self, audio: Audio) -&gt; AgentResponse:\n    \"\"\"Send audio via Chat Completions and parse the tool-call response.\"\"\"\n    audio_b64 = base64.b64encode(audio.data).decode(\"ascii\")\n\n    messages: list[dict[str, Any]] = []\n    if self.system_prompt:\n        messages.append({\"role\": \"system\", \"content\": self.system_prompt})\n\n    messages.append(\n        {\n            \"role\": \"user\",\n            \"content\": [\n                {\n                    \"type\": \"input_audio\",\n                    \"input_audio\": {\"data\": audio_b64, \"format\": audio.format},\n                }\n            ],\n        }\n    )\n\n    kwargs: dict[str, Any] = {\n        \"model\": self.model,\n        \"messages\": messages,\n        **self.extra_create_kwargs,\n    }\n    if self.tools:\n        kwargs[\"tools\"] = self.tools\n\n    logger.debug(\"Sending %d bytes of %s audio to %s\", len(audio.data), audio.format, self.model)\n\n    response = await self.client.chat.completions.create(**kwargs)\n    return self._parser.parse(response)\n</code></pre>"},{"location":"reference/adapters/#russo.adapters.openai.OpenAIRealtimeAgent","title":"OpenAIRealtimeAgent","text":"<pre><code>OpenAIRealtimeAgent(*, client: Any | None = None, connection: Any | None = None, model: str = 'gpt-4o-realtime-preview', tools: list[Any] | None = None, response_timeout: float = 30.0)\n</code></pre> <p>Agent adapter for OpenAI's Realtime API.</p> <p>Connects via the SDK's <code>client.beta.realtime.connect()</code> interface, sends audio, and collects <code>response.function_call_arguments.done</code> events.</p> <p>Accepts either:</p> <ul> <li>An <code>AsyncOpenAI</code> client (creates a new connection per <code>run()</code>)</li> <li>A pre-existing realtime connection (reuses it, no session config sent)</li> </ul> <p>Usage with client::</p> <pre><code>from openai import AsyncOpenAI\n\nclient = AsyncOpenAI()\nagent = OpenAIRealtimeAgent(\n    client=client,\n    model=\"gpt-4o-realtime-preview\",\n    tools=[{\n        \"type\": \"function\",\n        \"name\": \"book_flight\",\n        \"description\": \"Book a flight\",\n        \"parameters\": {\"type\": \"object\", \"properties\": {...}},\n    }],\n)\nresponse = await agent.run(audio)\n</code></pre> <p>Usage with pre-existing connection::</p> <pre><code>async with client.beta.realtime.connect(model=\"gpt-4o-realtime-preview\") as conn:\n    agent = OpenAIRealtimeAgent(connection=conn)\n    response = await agent.run(audio)\n</code></pre> Note <p>The Realtime API expects pcm16 audio at 24 kHz mono by default. If you pass WAV audio, the adapter automatically strips the WAV header to extract raw PCM frames.</p> PARAMETER DESCRIPTION <code>client</code> <p>An <code>openai.AsyncOpenAI</code> instance. Mutually preferred with connection.</p> <p> TYPE: <code>Any | None</code> DEFAULT: <code>None</code> </p> <code>connection</code> <p>A pre-existing realtime connection (from <code>client.beta.realtime.connect()</code>).</p> <p> TYPE: <code>Any | None</code> DEFAULT: <code>None</code> </p> <code>model</code> <p>Realtime model name.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'gpt-4o-realtime-preview'</code> </p> <code>tools</code> <p>Tool definitions sent during session configuration.</p> <p> TYPE: <code>list[Any] | None</code> DEFAULT: <code>None</code> </p> <code>response_timeout</code> <p>Max seconds to wait for a complete response.</p> <p> TYPE: <code>float</code> DEFAULT: <code>30.0</code> </p> Source code in <code>src/russo/adapters/openai.py</code> <pre><code>def __init__(\n    self,\n    *,\n    client: Any | None = None,\n    connection: Any | None = None,\n    model: str = \"gpt-4o-realtime-preview\",\n    tools: list[Any] | None = None,\n    response_timeout: float = 30.0,\n) -&gt; None:\n    \"\"\"\n    Args:\n        client: An ``openai.AsyncOpenAI`` instance. Mutually preferred with *connection*.\n        connection: A pre-existing realtime connection (from ``client.beta.realtime.connect()``).\n        model: Realtime model name.\n        tools: Tool definitions sent during session configuration.\n        response_timeout: Max seconds to wait for a complete response.\n    \"\"\"\n    if client is None and connection is None:\n        msg = \"Provide either 'client' (AsyncOpenAI) or 'connection' (realtime connection)\"\n        raise ValueError(msg)\n    self.client = client\n    self.connection = connection\n    self.model = model\n    self.tools = tools\n    self.response_timeout = response_timeout\n</code></pre>"},{"location":"reference/adapters/#russo.adapters.openai.OpenAIRealtimeAgent.run","title":"run  <code>async</code>","text":"<pre><code>run(audio: Audio) -&gt; AgentResponse\n</code></pre> <p>Send audio via the Realtime API and collect function calls.</p> Source code in <code>src/russo/adapters/openai.py</code> <pre><code>async def run(self, audio: Audio) -&gt; AgentResponse:\n    \"\"\"Send audio via the Realtime API and collect function calls.\"\"\"\n    if self.connection is not None:\n        return await self._run_on(self.connection, audio, configure=False)\n\n    async with self.client.beta.realtime.connect(model=self.model) as conn:\n        return await self._run_on(conn, audio, configure=True)\n</code></pre>"},{"location":"reference/adapters/#russo.adapters.websocket","title":"websocket","text":"<p>WebSocket agent adapter \u2014 sends audio to a WebSocket endpoint.</p> <p>Requires the <code>websockets</code> package: pip install russo[ws]</p>"},{"location":"reference/adapters/#russo.adapters.websocket.WebSocketAgent","title":"WebSocketAgent","text":"<pre><code>WebSocketAgent(*, url: str, parser: ResponseParser | None = None, headers: dict[str, str] | None = None, send_bytes: bool = False, audio_field: str = 'audio', format_field: str = 'format', response_timeout: float = 30.0, max_messages: int = 100, on_send: Callable[[Audio], str | bytes] | None = None, is_complete: Callable[[list[Any]], bool] | None = None, aggregate: Callable[[list[Any]], Any] | None = None, open_timeout: float = 10.0, close_timeout: float = 5.0, extra_ws_kwargs: dict[str, Any] | None = None)\n</code></pre> <p>Agent adapter that communicates over WebSocket.</p> <p>Connects to the endpoint, sends audio, collects response messages until a completion condition is met, then parses tool calls.</p> <p>Supports two send modes: - json (default): sends <code>{\"audio\": \"&lt;base64&gt;\", \"format\": \"wav\"}</code> - bytes: sends raw audio bytes directly on the wire</p> <p>And two ways to customize the protocol: - on_send: transform the Audio into whatever your server expects - is_complete: decide when to stop collecting response messages</p> Usage Source code in <code>src/russo/adapters/websocket.py</code> <pre><code>def __init__(\n    self,\n    *,\n    url: str,\n    parser: ResponseParser | None = None,\n    headers: dict[str, str] | None = None,\n    # Send options\n    send_bytes: bool = False,\n    audio_field: str = \"audio\",\n    format_field: str = \"format\",\n    # Response collection\n    response_timeout: float = 30.0,\n    max_messages: int = 100,\n    # Hooks\n    on_send: Callable[[Audio], str | bytes] | None = None,\n    is_complete: Callable[[list[Any]], bool] | None = None,\n    aggregate: Callable[[list[Any]], Any] | None = None,\n    # Connection\n    open_timeout: float = 10.0,\n    close_timeout: float = 5.0,\n    extra_ws_kwargs: dict[str, Any] | None = None,\n) -&gt; None:\n    if not _HAS_WEBSOCKETS:\n        msg = \"WebSocketAgent requires the 'websockets' package. Install with: pip install russo[ws]\"\n        raise ImportError(msg)\n\n    self.url = url\n    self.parser = parser\n    self.headers = headers or {}\n    self.send_bytes = send_bytes\n    self.audio_field = audio_field\n    self.format_field = format_field\n    self.response_timeout = response_timeout\n    self.max_messages = max_messages\n    self.on_send = on_send\n    self.is_complete = is_complete\n    self.aggregate = aggregate\n    self.open_timeout = open_timeout\n    self.close_timeout = close_timeout\n    self.extra_ws_kwargs = extra_ws_kwargs or {}\n</code></pre>"},{"location":"reference/adapters/#russo.adapters.websocket.WebSocketAgent--simple-json-protocol","title":"Simple JSON protocol","text":"<p>agent = WebSocketAgent(     url=\"ws://localhost:8000/ws/agent\",     parser=russo.parsers.GeminiResponseParser(), )</p>"},{"location":"reference/adapters/#russo.adapters.websocket.WebSocketAgent--raw-bytes-protocol-eg-streaming-pcm","title":"Raw bytes protocol (e.g. streaming PCM)","text":"<p>agent = WebSocketAgent(     url=\"ws://localhost:8000/ws/agent\",     send_bytes=True, )</p>"},{"location":"reference/adapters/#russo.adapters.websocket.WebSocketAgent--fully-custom-sendreceive","title":"Fully custom send/receive","text":"<p>agent = WebSocketAgent(     url=\"ws://localhost:8000/ws/agent\",     on_send=lambda audio: json.dumps({\"pcm\": base64.b64encode(audio.data).decode()}),     is_complete=lambda msgs: any('\"done\": true' in str(m) for m in msgs), )</p>"},{"location":"reference/adapters/#russo.adapters.websocket.WebSocketAgent.run","title":"run  <code>async</code>","text":"<pre><code>run(audio: Audio) -&gt; AgentResponse\n</code></pre> <p>Send audio over WebSocket and collect the response.</p> Source code in <code>src/russo/adapters/websocket.py</code> <pre><code>async def run(self, audio: Audio) -&gt; AgentResponse:\n    \"\"\"Send audio over WebSocket and collect the response.\"\"\"\n    import websockets\n\n    async with websockets.connect(\n        self.url,\n        additional_headers=self.headers or None,\n        open_timeout=self.open_timeout,\n        close_timeout=self.close_timeout,\n        **self.extra_ws_kwargs,\n    ) as ws:\n        # --- Send ---\n        message = self._prepare_message(audio)\n        if isinstance(message, bytes):\n            await ws.send(message)\n        else:\n            await ws.send(message)\n        logger.debug(\n            \"Sent %s message (%d bytes)\",\n            \"binary\" if isinstance(message, bytes) else \"text\",\n            len(message),\n        )\n\n        # --- Collect responses ---\n        messages = await self._collect_responses(ws)\n        logger.debug(\"Collected %d response messages\", len(messages))\n\n    # --- Parse ---\n    raw = self._aggregate(messages)\n\n    if self.parser:\n        return self.parser.parse(raw)\n    return self._default_parse(raw)\n</code></pre>"},{"location":"reference/adapters/callable/","title":"Callable Adapter","text":"<p>Callable agent adapter \u2014 wraps async functions as Agents.</p>"},{"location":"reference/adapters/callable/#russo.adapters.callable","title":"callable","text":"<p>Callable agent adapter \u2014 wraps async functions as Agents.</p> <p>Re-exports from _helpers for organizational clarity. The actual implementation lives in russo._helpers to keep the public API flat (russo.agent decorator).</p>"},{"location":"reference/adapters/callable/#russo.adapters.callable.agent","title":"agent","text":"<pre><code>agent(fn: Callable[[Audio], Coroutine[Any, Any, AgentResponse]]) -&gt; _CallableAgent\n</code></pre> <p>Decorator to turn an async function into an Agent.</p> Usage <p>@russo.agent async def my_agent(audio: russo.Audio) -&gt; russo.AgentResponse:     result = await call_my_api(audio.data)     return russo.AgentResponse(tool_calls=[...])</p> Source code in <code>src/russo/_helpers.py</code> <pre><code>def agent(fn: Callable[[Audio], Coroutine[Any, Any, AgentResponse]]) -&gt; _CallableAgent:\n    \"\"\"Decorator to turn an async function into an Agent.\n\n    Usage:\n        @russo.agent\n        async def my_agent(audio: russo.Audio) -&gt; russo.AgentResponse:\n            result = await call_my_api(audio.data)\n            return russo.AgentResponse(tool_calls=[...])\n    \"\"\"\n    return _CallableAgent(fn)\n</code></pre>"},{"location":"reference/adapters/gemini/","title":"Gemini Adapters","text":"<p>Gemini SDK agent adapters \u2014 wraps a <code>google-genai</code> Client as an Agent.</p>"},{"location":"reference/adapters/gemini/#russo.adapters.gemini","title":"gemini","text":"<p>Gemini SDK agent adapters \u2014 wraps a google-genai Client as an Agent.</p> <p>Provides two adapters:</p> <ul> <li>GeminiAgent: standard <code>generate_content</code> (request/response)</li> <li>GeminiLiveAgent: Live API over WebSocket (streaming/real-time)</li> </ul> <p>Send audio directly to a Gemini model via the SDK, no HTTP endpoint needed. Requires the <code>google-genai</code> package (already a core dependency).</p>"},{"location":"reference/adapters/gemini/#russo.adapters.gemini.GeminiAgent","title":"GeminiAgent","text":"<pre><code>GeminiAgent(*, client: Any, model: str = 'gemini-2.0-flash', tools: list[Any] | None = None, system_instruction: str | None = None, config: Any | None = None)\n</code></pre> <p>Agent adapter that wraps a <code>google.genai.Client</code> object directly.</p> <p>Sends audio to Gemini via <code>client.aio.models.generate_content()</code> and auto-parses function-call responses with :class:<code>GeminiResponseParser</code>.</p> <p>Usage::</p> <pre><code>from google import genai\n\nclient = genai.Client(api_key=\"...\")\nagent = GeminiAgent(\n    client=client,\n    model=\"gemini-2.0-flash\",\n    tools=[book_flight_declaration],\n)\nresponse = await agent.run(audio)\n</code></pre> <p>For Vertex AI::</p> <pre><code>client = genai.Client(vertexai=True, project=\"my-project\", location=\"us-central1\")\nagent = GeminiAgent(client=client, model=\"gemini-2.0-flash\", tools=[...])\n</code></pre> PARAMETER DESCRIPTION <code>client</code> <p>A <code>google.genai.Client</code> instance.</p> <p> TYPE: <code>Any</code> </p> <code>model</code> <p>Model name (e.g. <code>\"gemini-2.0-flash\"</code>).</p> <p> TYPE: <code>str</code> DEFAULT: <code>'gemini-2.0-flash'</code> </p> <code>tools</code> <p>Gemini tool declarations (dicts or <code>types.Tool</code> objects).</p> <p> TYPE: <code>list[Any] | None</code> DEFAULT: <code>None</code> </p> <code>system_instruction</code> <p>Optional system instruction prepended to the request.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>config</code> <p>Full <code>GenerateContentConfig</code> override. When provided,     <code>tools</code> and <code>system_instruction</code> are ignored.</p> <p> TYPE: <code>Any | None</code> DEFAULT: <code>None</code> </p> Source code in <code>src/russo/adapters/gemini.py</code> <pre><code>def __init__(\n    self,\n    *,\n    client: Any,\n    model: str = \"gemini-2.0-flash\",\n    tools: list[Any] | None = None,\n    system_instruction: str | None = None,\n    config: Any | None = None,\n) -&gt; None:\n    \"\"\"\n    Args:\n        client: A ``google.genai.Client`` instance.\n        model: Model name (e.g. ``\"gemini-2.0-flash\"``).\n        tools: Gemini tool declarations (dicts or ``types.Tool`` objects).\n        system_instruction: Optional system instruction prepended to the request.\n        config: Full ``GenerateContentConfig`` override. When provided,\n                ``tools`` and ``system_instruction`` are ignored.\n    \"\"\"\n    self.client = client\n    self.model = model\n    self.tools = tools\n    self.system_instruction = system_instruction\n    self.config = config\n    self._parser = GeminiResponseParser()\n</code></pre>"},{"location":"reference/adapters/gemini/#russo.adapters.gemini.GeminiAgent.run","title":"run  <code>async</code>","text":"<pre><code>run(audio: Audio) -&gt; AgentResponse\n</code></pre> <p>Send audio to Gemini and parse the tool-call response.</p> Source code in <code>src/russo/adapters/gemini.py</code> <pre><code>async def run(self, audio: Audio) -&gt; AgentResponse:\n    \"\"\"Send audio to Gemini and parse the tool-call response.\"\"\"\n    from google.genai import types\n\n    data, mime_type = _prepare_audio(audio)\n    contents = [types.Part.from_bytes(data=data, mime_type=mime_type)]\n\n    config = self._build_config(types)\n    logger.debug(\n        \"Sending %d bytes of %s audio to %s\", len(data), mime_type, self.model\n    )\n\n    response = await self.client.aio.models.generate_content(\n        model=self.model,\n        contents=contents,\n        config=config,\n    )\n\n    return self._parser.parse(response)\n</code></pre>"},{"location":"reference/adapters/gemini/#russo.adapters.gemini.GeminiLiveAgent","title":"GeminiLiveAgent","text":"<pre><code>GeminiLiveAgent(*, client: Any | None = None, session: Any | None = None, model: str = 'gemini-2.0-flash-live-preview-04-09', tools: list[Any] | None = None, system_instruction: str | None = None, config: Any | None = None, response_timeout: float = 30.0)\n</code></pre> <p>Agent adapter for Gemini's Live API (streaming/real-time).</p> <p>Connects via <code>client.aio.live.connect()</code>, sends audio as a turn-based content message, and collects function-call responses.</p> <p>Accepts either:</p> <ul> <li>A <code>google.genai.Client</code> (opens a new session per <code>run()</code>)</li> <li>A pre-existing Live session (reuses it)</li> </ul> <p>Usage with client::</p> <pre><code>from google import genai\n\nclient = genai.Client(vertexai=True, project=\"my-project\", location=\"us-central1\")\nagent = GeminiLiveAgent(\n    client=client,\n    model=\"gemini-2.0-flash-live-preview-04-09\",\n    tools=[book_flight_declaration],\n)\nresponse = await agent.run(audio)\n</code></pre> <p>Usage with pre-existing session::</p> <pre><code>config = types.LiveConnectConfig(tools=[...], response_modalities=[\"TEXT\"])\nasync with client.aio.live.connect(model=\"...\", config=config) as session:\n    agent = GeminiLiveAgent(session=session)\n    response = await agent.run(audio)\n</code></pre> Note <p>Model names differ by backend:</p> <ul> <li>Vertex AI: <code>gemini-2.0-flash-live-preview-04-09</code></li> <li>Google AI: <code>gemini-live-2.5-flash-preview</code></li> </ul> PARAMETER DESCRIPTION <code>client</code> <p>A <code>google.genai.Client</code> instance. Creates a new session per <code>run()</code>.</p> <p> TYPE: <code>Any | None</code> DEFAULT: <code>None</code> </p> <code>session</code> <p>A pre-existing Live session (from <code>client.aio.live.connect()</code>). When provided, <code>tools</code>/<code>system_instruction</code>/<code>config</code> are ignored (the session was already configured at connect time).</p> <p> TYPE: <code>Any | None</code> DEFAULT: <code>None</code> </p> <code>model</code> <p>Live model name.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'gemini-2.0-flash-live-preview-04-09'</code> </p> <code>tools</code> <p>Gemini tool declarations.</p> <p> TYPE: <code>list[Any] | None</code> DEFAULT: <code>None</code> </p> <code>system_instruction</code> <p>System instruction for the session.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>config</code> <p>Full <code>LiveConnectConfig</code> override.  When provided, <code>tools</code>, <code>system_instruction</code>, and <code>response_modalities</code> are ignored.</p> <p> TYPE: <code>Any | None</code> DEFAULT: <code>None</code> </p> <code>response_timeout</code> <p>Max seconds to wait for a complete response turn.</p> <p> TYPE: <code>float</code> DEFAULT: <code>30.0</code> </p> Source code in <code>src/russo/adapters/gemini.py</code> <pre><code>def __init__(\n    self,\n    *,\n    client: Any | None = None,\n    session: Any | None = None,\n    model: str = \"gemini-2.0-flash-live-preview-04-09\",\n    tools: list[Any] | None = None,\n    system_instruction: str | None = None,\n    config: Any | None = None,\n    response_timeout: float = 30.0,\n) -&gt; None:\n    \"\"\"\n    Args:\n        client: A ``google.genai.Client`` instance. Creates a new session per ``run()``.\n        session: A pre-existing Live session (from ``client.aio.live.connect()``).\n            When provided, ``tools``/``system_instruction``/``config`` are ignored\n            (the session was already configured at connect time).\n        model: Live model name.\n        tools: Gemini tool declarations.\n        system_instruction: System instruction for the session.\n        config: Full ``LiveConnectConfig`` override.  When provided,\n            ``tools``, ``system_instruction``, and ``response_modalities`` are ignored.\n        response_timeout: Max seconds to wait for a complete response turn.\n    \"\"\"\n    if client is None and session is None:\n        msg = \"Provide either 'client' (genai.Client) or 'session' (live session)\"\n        raise ValueError(msg)\n    self.client = client\n    self.session = session\n    self.model = model\n    self.tools = tools\n    self.system_instruction = system_instruction\n    self.config = config\n    self.response_timeout = response_timeout\n</code></pre>"},{"location":"reference/adapters/gemini/#russo.adapters.gemini.GeminiLiveAgent.run","title":"run  <code>async</code>","text":"<pre><code>run(audio: Audio) -&gt; AgentResponse\n</code></pre> <p>Send audio to a Live session and collect function calls.</p> Source code in <code>src/russo/adapters/gemini.py</code> <pre><code>async def run(self, audio: Audio) -&gt; AgentResponse:\n    \"\"\"Send audio to a Live session and collect function calls.\"\"\"\n    if self.session is not None:\n        return await self._run_on(self.session, audio)\n\n    from google.genai import types\n\n    assert self.client is not None  # guaranteed by __init__\n    config = self._build_config(types)\n    async with self.client.aio.live.connect(\n        model=self.model, config=config\n    ) as session:\n        return await self._run_on(session, audio)\n</code></pre>"},{"location":"reference/adapters/http/","title":"HTTP Adapter","text":"<p>HTTP agent adapter \u2014 sends audio to an API endpoint.</p>"},{"location":"reference/adapters/http/#russo.adapters.http","title":"http","text":"<p>HTTP agent adapter \u2014 sends audio to an API endpoint.</p>"},{"location":"reference/adapters/http/#russo.adapters.http.HttpAgent","title":"HttpAgent","text":"<pre><code>HttpAgent(*, url: str, parser: ResponseParser | None = None, method: str = 'POST', headers: dict[str, str] | None = None, audio_field: str = 'audio', format_field: str = 'format', timeout: float = 60.0)\n</code></pre> <p>Agent adapter that sends audio to an HTTP endpoint.</p> <p>Sends audio as base64-encoded JSON and parses the response using an optional ResponseParser.</p> Usage <p>agent = HttpAgent(     url=\"http://localhost:8000/voice-agent\",     parser=russo.parsers.GeminiResponseParser(), ) response = await agent.run(audio)</p> Source code in <code>src/russo/adapters/http.py</code> <pre><code>def __init__(\n    self,\n    *,\n    url: str,\n    parser: ResponseParser | None = None,\n    method: str = \"POST\",\n    headers: dict[str, str] | None = None,\n    audio_field: str = \"audio\",\n    format_field: str = \"format\",\n    timeout: float = 60.0,\n) -&gt; None:\n    self.url = url\n    self.parser = parser\n    self.method = method\n    self.headers = headers or {}\n    self.audio_field = audio_field\n    self.format_field = format_field\n    self.timeout = timeout\n</code></pre>"},{"location":"reference/adapters/http/#russo.adapters.http.HttpAgent.run","title":"run  <code>async</code>","text":"<pre><code>run(audio: Audio) -&gt; AgentResponse\n</code></pre> <p>Send audio to the HTTP endpoint and parse the response.</p> Source code in <code>src/russo/adapters/http.py</code> <pre><code>async def run(self, audio: Audio) -&gt; AgentResponse:\n    \"\"\"Send audio to the HTTP endpoint and parse the response.\"\"\"\n    payload = {\n        self.audio_field: base64.b64encode(audio.data).decode(\"ascii\"),\n        self.format_field: audio.format,\n    }\n\n    raw_response = await self._send(payload)\n\n    if self.parser:\n        return self.parser.parse(raw_response)\n\n    return self._default_parse(raw_response)\n</code></pre>"},{"location":"reference/adapters/openai/","title":"OpenAI Adapters","text":"<p>OpenAI SDK agent adapters \u2014 wraps OpenAI clients as Agents.</p> <p>Note</p> <p>Requires the <code>openai</code> extra: <code>pip install \"russo[openai]\"</code></p>"},{"location":"reference/adapters/openai/#russo.adapters.openai","title":"openai","text":"<p>OpenAI SDK agent adapters \u2014 wraps OpenAI clients as Agents.</p> <p>Provides two adapters:</p> <ul> <li>OpenAIAgent: standard Chat Completions with audio input   (<code>gpt-4o-audio-preview</code> and similar models)</li> <li>OpenAIRealtimeAgent: Realtime API over WebSocket   (<code>gpt-4o-realtime-preview</code>)</li> </ul> <p>Requires the <code>openai</code> package: <code>pip install russo[openai]</code></p>"},{"location":"reference/adapters/openai/#russo.adapters.openai.OpenAIAgent","title":"OpenAIAgent","text":"<pre><code>OpenAIAgent(*, client: Any, model: str = 'gpt-4o-audio-preview', tools: list[Any] | None = None, system_prompt: str | None = None, extra_create_kwargs: dict[str, Any] | None = None)\n</code></pre> <p>Agent adapter that wraps an <code>AsyncOpenAI</code> client for Chat Completions.</p> <p>Sends audio via the Chat Completions API and auto-parses tool-call responses with :class:<code>OpenAIResponseParser</code>.</p> <p>Usage::</p> <pre><code>from openai import AsyncOpenAI\n\nclient = AsyncOpenAI()\nagent = OpenAIAgent(\n    client=client,\n    model=\"gpt-4o-audio-preview\",\n    tools=[{\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"book_flight\",\n            \"parameters\": {\"type\": \"object\", \"properties\": {...}},\n        },\n    }],\n)\nresponse = await agent.run(audio)\n</code></pre> PARAMETER DESCRIPTION <code>client</code> <p>An <code>openai.AsyncOpenAI</code> instance.</p> <p> TYPE: <code>Any</code> </p> <code>model</code> <p>Model name supporting audio input.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'gpt-4o-audio-preview'</code> </p> <code>tools</code> <p>OpenAI tool definitions (function-calling format).</p> <p> TYPE: <code>list[Any] | None</code> DEFAULT: <code>None</code> </p> <code>system_prompt</code> <p>Optional system message prepended to the conversation.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>extra_create_kwargs</code> <p>Additional kwargs forwarded to <code>client.chat.completions.create()</code>.</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> Source code in <code>src/russo/adapters/openai.py</code> <pre><code>def __init__(\n    self,\n    *,\n    client: Any,\n    model: str = \"gpt-4o-audio-preview\",\n    tools: list[Any] | None = None,\n    system_prompt: str | None = None,\n    extra_create_kwargs: dict[str, Any] | None = None,\n) -&gt; None:\n    \"\"\"\n    Args:\n        client: An ``openai.AsyncOpenAI`` instance.\n        model: Model name supporting audio input.\n        tools: OpenAI tool definitions (function-calling format).\n        system_prompt: Optional system message prepended to the conversation.\n        extra_create_kwargs: Additional kwargs forwarded to\n            ``client.chat.completions.create()``.\n    \"\"\"\n    self.client = client\n    self.model = model\n    self.tools = tools\n    self.system_prompt = system_prompt\n    self.extra_create_kwargs = extra_create_kwargs or {}\n    self._parser = OpenAIResponseParser()\n</code></pre>"},{"location":"reference/adapters/openai/#russo.adapters.openai.OpenAIAgent.run","title":"run  <code>async</code>","text":"<pre><code>run(audio: Audio) -&gt; AgentResponse\n</code></pre> <p>Send audio via Chat Completions and parse the tool-call response.</p> Source code in <code>src/russo/adapters/openai.py</code> <pre><code>async def run(self, audio: Audio) -&gt; AgentResponse:\n    \"\"\"Send audio via Chat Completions and parse the tool-call response.\"\"\"\n    audio_b64 = base64.b64encode(audio.data).decode(\"ascii\")\n\n    messages: list[dict[str, Any]] = []\n    if self.system_prompt:\n        messages.append({\"role\": \"system\", \"content\": self.system_prompt})\n\n    messages.append(\n        {\n            \"role\": \"user\",\n            \"content\": [\n                {\n                    \"type\": \"input_audio\",\n                    \"input_audio\": {\"data\": audio_b64, \"format\": audio.format},\n                }\n            ],\n        }\n    )\n\n    kwargs: dict[str, Any] = {\n        \"model\": self.model,\n        \"messages\": messages,\n        **self.extra_create_kwargs,\n    }\n    if self.tools:\n        kwargs[\"tools\"] = self.tools\n\n    logger.debug(\"Sending %d bytes of %s audio to %s\", len(audio.data), audio.format, self.model)\n\n    response = await self.client.chat.completions.create(**kwargs)\n    return self._parser.parse(response)\n</code></pre>"},{"location":"reference/adapters/openai/#russo.adapters.openai.OpenAIRealtimeAgent","title":"OpenAIRealtimeAgent","text":"<pre><code>OpenAIRealtimeAgent(*, client: Any | None = None, connection: Any | None = None, model: str = 'gpt-4o-realtime-preview', tools: list[Any] | None = None, response_timeout: float = 30.0)\n</code></pre> <p>Agent adapter for OpenAI's Realtime API.</p> <p>Connects via the SDK's <code>client.beta.realtime.connect()</code> interface, sends audio, and collects <code>response.function_call_arguments.done</code> events.</p> <p>Accepts either:</p> <ul> <li>An <code>AsyncOpenAI</code> client (creates a new connection per <code>run()</code>)</li> <li>A pre-existing realtime connection (reuses it, no session config sent)</li> </ul> <p>Usage with client::</p> <pre><code>from openai import AsyncOpenAI\n\nclient = AsyncOpenAI()\nagent = OpenAIRealtimeAgent(\n    client=client,\n    model=\"gpt-4o-realtime-preview\",\n    tools=[{\n        \"type\": \"function\",\n        \"name\": \"book_flight\",\n        \"description\": \"Book a flight\",\n        \"parameters\": {\"type\": \"object\", \"properties\": {...}},\n    }],\n)\nresponse = await agent.run(audio)\n</code></pre> <p>Usage with pre-existing connection::</p> <pre><code>async with client.beta.realtime.connect(model=\"gpt-4o-realtime-preview\") as conn:\n    agent = OpenAIRealtimeAgent(connection=conn)\n    response = await agent.run(audio)\n</code></pre> Note <p>The Realtime API expects pcm16 audio at 24 kHz mono by default. If you pass WAV audio, the adapter automatically strips the WAV header to extract raw PCM frames.</p> PARAMETER DESCRIPTION <code>client</code> <p>An <code>openai.AsyncOpenAI</code> instance. Mutually preferred with connection.</p> <p> TYPE: <code>Any | None</code> DEFAULT: <code>None</code> </p> <code>connection</code> <p>A pre-existing realtime connection (from <code>client.beta.realtime.connect()</code>).</p> <p> TYPE: <code>Any | None</code> DEFAULT: <code>None</code> </p> <code>model</code> <p>Realtime model name.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'gpt-4o-realtime-preview'</code> </p> <code>tools</code> <p>Tool definitions sent during session configuration.</p> <p> TYPE: <code>list[Any] | None</code> DEFAULT: <code>None</code> </p> <code>response_timeout</code> <p>Max seconds to wait for a complete response.</p> <p> TYPE: <code>float</code> DEFAULT: <code>30.0</code> </p> Source code in <code>src/russo/adapters/openai.py</code> <pre><code>def __init__(\n    self,\n    *,\n    client: Any | None = None,\n    connection: Any | None = None,\n    model: str = \"gpt-4o-realtime-preview\",\n    tools: list[Any] | None = None,\n    response_timeout: float = 30.0,\n) -&gt; None:\n    \"\"\"\n    Args:\n        client: An ``openai.AsyncOpenAI`` instance. Mutually preferred with *connection*.\n        connection: A pre-existing realtime connection (from ``client.beta.realtime.connect()``).\n        model: Realtime model name.\n        tools: Tool definitions sent during session configuration.\n        response_timeout: Max seconds to wait for a complete response.\n    \"\"\"\n    if client is None and connection is None:\n        msg = \"Provide either 'client' (AsyncOpenAI) or 'connection' (realtime connection)\"\n        raise ValueError(msg)\n    self.client = client\n    self.connection = connection\n    self.model = model\n    self.tools = tools\n    self.response_timeout = response_timeout\n</code></pre>"},{"location":"reference/adapters/openai/#russo.adapters.openai.OpenAIRealtimeAgent.run","title":"run  <code>async</code>","text":"<pre><code>run(audio: Audio) -&gt; AgentResponse\n</code></pre> <p>Send audio via the Realtime API and collect function calls.</p> Source code in <code>src/russo/adapters/openai.py</code> <pre><code>async def run(self, audio: Audio) -&gt; AgentResponse:\n    \"\"\"Send audio via the Realtime API and collect function calls.\"\"\"\n    if self.connection is not None:\n        return await self._run_on(self.connection, audio, configure=False)\n\n    async with self.client.beta.realtime.connect(model=self.model) as conn:\n        return await self._run_on(conn, audio, configure=True)\n</code></pre>"},{"location":"reference/adapters/websocket/","title":"WebSocket Adapter","text":"<p>WebSocket agent adapter \u2014 sends audio to a WebSocket endpoint.</p> <p>Note</p> <p>Requires the <code>ws</code> extra: <code>pip install \"russo[ws]\"</code></p>"},{"location":"reference/adapters/websocket/#russo.adapters.websocket","title":"websocket","text":"<p>WebSocket agent adapter \u2014 sends audio to a WebSocket endpoint.</p> <p>Requires the <code>websockets</code> package: pip install russo[ws]</p>"},{"location":"reference/adapters/websocket/#russo.adapters.websocket.WebSocketAgent","title":"WebSocketAgent","text":"<pre><code>WebSocketAgent(*, url: str, parser: ResponseParser | None = None, headers: dict[str, str] | None = None, send_bytes: bool = False, audio_field: str = 'audio', format_field: str = 'format', response_timeout: float = 30.0, max_messages: int = 100, on_send: Callable[[Audio], str | bytes] | None = None, is_complete: Callable[[list[Any]], bool] | None = None, aggregate: Callable[[list[Any]], Any] | None = None, open_timeout: float = 10.0, close_timeout: float = 5.0, extra_ws_kwargs: dict[str, Any] | None = None)\n</code></pre> <p>Agent adapter that communicates over WebSocket.</p> <p>Connects to the endpoint, sends audio, collects response messages until a completion condition is met, then parses tool calls.</p> <p>Supports two send modes: - json (default): sends <code>{\"audio\": \"&lt;base64&gt;\", \"format\": \"wav\"}</code> - bytes: sends raw audio bytes directly on the wire</p> <p>And two ways to customize the protocol: - on_send: transform the Audio into whatever your server expects - is_complete: decide when to stop collecting response messages</p> Usage Source code in <code>src/russo/adapters/websocket.py</code> <pre><code>def __init__(\n    self,\n    *,\n    url: str,\n    parser: ResponseParser | None = None,\n    headers: dict[str, str] | None = None,\n    # Send options\n    send_bytes: bool = False,\n    audio_field: str = \"audio\",\n    format_field: str = \"format\",\n    # Response collection\n    response_timeout: float = 30.0,\n    max_messages: int = 100,\n    # Hooks\n    on_send: Callable[[Audio], str | bytes] | None = None,\n    is_complete: Callable[[list[Any]], bool] | None = None,\n    aggregate: Callable[[list[Any]], Any] | None = None,\n    # Connection\n    open_timeout: float = 10.0,\n    close_timeout: float = 5.0,\n    extra_ws_kwargs: dict[str, Any] | None = None,\n) -&gt; None:\n    if not _HAS_WEBSOCKETS:\n        msg = \"WebSocketAgent requires the 'websockets' package. Install with: pip install russo[ws]\"\n        raise ImportError(msg)\n\n    self.url = url\n    self.parser = parser\n    self.headers = headers or {}\n    self.send_bytes = send_bytes\n    self.audio_field = audio_field\n    self.format_field = format_field\n    self.response_timeout = response_timeout\n    self.max_messages = max_messages\n    self.on_send = on_send\n    self.is_complete = is_complete\n    self.aggregate = aggregate\n    self.open_timeout = open_timeout\n    self.close_timeout = close_timeout\n    self.extra_ws_kwargs = extra_ws_kwargs or {}\n</code></pre>"},{"location":"reference/adapters/websocket/#russo.adapters.websocket.WebSocketAgent--simple-json-protocol","title":"Simple JSON protocol","text":"<p>agent = WebSocketAgent(     url=\"ws://localhost:8000/ws/agent\",     parser=russo.parsers.GeminiResponseParser(), )</p>"},{"location":"reference/adapters/websocket/#russo.adapters.websocket.WebSocketAgent--raw-bytes-protocol-eg-streaming-pcm","title":"Raw bytes protocol (e.g. streaming PCM)","text":"<p>agent = WebSocketAgent(     url=\"ws://localhost:8000/ws/agent\",     send_bytes=True, )</p>"},{"location":"reference/adapters/websocket/#russo.adapters.websocket.WebSocketAgent--fully-custom-sendreceive","title":"Fully custom send/receive","text":"<p>agent = WebSocketAgent(     url=\"ws://localhost:8000/ws/agent\",     on_send=lambda audio: json.dumps({\"pcm\": base64.b64encode(audio.data).decode()}),     is_complete=lambda msgs: any('\"done\": true' in str(m) for m in msgs), )</p>"},{"location":"reference/adapters/websocket/#russo.adapters.websocket.WebSocketAgent.run","title":"run  <code>async</code>","text":"<pre><code>run(audio: Audio) -&gt; AgentResponse\n</code></pre> <p>Send audio over WebSocket and collect the response.</p> Source code in <code>src/russo/adapters/websocket.py</code> <pre><code>async def run(self, audio: Audio) -&gt; AgentResponse:\n    \"\"\"Send audio over WebSocket and collect the response.\"\"\"\n    import websockets\n\n    async with websockets.connect(\n        self.url,\n        additional_headers=self.headers or None,\n        open_timeout=self.open_timeout,\n        close_timeout=self.close_timeout,\n        **self.extra_ws_kwargs,\n    ) as ws:\n        # --- Send ---\n        message = self._prepare_message(audio)\n        if isinstance(message, bytes):\n            await ws.send(message)\n        else:\n            await ws.send(message)\n        logger.debug(\n            \"Sent %s message (%d bytes)\",\n            \"binary\" if isinstance(message, bytes) else \"text\",\n            len(message),\n        )\n\n        # --- Collect responses ---\n        messages = await self._collect_responses(ws)\n        logger.debug(\"Collected %d response messages\", len(messages))\n\n    # --- Parse ---\n    raw = self._aggregate(messages)\n\n    if self.parser:\n        return self.parser.parse(raw)\n    return self._default_parse(raw)\n</code></pre>"},{"location":"reference/core/assertions/","title":"Assertions","text":"<p>Custom assertion helpers for russo test results.</p>"},{"location":"reference/core/assertions/#russo._assertions","title":"_assertions","text":"<p>Custom assertion helpers for russo test results.</p>"},{"location":"reference/core/assertions/#russo._assertions.ToolCallAssertionError","title":"ToolCallAssertionError","text":"<pre><code>ToolCallAssertionError(result: EvalResult, message: str = '')\n</code></pre> <p>               Bases: <code>AssertionError</code></p> <p>Rich assertion error with detailed tool call diff.</p> Source code in <code>src/russo/_assertions.py</code> <pre><code>def __init__(self, result: EvalResult, message: str = \"\") -&gt; None:\n    self.result = result\n    detail = result.summary()\n    full_message = f\"{message}\\n{detail}\" if message else detail\n    super().__init__(full_message)\n</code></pre>"},{"location":"reference/core/assertions/#russo._assertions.assert_tool_calls","title":"assert_tool_calls","text":"<pre><code>assert_tool_calls(result: EvalResult, *, message: str = '') -&gt; None\n</code></pre> <p>Assert that an EvalResult passed.</p> <p>Raises a ToolCallAssertionError with a rich diff if it didn't.</p> Usage <p>result = await russo.run(...) russo.assert_tool_calls(result)</p> Source code in <code>src/russo/_assertions.py</code> <pre><code>def assert_tool_calls(\n    result: EvalResult,\n    *,\n    message: str = \"\",\n) -&gt; None:\n    \"\"\"Assert that an EvalResult passed.\n\n    Raises a ToolCallAssertionError with a rich diff if it didn't.\n\n    Usage:\n        result = await russo.run(...)\n        russo.assert_tool_calls(result)\n\n        # Or with a custom message\n        russo.assert_tool_calls(result, message=\"Flight booking should work\")\n    \"\"\"\n    if not result.passed:\n        raise ToolCallAssertionError(result, message)\n</code></pre>"},{"location":"reference/core/assertions/#russo._assertions.assert_tool_calls--or-with-a-custom-message","title":"Or with a custom message","text":"<p>russo.assert_tool_calls(result, message=\"Flight booking should work\")</p>"},{"location":"reference/core/cache/","title":"Cache","text":"<p>Audio caching for synthesized prompts.</p>"},{"location":"reference/core/cache/#russo._cache","title":"_cache","text":"<p>Audio caching for synthesized prompts.</p> <p>Saves synthesized audio to disk keyed by a hash of the prompt text, so repeated test runs skip the TTS call entirely.</p>"},{"location":"reference/core/cache/#russo._cache.AudioCache","title":"AudioCache","text":"<pre><code>AudioCache(cache_dir: Path = _DEFAULT_CACHE_DIR)\n</code></pre> <p>File-system cache for synthesized audio.</p> Each entry is a pair of files <p>.audio  \u2014 raw audio bytes .meta   \u2014 JSON with format, sample_rate, prompt Usage <p>cache = AudioCache()                     # .russo_cache/ cache = AudioCache(Path(\"my_cache\"))     # custom dir cache.get(\"abc123\")                      # Audio | None cache.put(\"abc123\", audio) cache.clear()</p> Source code in <code>src/russo/_cache.py</code> <pre><code>def __init__(self, cache_dir: Path = _DEFAULT_CACHE_DIR) -&gt; None:\n    self.cache_dir = cache_dir\n</code></pre>"},{"location":"reference/core/cache/#russo._cache.AudioCache.cache_key","title":"cache_key","text":"<pre><code>cache_key(prompt: str, **extra: Any) -&gt; str\n</code></pre> <p>Deterministic key from prompt text + optional extra metadata.</p> <p>Extra kwargs (e.g. voice, model) are included so a change in synthesizer config invalidates the cache automatically.</p> Source code in <code>src/russo/_cache.py</code> <pre><code>def cache_key(self, prompt: str, **extra: Any) -&gt; str:\n    \"\"\"Deterministic key from prompt text + optional extra metadata.\n\n    Extra kwargs (e.g. voice, model) are included so a change in\n    synthesizer config invalidates the cache automatically.\n    \"\"\"\n    blob = json.dumps({\"prompt\": prompt, **extra}, sort_keys=True)\n    return hashlib.sha256(blob.encode()).hexdigest()[:24]\n</code></pre>"},{"location":"reference/core/cache/#russo._cache.AudioCache.get","title":"get","text":"<pre><code>get(key: str) -&gt; Audio | None\n</code></pre> <p>Load cached audio, or None if not cached.</p> Source code in <code>src/russo/_cache.py</code> <pre><code>def get(self, key: str) -&gt; Audio | None:\n    \"\"\"Load cached audio, or None if not cached.\"\"\"\n    audio_path = self.cache_dir / f\"{key}.audio\"\n    meta_path = self.cache_dir / f\"{key}.meta\"\n    if not audio_path.exists() or not meta_path.exists():\n        return None\n    try:\n        meta = json.loads(meta_path.read_text())\n        data = audio_path.read_bytes()\n        logger.debug(\"Cache hit: %s\", key)\n        return Audio(\n            data=data, format=meta[\"format\"], sample_rate=meta[\"sample_rate\"]\n        )\n    except (json.JSONDecodeError, KeyError, OSError) as exc:\n        logger.warning(\"Corrupt cache entry %s, removing: %s\", key, exc)\n        self._remove_entry(key)\n        return None\n</code></pre>"},{"location":"reference/core/cache/#russo._cache.AudioCache.put","title":"put","text":"<pre><code>put(key: str, audio: Audio, *, prompt: str = '') -&gt; None\n</code></pre> <p>Write audio + metadata to cache.</p> Source code in <code>src/russo/_cache.py</code> <pre><code>def put(self, key: str, audio: Audio, *, prompt: str = \"\") -&gt; None:\n    \"\"\"Write audio + metadata to cache.\"\"\"\n    self._ensure_dir()\n    audio_path = self.cache_dir / f\"{key}.audio\"\n    meta_path = self.cache_dir / f\"{key}.meta\"\n    audio_path.write_bytes(audio.data)\n    meta = {\n        \"format\": audio.format,\n        \"sample_rate\": audio.sample_rate,\n        \"prompt\": prompt,\n    }\n    meta_path.write_text(json.dumps(meta, indent=2))\n    logger.debug(\"Cached: %s (%d bytes)\", key, len(audio.data))\n</code></pre>"},{"location":"reference/core/cache/#russo._cache.AudioCache.clear","title":"clear","text":"<pre><code>clear() -&gt; None\n</code></pre> <p>Remove all cached entries.</p> Source code in <code>src/russo/_cache.py</code> <pre><code>def clear(self) -&gt; None:\n    \"\"\"Remove all cached entries.\"\"\"\n    if not self.cache_dir.exists():\n        return\n    count = 0\n    for f in self.cache_dir.iterdir():\n        if f.suffix in (\".audio\", \".meta\"):\n            f.unlink()\n            count += 1\n    logger.info(\"Cleared %d cache files from %s\", count, self.cache_dir)\n</code></pre>"},{"location":"reference/core/cache/#russo._cache.AudioCache.size","title":"size","text":"<pre><code>size() -&gt; int\n</code></pre> <p>Number of cached audio entries.</p> Source code in <code>src/russo/_cache.py</code> <pre><code>def size(self) -&gt; int:\n    \"\"\"Number of cached audio entries.\"\"\"\n    if not self.cache_dir.exists():\n        return 0\n    return sum(1 for f in self.cache_dir.iterdir() if f.suffix == \".audio\")\n</code></pre>"},{"location":"reference/core/cache/#russo._cache.CachedSynthesizer","title":"CachedSynthesizer","text":"<pre><code>CachedSynthesizer(synthesizer: Synthesizer, *, cache: AudioCache | None = None, enabled: bool = True, cache_key_extra: dict[str, Any] | None = None)\n</code></pre> <p>Wraps any Synthesizer with local audio caching.</p> <p>Satisfies the Synthesizer protocol \u2014 drop-in replacement.</p> Usage <p>synth = CachedSynthesizer(GoogleSynthesizer(...))</p> Source code in <code>src/russo/_cache.py</code> <pre><code>def __init__(\n    self,\n    synthesizer: Synthesizer,\n    *,\n    cache: AudioCache | None = None,\n    enabled: bool = True,\n    cache_key_extra: dict[str, Any] | None = None,\n) -&gt; None:\n    self.inner = synthesizer\n    self.cache = cache or AudioCache()\n    self.enabled = enabled\n    self.cache_key_extra = cache_key_extra or {}\n</code></pre>"},{"location":"reference/core/cache/#russo._cache.CachedSynthesizer--disable-caching-at-runtime","title":"Disable caching at runtime","text":"<p>synth = CachedSynthesizer(GoogleSynthesizer(...), enabled=False)</p>"},{"location":"reference/core/cache/#russo._cache.CachedSynthesizer--custom-cache-directory","title":"Custom cache directory","text":"<p>synth = CachedSynthesizer(     GoogleSynthesizer(...),     cache=AudioCache(Path(\"/tmp/my_cache\")), )</p>"},{"location":"reference/core/cache/#russo._cache.CachedSynthesizer--include-synthesizer-config-in-cache-key-invalidates-on-config-change","title":"Include synthesizer config in cache key (invalidates on config change)","text":"<p>synth = CachedSynthesizer(     GoogleSynthesizer(voice=\"Kore\", model=\"gemini-2.5-flash-preview-tts\"),     cache_key_extra={\"voice\": \"Kore\", \"model\": \"gemini-2.5-flash-preview-tts\"}, )</p>"},{"location":"reference/core/cache/#russo._cache.CachedSynthesizer--clear-cache","title":"Clear cache","text":"<p>synth.cache.clear()</p>"},{"location":"reference/core/cache/#russo._cache.CachedSynthesizer.synthesize","title":"synthesize  <code>async</code>","text":"<pre><code>synthesize(text: str) -&gt; Audio\n</code></pre> <p>Synthesize with cache lookup/store.</p> Source code in <code>src/russo/_cache.py</code> <pre><code>async def synthesize(self, text: str) -&gt; Audio:\n    \"\"\"Synthesize with cache lookup/store.\"\"\"\n    if not self.enabled:\n        return await self.inner.synthesize(text)\n\n    key = self.cache.cache_key(text, **self.cache_key_extra)\n    cached = self.cache.get(key)\n    if cached is not None:\n        return cached\n\n    audio = await self.inner.synthesize(text)\n    self.cache.put(key, audio, prompt=text)\n    return audio\n</code></pre>"},{"location":"reference/core/init/","title":"russo","text":"<p>Top-level module exports.</p>"},{"location":"reference/core/init/#russo","title":"russo","text":"<p>russo \u2014 testing framework for LLM tool-call accuracy.</p>"},{"location":"reference/core/init/#russo.Audio","title":"Audio","text":"<p>               Bases: <code>BaseModel</code></p> <p>Audio data with format metadata.</p>"},{"location":"reference/core/init/#russo.Audio.save","title":"save","text":"<pre><code>save(path: str | Path) -&gt; Path\n</code></pre> <p>Save audio to a file. Wraps raw PCM in a WAV container if needed.</p> Usage <p>audio.save(\"output.wav\")</p> Source code in <code>src/russo/_types.py</code> <pre><code>def save(self, path: str | Path) -&gt; Path:\n    \"\"\"Save audio to a file. Wraps raw PCM in a WAV container if needed.\n\n    Usage:\n        audio.save(\"output.wav\")\n    \"\"\"\n    import wave\n    from pathlib import Path as _Path\n\n    p = _Path(path)\n    p.parent.mkdir(parents=True, exist_ok=True)\n\n    if p.suffix.lower() == \".wav\":\n        with wave.open(str(p), \"wb\") as wf:\n            wf.setnchannels(self.channels)\n            wf.setsampwidth(self.sample_width)\n            wf.setframerate(self.sample_rate)\n            wf.writeframes(self.data)\n    else:\n        # For non-WAV formats, write raw bytes\n        p.write_bytes(self.data)\n    return p\n</code></pre>"},{"location":"reference/core/init/#russo.ToolCall","title":"ToolCall","text":"<p>               Bases: <code>BaseModel</code></p> <p>A normalized tool/function call representation.</p> <p>Provider-agnostic \u2014 parsers convert provider-specific formats into this.</p>"},{"location":"reference/core/init/#russo.AgentResponse","title":"AgentResponse","text":"<p>               Bases: <code>BaseModel</code></p> <p>Normalized response from an agent, containing extracted tool calls.</p>"},{"location":"reference/core/init/#russo.AgentResponse.raw","title":"raw  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>raw: Any | None = None\n</code></pre> <p>The raw, unparsed response from the provider (for debugging).</p>"},{"location":"reference/core/init/#russo.EvalResult","title":"EvalResult","text":"<p>               Bases: <code>BaseModel</code></p> <p>Full evaluation result for a test scenario.</p>"},{"location":"reference/core/init/#russo.EvalResult.match_rate","title":"match_rate  <code>property</code>","text":"<pre><code>match_rate: float\n</code></pre> <p>Fraction of expected tool calls that matched.</p>"},{"location":"reference/core/init/#russo.EvalResult.summary","title":"summary","text":"<pre><code>summary() -&gt; str\n</code></pre> <p>Human-readable summary of the evaluation.</p> Source code in <code>src/russo/_types.py</code> <pre><code>def summary(self) -&gt; str:\n    \"\"\"Human-readable summary of the evaluation.\"\"\"\n    status = \"PASSED\" if self.passed else \"FAILED\"\n    lines = [f\"{status} ({self.match_rate:.0%} match rate)\"]\n    for m in self.matches:\n        icon = \"+\" if m.matched else \"-\"\n        actual_str = (\n            f\" -&gt; {m.actual.name}({m.actual.arguments})\"\n            if m.actual\n            else \" -&gt; (no match)\"\n        )\n        lines.append(\n            f\"  [{icon}] {m.expected.name}({m.expected.arguments}){actual_str}\"\n        )\n        if m.details:\n            lines.append(f\"      {m.details}\")\n    return \"\\n\".join(lines)\n</code></pre>"},{"location":"reference/core/init/#russo.ToolCallMatch","title":"ToolCallMatch","text":"<p>               Bases: <code>BaseModel</code></p> <p>Result of comparing a single expected tool call against actuals.</p>"},{"location":"reference/core/init/#russo.AudioCache","title":"AudioCache","text":"<pre><code>AudioCache(cache_dir: Path = _DEFAULT_CACHE_DIR)\n</code></pre> <p>File-system cache for synthesized audio.</p> Each entry is a pair of files <p>.audio  \u2014 raw audio bytes .meta   \u2014 JSON with format, sample_rate, prompt Usage <p>cache = AudioCache()                     # .russo_cache/ cache = AudioCache(Path(\"my_cache\"))     # custom dir cache.get(\"abc123\")                      # Audio | None cache.put(\"abc123\", audio) cache.clear()</p> Source code in <code>src/russo/_cache.py</code> <pre><code>def __init__(self, cache_dir: Path = _DEFAULT_CACHE_DIR) -&gt; None:\n    self.cache_dir = cache_dir\n</code></pre>"},{"location":"reference/core/init/#russo.AudioCache.cache_key","title":"cache_key","text":"<pre><code>cache_key(prompt: str, **extra: Any) -&gt; str\n</code></pre> <p>Deterministic key from prompt text + optional extra metadata.</p> <p>Extra kwargs (e.g. voice, model) are included so a change in synthesizer config invalidates the cache automatically.</p> Source code in <code>src/russo/_cache.py</code> <pre><code>def cache_key(self, prompt: str, **extra: Any) -&gt; str:\n    \"\"\"Deterministic key from prompt text + optional extra metadata.\n\n    Extra kwargs (e.g. voice, model) are included so a change in\n    synthesizer config invalidates the cache automatically.\n    \"\"\"\n    blob = json.dumps({\"prompt\": prompt, **extra}, sort_keys=True)\n    return hashlib.sha256(blob.encode()).hexdigest()[:24]\n</code></pre>"},{"location":"reference/core/init/#russo.AudioCache.get","title":"get","text":"<pre><code>get(key: str) -&gt; Audio | None\n</code></pre> <p>Load cached audio, or None if not cached.</p> Source code in <code>src/russo/_cache.py</code> <pre><code>def get(self, key: str) -&gt; Audio | None:\n    \"\"\"Load cached audio, or None if not cached.\"\"\"\n    audio_path = self.cache_dir / f\"{key}.audio\"\n    meta_path = self.cache_dir / f\"{key}.meta\"\n    if not audio_path.exists() or not meta_path.exists():\n        return None\n    try:\n        meta = json.loads(meta_path.read_text())\n        data = audio_path.read_bytes()\n        logger.debug(\"Cache hit: %s\", key)\n        return Audio(\n            data=data, format=meta[\"format\"], sample_rate=meta[\"sample_rate\"]\n        )\n    except (json.JSONDecodeError, KeyError, OSError) as exc:\n        logger.warning(\"Corrupt cache entry %s, removing: %s\", key, exc)\n        self._remove_entry(key)\n        return None\n</code></pre>"},{"location":"reference/core/init/#russo.AudioCache.put","title":"put","text":"<pre><code>put(key: str, audio: Audio, *, prompt: str = '') -&gt; None\n</code></pre> <p>Write audio + metadata to cache.</p> Source code in <code>src/russo/_cache.py</code> <pre><code>def put(self, key: str, audio: Audio, *, prompt: str = \"\") -&gt; None:\n    \"\"\"Write audio + metadata to cache.\"\"\"\n    self._ensure_dir()\n    audio_path = self.cache_dir / f\"{key}.audio\"\n    meta_path = self.cache_dir / f\"{key}.meta\"\n    audio_path.write_bytes(audio.data)\n    meta = {\n        \"format\": audio.format,\n        \"sample_rate\": audio.sample_rate,\n        \"prompt\": prompt,\n    }\n    meta_path.write_text(json.dumps(meta, indent=2))\n    logger.debug(\"Cached: %s (%d bytes)\", key, len(audio.data))\n</code></pre>"},{"location":"reference/core/init/#russo.AudioCache.clear","title":"clear","text":"<pre><code>clear() -&gt; None\n</code></pre> <p>Remove all cached entries.</p> Source code in <code>src/russo/_cache.py</code> <pre><code>def clear(self) -&gt; None:\n    \"\"\"Remove all cached entries.\"\"\"\n    if not self.cache_dir.exists():\n        return\n    count = 0\n    for f in self.cache_dir.iterdir():\n        if f.suffix in (\".audio\", \".meta\"):\n            f.unlink()\n            count += 1\n    logger.info(\"Cleared %d cache files from %s\", count, self.cache_dir)\n</code></pre>"},{"location":"reference/core/init/#russo.AudioCache.size","title":"size","text":"<pre><code>size() -&gt; int\n</code></pre> <p>Number of cached audio entries.</p> Source code in <code>src/russo/_cache.py</code> <pre><code>def size(self) -&gt; int:\n    \"\"\"Number of cached audio entries.\"\"\"\n    if not self.cache_dir.exists():\n        return 0\n    return sum(1 for f in self.cache_dir.iterdir() if f.suffix == \".audio\")\n</code></pre>"},{"location":"reference/core/init/#russo.CachedSynthesizer","title":"CachedSynthesizer","text":"<pre><code>CachedSynthesizer(synthesizer: Synthesizer, *, cache: AudioCache | None = None, enabled: bool = True, cache_key_extra: dict[str, Any] | None = None)\n</code></pre> <p>Wraps any Synthesizer with local audio caching.</p> <p>Satisfies the Synthesizer protocol \u2014 drop-in replacement.</p> Usage <p>synth = CachedSynthesizer(GoogleSynthesizer(...))</p> Source code in <code>src/russo/_cache.py</code> <pre><code>def __init__(\n    self,\n    synthesizer: Synthesizer,\n    *,\n    cache: AudioCache | None = None,\n    enabled: bool = True,\n    cache_key_extra: dict[str, Any] | None = None,\n) -&gt; None:\n    self.inner = synthesizer\n    self.cache = cache or AudioCache()\n    self.enabled = enabled\n    self.cache_key_extra = cache_key_extra or {}\n</code></pre>"},{"location":"reference/core/init/#russo.CachedSynthesizer--disable-caching-at-runtime","title":"Disable caching at runtime","text":"<p>synth = CachedSynthesizer(GoogleSynthesizer(...), enabled=False)</p>"},{"location":"reference/core/init/#russo.CachedSynthesizer--custom-cache-directory","title":"Custom cache directory","text":"<p>synth = CachedSynthesizer(     GoogleSynthesizer(...),     cache=AudioCache(Path(\"/tmp/my_cache\")), )</p>"},{"location":"reference/core/init/#russo.CachedSynthesizer--include-synthesizer-config-in-cache-key-invalidates-on-config-change","title":"Include synthesizer config in cache key (invalidates on config change)","text":"<p>synth = CachedSynthesizer(     GoogleSynthesizer(voice=\"Kore\", model=\"gemini-2.5-flash-preview-tts\"),     cache_key_extra={\"voice\": \"Kore\", \"model\": \"gemini-2.5-flash-preview-tts\"}, )</p>"},{"location":"reference/core/init/#russo.CachedSynthesizer--clear-cache","title":"Clear cache","text":"<p>synth.cache.clear()</p>"},{"location":"reference/core/init/#russo.CachedSynthesizer.synthesize","title":"synthesize  <code>async</code>","text":"<pre><code>synthesize(text: str) -&gt; Audio\n</code></pre> <p>Synthesize with cache lookup/store.</p> Source code in <code>src/russo/_cache.py</code> <pre><code>async def synthesize(self, text: str) -&gt; Audio:\n    \"\"\"Synthesize with cache lookup/store.\"\"\"\n    if not self.enabled:\n        return await self.inner.synthesize(text)\n\n    key = self.cache.cache_key(text, **self.cache_key_extra)\n    cached = self.cache.get(key)\n    if cached is not None:\n        return cached\n\n    audio = await self.inner.synthesize(text)\n    self.cache.put(key, audio, prompt=text)\n    return audio\n</code></pre>"},{"location":"reference/core/init/#russo.ToolCallAssertionError","title":"ToolCallAssertionError","text":"<pre><code>ToolCallAssertionError(result: EvalResult, message: str = '')\n</code></pre> <p>               Bases: <code>AssertionError</code></p> <p>Rich assertion error with detailed tool call diff.</p> Source code in <code>src/russo/_assertions.py</code> <pre><code>def __init__(self, result: EvalResult, message: str = \"\") -&gt; None:\n    self.result = result\n    detail = result.summary()\n    full_message = f\"{message}\\n{detail}\" if message else detail\n    super().__init__(full_message)\n</code></pre>"},{"location":"reference/core/init/#russo.tool_call","title":"tool_call","text":"<pre><code>tool_call(name: str, **arguments: Any) -&gt; ToolCall\n</code></pre> <p>Shorthand for creating a ToolCall.</p> Usage <p>russo.tool_call(\"book_flight\", from_city=\"NYC\", to_city=\"LA\")</p> Source code in <code>src/russo/_helpers.py</code> <pre><code>def tool_call(name: str, **arguments: Any) -&gt; ToolCall:\n    \"\"\"Shorthand for creating a ToolCall.\n\n    Usage:\n        russo.tool_call(\"book_flight\", from_city=\"NYC\", to_city=\"LA\")\n    \"\"\"\n    return ToolCall(name=name, arguments=arguments)\n</code></pre>"},{"location":"reference/core/init/#russo.agent","title":"agent","text":"<pre><code>agent(fn: Callable[[Audio], Coroutine[Any, Any, AgentResponse]]) -&gt; _CallableAgent\n</code></pre> <p>Decorator to turn an async function into an Agent.</p> Usage <p>@russo.agent async def my_agent(audio: russo.Audio) -&gt; russo.AgentResponse:     result = await call_my_api(audio.data)     return russo.AgentResponse(tool_calls=[...])</p> Source code in <code>src/russo/_helpers.py</code> <pre><code>def agent(fn: Callable[[Audio], Coroutine[Any, Any, AgentResponse]]) -&gt; _CallableAgent:\n    \"\"\"Decorator to turn an async function into an Agent.\n\n    Usage:\n        @russo.agent\n        async def my_agent(audio: russo.Audio) -&gt; russo.AgentResponse:\n            result = await call_my_api(audio.data)\n            return russo.AgentResponse(tool_calls=[...])\n    \"\"\"\n    return _CallableAgent(fn)\n</code></pre>"},{"location":"reference/core/init/#russo.run","title":"run  <code>async</code>","text":"<pre><code>run(*, prompt: str, synthesizer: Synthesizer, agent: Agent, evaluator: Evaluator, expect: list[ToolCall]) -&gt; EvalResult\n</code></pre> <p>Run the full russo pipeline.</p> <ol> <li>Synthesize audio from the text prompt.</li> <li>Pass audio to the agent under test.</li> <li>Evaluate the agent's tool calls against expectations.</li> </ol> PARAMETER DESCRIPTION <code>prompt</code> <p>The text prompt to synthesize into audio.</p> <p> TYPE: <code>str</code> </p> <code>synthesizer</code> <p>Converts text to audio.</p> <p> TYPE: <code>Synthesizer</code> </p> <code>agent</code> <p>The agent under test.</p> <p> TYPE: <code>Agent</code> </p> <code>evaluator</code> <p>Compares expected vs actual tool calls.</p> <p> TYPE: <code>Evaluator</code> </p> <code>expect</code> <p>The expected tool calls.</p> <p> TYPE: <code>list[ToolCall]</code> </p> RETURNS DESCRIPTION <code>EvalResult</code> <p>EvalResult with pass/fail and per-call match details.</p> Source code in <code>src/russo/_pipeline.py</code> <pre><code>async def run(\n    *,\n    prompt: str,\n    synthesizer: Synthesizer,\n    agent: Agent,\n    evaluator: Evaluator,\n    expect: list[ToolCall],\n) -&gt; EvalResult:\n    \"\"\"Run the full russo pipeline.\n\n    1. Synthesize audio from the text prompt.\n    2. Pass audio to the agent under test.\n    3. Evaluate the agent's tool calls against expectations.\n\n    Args:\n        prompt: The text prompt to synthesize into audio.\n        synthesizer: Converts text to audio.\n        agent: The agent under test.\n        evaluator: Compares expected vs actual tool calls.\n        expect: The expected tool calls.\n\n    Returns:\n        EvalResult with pass/fail and per-call match details.\n    \"\"\"\n    audio = await synthesizer.synthesize(prompt)\n    response = await agent.run(audio)\n    return evaluator.evaluate(expected=expect, actual=response.tool_calls)\n</code></pre>"},{"location":"reference/core/init/#russo.assert_tool_calls","title":"assert_tool_calls","text":"<pre><code>assert_tool_calls(result: EvalResult, *, message: str = '') -&gt; None\n</code></pre> <p>Assert that an EvalResult passed.</p> <p>Raises a ToolCallAssertionError with a rich diff if it didn't.</p> Usage <p>result = await russo.run(...) russo.assert_tool_calls(result)</p> Source code in <code>src/russo/_assertions.py</code> <pre><code>def assert_tool_calls(\n    result: EvalResult,\n    *,\n    message: str = \"\",\n) -&gt; None:\n    \"\"\"Assert that an EvalResult passed.\n\n    Raises a ToolCallAssertionError with a rich diff if it didn't.\n\n    Usage:\n        result = await russo.run(...)\n        russo.assert_tool_calls(result)\n\n        # Or with a custom message\n        russo.assert_tool_calls(result, message=\"Flight booking should work\")\n    \"\"\"\n    if not result.passed:\n        raise ToolCallAssertionError(result, message)\n</code></pre>"},{"location":"reference/core/init/#russo.assert_tool_calls--or-with-a-custom-message","title":"Or with a custom message","text":"<p>russo.assert_tool_calls(result, message=\"Flight booking should work\")</p>"},{"location":"reference/core/pipeline/","title":"Pipeline","text":"<p>The <code>run()</code> function orchestrates the full russo pipeline.</p>"},{"location":"reference/core/pipeline/#russo._pipeline","title":"_pipeline","text":"<p>Pipeline orchestrator \u2014 chains Synthesizer -&gt; Agent -&gt; Evaluator.</p>"},{"location":"reference/core/pipeline/#russo._pipeline.run","title":"run  <code>async</code>","text":"<pre><code>run(*, prompt: str, synthesizer: Synthesizer, agent: Agent, evaluator: Evaluator, expect: list[ToolCall]) -&gt; EvalResult\n</code></pre> <p>Run the full russo pipeline.</p> <ol> <li>Synthesize audio from the text prompt.</li> <li>Pass audio to the agent under test.</li> <li>Evaluate the agent's tool calls against expectations.</li> </ol> PARAMETER DESCRIPTION <code>prompt</code> <p>The text prompt to synthesize into audio.</p> <p> TYPE: <code>str</code> </p> <code>synthesizer</code> <p>Converts text to audio.</p> <p> TYPE: <code>Synthesizer</code> </p> <code>agent</code> <p>The agent under test.</p> <p> TYPE: <code>Agent</code> </p> <code>evaluator</code> <p>Compares expected vs actual tool calls.</p> <p> TYPE: <code>Evaluator</code> </p> <code>expect</code> <p>The expected tool calls.</p> <p> TYPE: <code>list[ToolCall]</code> </p> RETURNS DESCRIPTION <code>EvalResult</code> <p>EvalResult with pass/fail and per-call match details.</p> Source code in <code>src/russo/_pipeline.py</code> <pre><code>async def run(\n    *,\n    prompt: str,\n    synthesizer: Synthesizer,\n    agent: Agent,\n    evaluator: Evaluator,\n    expect: list[ToolCall],\n) -&gt; EvalResult:\n    \"\"\"Run the full russo pipeline.\n\n    1. Synthesize audio from the text prompt.\n    2. Pass audio to the agent under test.\n    3. Evaluate the agent's tool calls against expectations.\n\n    Args:\n        prompt: The text prompt to synthesize into audio.\n        synthesizer: Converts text to audio.\n        agent: The agent under test.\n        evaluator: Compares expected vs actual tool calls.\n        expect: The expected tool calls.\n\n    Returns:\n        EvalResult with pass/fail and per-call match details.\n    \"\"\"\n    audio = await synthesizer.synthesize(prompt)\n    response = await agent.run(audio)\n    return evaluator.evaluate(expected=expect, actual=response.tool_calls)\n</code></pre>"},{"location":"reference/core/protocols/","title":"Protocols","text":"<p>Protocol definitions for russo extension points.</p>"},{"location":"reference/core/protocols/#russo._protocols","title":"_protocols","text":"<p>Protocol definitions for russo extension points.</p> <p>All extension points use typing.Protocol (structural subtyping). Users never need to inherit \u2014 if the object has the right methods, it works.</p>"},{"location":"reference/core/protocols/#russo._protocols.Synthesizer","title":"Synthesizer","text":"<p>               Bases: <code>Protocol</code></p> <p>Converts text into audio.</p> <p>Implement this to plug in any TTS provider (Google, OpenAI, ElevenLabs, etc.).</p>"},{"location":"reference/core/protocols/#russo._protocols.Agent","title":"Agent","text":"<p>               Bases: <code>Protocol</code></p> <p>The agent under test.</p> <p>Takes audio input and returns a response containing tool calls.</p>"},{"location":"reference/core/protocols/#russo._protocols.Evaluator","title":"Evaluator","text":"<p>               Bases: <code>Protocol</code></p> <p>Compares expected tool calls against actual tool calls.</p> <p>Implement this for custom matching logic (exact, semantic, partial, etc.).</p>"},{"location":"reference/core/protocols/#russo._protocols.ResponseParser","title":"ResponseParser","text":"<p>               Bases: <code>Protocol</code></p> <p>Parses a provider-specific raw response into a normalized AgentResponse.</p> <p>Implement this for each LLM provider format (Gemini, OpenAI, Anthropic, etc.).</p>"},{"location":"reference/core/types/","title":"Types","text":"<p>Core data types for russo. All types are Pydantic models.</p>"},{"location":"reference/core/types/#russo._types","title":"_types","text":"<p>Core data types for russo.</p> <p>All data flowing through the pipeline is a Pydantic model, giving us validation, serialization, and rich repr for free.</p>"},{"location":"reference/core/types/#russo._types.Audio","title":"Audio","text":"<p>               Bases: <code>BaseModel</code></p> <p>Audio data with format metadata.</p>"},{"location":"reference/core/types/#russo._types.Audio.save","title":"save","text":"<pre><code>save(path: str | Path) -&gt; Path\n</code></pre> <p>Save audio to a file. Wraps raw PCM in a WAV container if needed.</p> Usage <p>audio.save(\"output.wav\")</p> Source code in <code>src/russo/_types.py</code> <pre><code>def save(self, path: str | Path) -&gt; Path:\n    \"\"\"Save audio to a file. Wraps raw PCM in a WAV container if needed.\n\n    Usage:\n        audio.save(\"output.wav\")\n    \"\"\"\n    import wave\n    from pathlib import Path as _Path\n\n    p = _Path(path)\n    p.parent.mkdir(parents=True, exist_ok=True)\n\n    if p.suffix.lower() == \".wav\":\n        with wave.open(str(p), \"wb\") as wf:\n            wf.setnchannels(self.channels)\n            wf.setsampwidth(self.sample_width)\n            wf.setframerate(self.sample_rate)\n            wf.writeframes(self.data)\n    else:\n        # For non-WAV formats, write raw bytes\n        p.write_bytes(self.data)\n    return p\n</code></pre>"},{"location":"reference/core/types/#russo._types.ToolCall","title":"ToolCall","text":"<p>               Bases: <code>BaseModel</code></p> <p>A normalized tool/function call representation.</p> <p>Provider-agnostic \u2014 parsers convert provider-specific formats into this.</p>"},{"location":"reference/core/types/#russo._types.AgentResponse","title":"AgentResponse","text":"<p>               Bases: <code>BaseModel</code></p> <p>Normalized response from an agent, containing extracted tool calls.</p>"},{"location":"reference/core/types/#russo._types.AgentResponse.raw","title":"raw  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>raw: Any | None = None\n</code></pre> <p>The raw, unparsed response from the provider (for debugging).</p>"},{"location":"reference/core/types/#russo._types.ToolCallMatch","title":"ToolCallMatch","text":"<p>               Bases: <code>BaseModel</code></p> <p>Result of comparing a single expected tool call against actuals.</p>"},{"location":"reference/core/types/#russo._types.EvalResult","title":"EvalResult","text":"<p>               Bases: <code>BaseModel</code></p> <p>Full evaluation result for a test scenario.</p>"},{"location":"reference/core/types/#russo._types.EvalResult.match_rate","title":"match_rate  <code>property</code>","text":"<pre><code>match_rate: float\n</code></pre> <p>Fraction of expected tool calls that matched.</p>"},{"location":"reference/core/types/#russo._types.EvalResult.summary","title":"summary","text":"<pre><code>summary() -&gt; str\n</code></pre> <p>Human-readable summary of the evaluation.</p> Source code in <code>src/russo/_types.py</code> <pre><code>def summary(self) -&gt; str:\n    \"\"\"Human-readable summary of the evaluation.\"\"\"\n    status = \"PASSED\" if self.passed else \"FAILED\"\n    lines = [f\"{status} ({self.match_rate:.0%} match rate)\"]\n    for m in self.matches:\n        icon = \"+\" if m.matched else \"-\"\n        actual_str = (\n            f\" -&gt; {m.actual.name}({m.actual.arguments})\"\n            if m.actual\n            else \" -&gt; (no match)\"\n        )\n        lines.append(\n            f\"  [{icon}] {m.expected.name}({m.expected.arguments}){actual_str}\"\n        )\n        if m.details:\n            lines.append(f\"      {m.details}\")\n    return \"\\n\".join(lines)\n</code></pre>"},{"location":"reference/evaluators/","title":"Evaluators","text":"<p>Built-in evaluators for comparing expected vs actual tool calls.</p>"},{"location":"reference/evaluators/#russo.evaluators","title":"evaluators","text":"<p>Built-in evaluators for comparing expected vs actual tool calls.</p>"},{"location":"reference/evaluators/#russo.evaluators.ExactEvaluator","title":"ExactEvaluator","text":"<pre><code>ExactEvaluator(*, match_order: bool = False, ignore_extra_args: bool = False, ignore_extra_calls: bool = True)\n</code></pre> <p>Evaluates tool calls by exact name + arguments match.</p> <p>Supports optional config for relaxed matching: - match_order: If True, tool calls must appear in the same order. - ignore_extra_args: If True, actual calls may contain extra arguments. - ignore_extra_calls: If True, extra actual calls don't cause failure.</p> Usage <p>evaluator = ExactEvaluator() result = evaluator.evaluate(expected=[...], actual=[...])</p> Source code in <code>src/russo/evaluators/exact.py</code> <pre><code>def __init__(\n    self,\n    *,\n    match_order: bool = False,\n    ignore_extra_args: bool = False,\n    ignore_extra_calls: bool = True,\n) -&gt; None:\n    self.match_order = match_order\n    self.ignore_extra_args = ignore_extra_args\n    self.ignore_extra_calls = ignore_extra_calls\n</code></pre>"},{"location":"reference/evaluators/#russo.evaluators.ExactEvaluator.evaluate","title":"evaluate","text":"<pre><code>evaluate(expected: list[ToolCall], actual: list[ToolCall]) -&gt; EvalResult\n</code></pre> <p>Compare expected tool calls against actual ones.</p> Source code in <code>src/russo/evaluators/exact.py</code> <pre><code>def evaluate(self, expected: list[ToolCall], actual: list[ToolCall]) -&gt; EvalResult:\n    \"\"\"Compare expected tool calls against actual ones.\"\"\"\n    if not expected:\n        return EvalResult(passed=True, expected=expected, actual=actual, matches=[])\n\n    matches: list[ToolCallMatch] = []\n    remaining_actual = list(actual)\n\n    for i, exp in enumerate(expected):\n        match = self._find_match(exp, remaining_actual, index=i if self.match_order else None)\n        matches.append(match)\n        if match.matched and match.actual in remaining_actual:\n            remaining_actual.remove(match.actual)\n\n    all_matched = all(m.matched for m in matches)\n\n    extra_calls_ok = self.ignore_extra_calls or len(remaining_actual) == 0\n    passed = all_matched and extra_calls_ok\n\n    if not extra_calls_ok and all_matched:\n        for leftover in remaining_actual:\n            matches.append(\n                ToolCallMatch(\n                    expected=ToolCall(name=\"(none)\", arguments={}),\n                    actual=leftover,\n                    matched=False,\n                    details=f\"Unexpected extra tool call: {leftover.name}\",\n                )\n            )\n\n    return EvalResult(passed=passed, expected=expected, actual=actual, matches=matches)\n</code></pre>"},{"location":"reference/evaluators/exact/","title":"Exact Evaluator","text":"<p>Exact-match evaluator for tool calls.</p>"},{"location":"reference/evaluators/exact/#russo.evaluators.exact","title":"exact","text":"<p>Exact-match evaluator for tool calls.</p>"},{"location":"reference/evaluators/exact/#russo.evaluators.exact.ExactEvaluator","title":"ExactEvaluator","text":"<pre><code>ExactEvaluator(*, match_order: bool = False, ignore_extra_args: bool = False, ignore_extra_calls: bool = True)\n</code></pre> <p>Evaluates tool calls by exact name + arguments match.</p> <p>Supports optional config for relaxed matching: - match_order: If True, tool calls must appear in the same order. - ignore_extra_args: If True, actual calls may contain extra arguments. - ignore_extra_calls: If True, extra actual calls don't cause failure.</p> Usage <p>evaluator = ExactEvaluator() result = evaluator.evaluate(expected=[...], actual=[...])</p> Source code in <code>src/russo/evaluators/exact.py</code> <pre><code>def __init__(\n    self,\n    *,\n    match_order: bool = False,\n    ignore_extra_args: bool = False,\n    ignore_extra_calls: bool = True,\n) -&gt; None:\n    self.match_order = match_order\n    self.ignore_extra_args = ignore_extra_args\n    self.ignore_extra_calls = ignore_extra_calls\n</code></pre>"},{"location":"reference/evaluators/exact/#russo.evaluators.exact.ExactEvaluator.evaluate","title":"evaluate","text":"<pre><code>evaluate(expected: list[ToolCall], actual: list[ToolCall]) -&gt; EvalResult\n</code></pre> <p>Compare expected tool calls against actual ones.</p> Source code in <code>src/russo/evaluators/exact.py</code> <pre><code>def evaluate(self, expected: list[ToolCall], actual: list[ToolCall]) -&gt; EvalResult:\n    \"\"\"Compare expected tool calls against actual ones.\"\"\"\n    if not expected:\n        return EvalResult(passed=True, expected=expected, actual=actual, matches=[])\n\n    matches: list[ToolCallMatch] = []\n    remaining_actual = list(actual)\n\n    for i, exp in enumerate(expected):\n        match = self._find_match(exp, remaining_actual, index=i if self.match_order else None)\n        matches.append(match)\n        if match.matched and match.actual in remaining_actual:\n            remaining_actual.remove(match.actual)\n\n    all_matched = all(m.matched for m in matches)\n\n    extra_calls_ok = self.ignore_extra_calls or len(remaining_actual) == 0\n    passed = all_matched and extra_calls_ok\n\n    if not extra_calls_ok and all_matched:\n        for leftover in remaining_actual:\n            matches.append(\n                ToolCallMatch(\n                    expected=ToolCall(name=\"(none)\", arguments={}),\n                    actual=leftover,\n                    matched=False,\n                    details=f\"Unexpected extra tool call: {leftover.name}\",\n                )\n            )\n\n    return EvalResult(passed=passed, expected=expected, actual=actual, matches=matches)\n</code></pre>"},{"location":"reference/parsers/","title":"Parsers","text":"<p>Built-in response parsers for normalizing provider-specific tool call formats.</p>"},{"location":"reference/parsers/#russo.parsers","title":"parsers","text":"<p>Built-in response parsers for normalizing provider-specific tool call formats.</p>"},{"location":"reference/parsers/#russo.parsers.GeminiResponseParser","title":"GeminiResponseParser","text":"<p>Parses Gemini GenerateContentResponse into AgentResponse.</p> <p>Handles the Gemini response format where tool calls appear as function_call parts in response.candidates[].content.parts[].</p> <p>Works with both the raw dict format and the google-genai SDK objects.</p> Usage <p>parser = GeminiResponseParser() response = parser.parse(gemini_raw_response)</p>"},{"location":"reference/parsers/#russo.parsers.GeminiResponseParser.parse","title":"parse","text":"<pre><code>parse(raw_response: Any) -&gt; AgentResponse\n</code></pre> <p>Parse a Gemini response into a normalized AgentResponse.</p> Source code in <code>src/russo/parsers/gemini.py</code> <pre><code>def parse(self, raw_response: Any) -&gt; AgentResponse:\n    \"\"\"Parse a Gemini response into a normalized AgentResponse.\"\"\"\n    tool_calls: list[ToolCall] = []\n\n    # Handle google-genai SDK response objects\n    candidates = _get_attr_or_key(raw_response, \"candidates\", [])\n    for candidate in candidates:\n        content = _get_attr_or_key(candidate, \"content\", None)\n        if content is None:\n            continue\n        parts = _get_attr_or_key(content, \"parts\", [])\n        for part in parts:\n            fc = _get_attr_or_key(part, \"function_call\", None)\n            if fc is not None:\n                name = _get_attr_or_key(fc, \"name\", \"\")\n                args = _get_attr_or_key(fc, \"args\", {})\n                if isinstance(args, str):\n                    import json\n\n                    args = json.loads(args)\n                tool_calls.append(ToolCall(name=name, arguments=dict(args) if args else {}))\n\n    return AgentResponse(tool_calls=tool_calls, raw=raw_response)\n</code></pre>"},{"location":"reference/parsers/#russo.parsers.OpenAIResponseParser","title":"OpenAIResponseParser","text":"<p>Parses OpenAI ChatCompletion responses into AgentResponse.</p> <p>Handles the OpenAI format where tool calls appear at: response.choices[].message.tool_calls[]</p> <p>Each tool call has: {id, type, function: {name, arguments}}.</p> <p>Works with both the raw dict format and the openai SDK objects.</p> Usage <p>parser = OpenAIResponseParser() response = parser.parse(openai_raw_response)</p>"},{"location":"reference/parsers/#russo.parsers.OpenAIResponseParser.parse","title":"parse","text":"<pre><code>parse(raw_response: Any) -&gt; AgentResponse\n</code></pre> <p>Parse an OpenAI response into a normalized AgentResponse.</p> Source code in <code>src/russo/parsers/openai.py</code> <pre><code>def parse(self, raw_response: Any) -&gt; AgentResponse:\n    \"\"\"Parse an OpenAI response into a normalized AgentResponse.\"\"\"\n    tool_calls: list[ToolCall] = []\n\n    choices = _get_attr_or_key(raw_response, \"choices\", [])\n    for choice in choices:\n        message = _get_attr_or_key(choice, \"message\", None)\n        if message is None:\n            continue\n        raw_tool_calls = _get_attr_or_key(message, \"tool_calls\", [])\n        if not raw_tool_calls:\n            continue\n        for tc in raw_tool_calls:\n            function = _get_attr_or_key(tc, \"function\", None)\n            if function is None:\n                continue\n            name = _get_attr_or_key(function, \"name\", \"\")\n            arguments_raw = _get_attr_or_key(function, \"arguments\", \"{}\")\n            if isinstance(arguments_raw, str):\n                try:\n                    arguments = json.loads(arguments_raw)\n                except (json.JSONDecodeError, TypeError):\n                    arguments = {}\n            elif isinstance(arguments_raw, dict):\n                arguments = arguments_raw\n            else:\n                arguments = {}\n            tool_calls.append(ToolCall(name=name, arguments=arguments))\n\n    return AgentResponse(tool_calls=tool_calls, raw=raw_response)\n</code></pre>"},{"location":"reference/parsers/gemini/","title":"Gemini Parser","text":"<p>Parser for Google Gemini function call responses.</p>"},{"location":"reference/parsers/gemini/#russo.parsers.gemini","title":"gemini","text":"<p>Parser for Google Gemini function call responses.</p>"},{"location":"reference/parsers/gemini/#russo.parsers.gemini.GeminiResponseParser","title":"GeminiResponseParser","text":"<p>Parses Gemini GenerateContentResponse into AgentResponse.</p> <p>Handles the Gemini response format where tool calls appear as function_call parts in response.candidates[].content.parts[].</p> <p>Works with both the raw dict format and the google-genai SDK objects.</p> Usage <p>parser = GeminiResponseParser() response = parser.parse(gemini_raw_response)</p>"},{"location":"reference/parsers/gemini/#russo.parsers.gemini.GeminiResponseParser.parse","title":"parse","text":"<pre><code>parse(raw_response: Any) -&gt; AgentResponse\n</code></pre> <p>Parse a Gemini response into a normalized AgentResponse.</p> Source code in <code>src/russo/parsers/gemini.py</code> <pre><code>def parse(self, raw_response: Any) -&gt; AgentResponse:\n    \"\"\"Parse a Gemini response into a normalized AgentResponse.\"\"\"\n    tool_calls: list[ToolCall] = []\n\n    # Handle google-genai SDK response objects\n    candidates = _get_attr_or_key(raw_response, \"candidates\", [])\n    for candidate in candidates:\n        content = _get_attr_or_key(candidate, \"content\", None)\n        if content is None:\n            continue\n        parts = _get_attr_or_key(content, \"parts\", [])\n        for part in parts:\n            fc = _get_attr_or_key(part, \"function_call\", None)\n            if fc is not None:\n                name = _get_attr_or_key(fc, \"name\", \"\")\n                args = _get_attr_or_key(fc, \"args\", {})\n                if isinstance(args, str):\n                    import json\n\n                    args = json.loads(args)\n                tool_calls.append(ToolCall(name=name, arguments=dict(args) if args else {}))\n\n    return AgentResponse(tool_calls=tool_calls, raw=raw_response)\n</code></pre>"},{"location":"reference/parsers/openai/","title":"OpenAI Parser","text":"<p>Parser for OpenAI chat completion tool call responses.</p>"},{"location":"reference/parsers/openai/#russo.parsers.openai","title":"openai","text":"<p>Parser for OpenAI chat completion tool call responses.</p>"},{"location":"reference/parsers/openai/#russo.parsers.openai.OpenAIResponseParser","title":"OpenAIResponseParser","text":"<p>Parses OpenAI ChatCompletion responses into AgentResponse.</p> <p>Handles the OpenAI format where tool calls appear at: response.choices[].message.tool_calls[]</p> <p>Each tool call has: {id, type, function: {name, arguments}}.</p> <p>Works with both the raw dict format and the openai SDK objects.</p> Usage <p>parser = OpenAIResponseParser() response = parser.parse(openai_raw_response)</p>"},{"location":"reference/parsers/openai/#russo.parsers.openai.OpenAIResponseParser.parse","title":"parse","text":"<pre><code>parse(raw_response: Any) -&gt; AgentResponse\n</code></pre> <p>Parse an OpenAI response into a normalized AgentResponse.</p> Source code in <code>src/russo/parsers/openai.py</code> <pre><code>def parse(self, raw_response: Any) -&gt; AgentResponse:\n    \"\"\"Parse an OpenAI response into a normalized AgentResponse.\"\"\"\n    tool_calls: list[ToolCall] = []\n\n    choices = _get_attr_or_key(raw_response, \"choices\", [])\n    for choice in choices:\n        message = _get_attr_or_key(choice, \"message\", None)\n        if message is None:\n            continue\n        raw_tool_calls = _get_attr_or_key(message, \"tool_calls\", [])\n        if not raw_tool_calls:\n            continue\n        for tc in raw_tool_calls:\n            function = _get_attr_or_key(tc, \"function\", None)\n            if function is None:\n                continue\n            name = _get_attr_or_key(function, \"name\", \"\")\n            arguments_raw = _get_attr_or_key(function, \"arguments\", \"{}\")\n            if isinstance(arguments_raw, str):\n                try:\n                    arguments = json.loads(arguments_raw)\n                except (json.JSONDecodeError, TypeError):\n                    arguments = {}\n            elif isinstance(arguments_raw, dict):\n                arguments = arguments_raw\n            else:\n                arguments = {}\n            tool_calls.append(ToolCall(name=name, arguments=arguments))\n\n    return AgentResponse(tool_calls=tool_calls, raw=raw_response)\n</code></pre>"},{"location":"reference/synthesizers/","title":"Synthesizers","text":"<p>Built-in audio synthesizers.</p>"},{"location":"reference/synthesizers/#russo.synthesizers","title":"synthesizers","text":"<p>Built-in audio synthesizers.</p>"},{"location":"reference/synthesizers/#russo.synthesizers.GoogleSynthesizer","title":"GoogleSynthesizer","text":"<pre><code>GoogleSynthesizer(*, voice: str = 'Kore', model: str = 'gemini-2.5-flash-preview-tts', api_key: str | None = None, vertexai: bool = False, project: str | None = None, location: str | None = None, audio_format: Literal['wav', 'mp3', 'pcm', 'ogg'] = 'wav', sample_rate: int = 24000)\n</code></pre> <p>Synthesizes audio from text using Google Gemini's TTS.</p> <p>Supports two auth modes:</p> <ol> <li> <p>Google AI API (api_key):     synth = GoogleSynthesizer(api_key=\"AIza...\")</p> </li> <li> <p>Vertex AI (ADC / GOOGLE_APPLICATION_CREDENTIALS):     synth = GoogleSynthesizer(vertexai=True, project=\"my-proj\", location=\"us-central1\")</p> </li> </ol> Source code in <code>src/russo/synthesizers/google.py</code> <pre><code>def __init__(\n    self,\n    *,\n    voice: str = \"Kore\",\n    model: str = \"gemini-2.5-flash-preview-tts\",\n    api_key: str | None = None,\n    vertexai: bool = False,\n    project: str | None = None,\n    location: str | None = None,\n    audio_format: Literal[\"wav\", \"mp3\", \"pcm\", \"ogg\"] = \"wav\",\n    sample_rate: int = 24000,\n) -&gt; None:\n    self.voice = voice\n    self.model = model\n    self.audio_format = audio_format\n    self.sample_rate = sample_rate\n\n    if api_key:\n        self._client = genai.Client(api_key=api_key)\n    elif vertexai:\n        self._client = genai.Client(\n            vertexai=True,\n            project=project,\n            location=location or \"us-central1\",\n        )\n    else:\n        # Fall back: let the SDK resolve from env (GOOGLE_API_KEY, ADC, etc.)\n        self._client = genai.Client()\n</code></pre>"},{"location":"reference/synthesizers/#russo.synthesizers.GoogleSynthesizer.synthesize","title":"synthesize  <code>async</code>","text":"<pre><code>synthesize(text: str) -&gt; Audio\n</code></pre> <p>Convert text to audio using Gemini TTS.</p> Source code in <code>src/russo/synthesizers/google.py</code> <pre><code>async def synthesize(self, text: str) -&gt; Audio:\n    \"\"\"Convert text to audio using Gemini TTS.\"\"\"\n    response = await self._client.aio.models.generate_content(\n        model=self.model,\n        contents=text,\n        config=types.GenerateContentConfig(\n            response_modalities=[\"AUDIO\"],\n            speech_config=types.SpeechConfig(\n                voice_config=types.VoiceConfig(\n                    prebuilt_voice_config=types.PrebuiltVoiceConfig(\n                        voice_name=self.voice\n                    ),\n                ),\n            ),\n        ),\n    )\n    audio_data = b\"\"\n    if response.candidates:\n        for part in response.candidates[0].content.parts:\n            if part.inline_data and part.inline_data.data:\n                audio_data += part.inline_data.data\n\n    return Audio(\n        data=audio_data,\n        format=self.audio_format,\n        sample_rate=self.sample_rate,\n    )\n</code></pre>"},{"location":"reference/synthesizers/google/","title":"Google Synthesizer","text":"<p>Google Gemini TTS synthesizer.</p>"},{"location":"reference/synthesizers/google/#russo.synthesizers.google","title":"google","text":"<p>Google Gemini TTS synthesizer.</p>"},{"location":"reference/synthesizers/google/#russo.synthesizers.google.GoogleSynthesizer","title":"GoogleSynthesizer","text":"<pre><code>GoogleSynthesizer(*, voice: str = 'Kore', model: str = 'gemini-2.5-flash-preview-tts', api_key: str | None = None, vertexai: bool = False, project: str | None = None, location: str | None = None, audio_format: Literal['wav', 'mp3', 'pcm', 'ogg'] = 'wav', sample_rate: int = 24000)\n</code></pre> <p>Synthesizes audio from text using Google Gemini's TTS.</p> <p>Supports two auth modes:</p> <ol> <li> <p>Google AI API (api_key):     synth = GoogleSynthesizer(api_key=\"AIza...\")</p> </li> <li> <p>Vertex AI (ADC / GOOGLE_APPLICATION_CREDENTIALS):     synth = GoogleSynthesizer(vertexai=True, project=\"my-proj\", location=\"us-central1\")</p> </li> </ol> Source code in <code>src/russo/synthesizers/google.py</code> <pre><code>def __init__(\n    self,\n    *,\n    voice: str = \"Kore\",\n    model: str = \"gemini-2.5-flash-preview-tts\",\n    api_key: str | None = None,\n    vertexai: bool = False,\n    project: str | None = None,\n    location: str | None = None,\n    audio_format: Literal[\"wav\", \"mp3\", \"pcm\", \"ogg\"] = \"wav\",\n    sample_rate: int = 24000,\n) -&gt; None:\n    self.voice = voice\n    self.model = model\n    self.audio_format = audio_format\n    self.sample_rate = sample_rate\n\n    if api_key:\n        self._client = genai.Client(api_key=api_key)\n    elif vertexai:\n        self._client = genai.Client(\n            vertexai=True,\n            project=project,\n            location=location or \"us-central1\",\n        )\n    else:\n        # Fall back: let the SDK resolve from env (GOOGLE_API_KEY, ADC, etc.)\n        self._client = genai.Client()\n</code></pre>"},{"location":"reference/synthesizers/google/#russo.synthesizers.google.GoogleSynthesizer.synthesize","title":"synthesize  <code>async</code>","text":"<pre><code>synthesize(text: str) -&gt; Audio\n</code></pre> <p>Convert text to audio using Gemini TTS.</p> Source code in <code>src/russo/synthesizers/google.py</code> <pre><code>async def synthesize(self, text: str) -&gt; Audio:\n    \"\"\"Convert text to audio using Gemini TTS.\"\"\"\n    response = await self._client.aio.models.generate_content(\n        model=self.model,\n        contents=text,\n        config=types.GenerateContentConfig(\n            response_modalities=[\"AUDIO\"],\n            speech_config=types.SpeechConfig(\n                voice_config=types.VoiceConfig(\n                    prebuilt_voice_config=types.PrebuiltVoiceConfig(\n                        voice_name=self.voice\n                    ),\n                ),\n            ),\n        ),\n    )\n    audio_data = b\"\"\n    if response.candidates:\n        for part in response.candidates[0].content.parts:\n            if part.inline_data and part.inline_data.data:\n                audio_data += part.inline_data.data\n\n    return Audio(\n        data=audio_data,\n        format=self.audio_format,\n        sample_rate=self.sample_rate,\n    )\n</code></pre>"},{"location":"tutorial/","title":"Tutorial","text":"<p>This tutorial covers every major component of russo in detail. Work through it sequentially, or jump to the section you need.</p>"},{"location":"tutorial/#overview","title":"Overview","text":"<p>russo's architecture is a simple pipeline with pluggable components:</p> <pre><code>graph LR\n    A[\"Text Prompt\"] --&gt; B[\"Synthesizer\"]\n    B --&gt;|Audio| C[\"Agent\"]\n    C --&gt;|AgentResponse| D[\"Evaluator\"]\n    D --&gt;|EvalResult| E[\"Pass / Fail\"]</code></pre> <p>Each component is defined by a protocol (structural typing). You don't need to inherit from anything \u2014 just implement the right method signature.</p>"},{"location":"tutorial/#sections","title":"Sections","text":"Section What You'll Learn Pipeline How <code>russo.run()</code> orchestrates the full flow Adapters Connecting to Gemini, OpenAI, HTTP, WebSocket, or custom agents Synthesizers Converting text prompts to audio Evaluators Comparing expected vs actual tool calls Caching Skipping TTS calls on repeated test runs pytest Plugin Markers, fixtures, CLI options, and reporting"},{"location":"tutorial/adapters/","title":"Adapters","text":"<p>Adapters connect russo to your agent. Each adapter implements the <code>Agent</code> protocol:</p> <pre><code>class Agent(Protocol):\n    async def run(self, audio: Audio) -&gt; AgentResponse: ...\n</code></pre> <p>russo ships with adapters for the most common patterns.</p>"},{"location":"tutorial/adapters/#built-in-adapters","title":"Built-in Adapters","text":""},{"location":"tutorial/adapters/#gemini-sdk","title":"Gemini SDK","text":"<pre><code>from russo.adapters import GeminiAgent, GeminiLiveAgent\n</code></pre> <p><code>GeminiAgent</code> \u2014 standard <code>generate_content</code> (request/response):</p> <pre><code>agent = GeminiAgent(\n    api_key=\"...\",\n    model=\"gemini-2.0-flash\",\n    tools=[{\"function_declarations\": [...]}],\n)\n</code></pre> <p><code>GeminiLiveAgent</code> \u2014 Live API over WebSocket (streaming/real-time):</p> <pre><code>agent = GeminiLiveAgent(\n    api_key=\"...\",\n    model=\"gemini-2.0-flash-live-001\",\n    tools=[{\"function_declarations\": [...]}],\n)\n</code></pre>"},{"location":"tutorial/adapters/#openai-sdk","title":"OpenAI SDK","text":"<p>Note</p> <p>Requires the <code>openai</code> extra: <code>pip install \"russo[openai]\"</code></p> <pre><code>from russo.adapters import OpenAIAgent, OpenAIRealtimeAgent\n</code></pre> <p><code>OpenAIAgent</code> \u2014 Chat Completions with audio input:</p> <pre><code>agent = OpenAIAgent(\n    api_key=\"...\",\n    model=\"gpt-4o-audio-preview\",\n    tools=[...],\n)\n</code></pre> <p><code>OpenAIRealtimeAgent</code> \u2014 Realtime API over WebSocket:</p> <pre><code>agent = OpenAIRealtimeAgent(\n    api_key=\"...\",\n    model=\"gpt-4o-realtime-preview\",\n    tools=[...],\n)\n</code></pre>"},{"location":"tutorial/adapters/#http","title":"HTTP","text":"<p>Send audio to any HTTP endpoint:</p> <pre><code>from russo.adapters import HttpAgent\nfrom russo.parsers import GeminiResponseParser\n\nagent = HttpAgent(\n    url=\"https://my-agent.example.com/audio\",\n    parser=GeminiResponseParser(),\n)\n</code></pre>"},{"location":"tutorial/adapters/#websocket","title":"WebSocket","text":"<p>Note</p> <p>Requires the <code>ws</code> extra: <code>pip install \"russo[ws]\"</code></p> <pre><code>from russo.adapters import WebSocketAgent\n\nagent = WebSocketAgent(\n    url=\"wss://my-agent.example.com/ws\",\n    parser=my_parser,\n)\n</code></pre>"},{"location":"tutorial/adapters/#callable-custom","title":"Callable (Custom)","text":"<p>Wrap any async function:</p> <pre><code>import russo\n\n@russo.agent\nasync def my_agent(audio: russo.Audio) -&gt; russo.AgentResponse:\n    # Your custom logic here\n    result = await call_my_api(audio.data)\n    return russo.AgentResponse(\n        tool_calls=[russo.ToolCall(name=\"...\", arguments={...})]\n    )\n</code></pre> <p>Or use the class directly:</p> <pre><code>from russo.adapters import CallableAgent\n\nagent = CallableAgent(my_async_function)\n</code></pre>"},{"location":"tutorial/adapters/#custom-adapters","title":"Custom Adapters","text":"<p>You don't need to inherit from anything. Just implement the <code>run</code> method:</p> <pre><code>class MyCustomAgent:\n    async def run(self, audio: russo.Audio) -&gt; russo.AgentResponse:\n        # Send audio to your service\n        raw = await my_service.process(audio.data)\n        # Parse and return\n        return russo.AgentResponse(\n            tool_calls=[russo.ToolCall(name=raw[\"tool\"], arguments=raw[\"args\"])]\n        )\n</code></pre> <p>russo uses structural typing \u2014 if your class has <code>async def run(self, audio: Audio) -&gt; AgentResponse</code>, it's an Agent.</p>"},{"location":"tutorial/adapters/#api-reference","title":"API Reference","text":"<p>See the Adapters reference for full API docs on each adapter.</p>"},{"location":"tutorial/caching/","title":"Caching","text":"<p>TTS calls are slow and cost money. russo's caching layer saves synthesized audio to disk so repeated test runs skip the TTS call entirely.</p>"},{"location":"tutorial/caching/#how-it-works","title":"How It Works","text":"<p>Audio is cached by a deterministic hash of the prompt text (plus optional metadata like voice/model). On subsequent runs, if the cache has a hit, the synthesizer is bypassed.</p> <pre><code>First run:  prompt \u2192 TTS API \u2192 audio \u2192 cache \u2192 agent\nNext runs:  prompt \u2192 cache hit \u2192 audio \u2192 agent   (TTS skipped)\n</code></pre>"},{"location":"tutorial/caching/#cachedsynthesizer","title":"CachedSynthesizer","text":"<p>Wrap any synthesizer with <code>CachedSynthesizer</code>:</p> <pre><code>from russo import CachedSynthesizer\nfrom russo.synthesizers import GoogleSynthesizer\n\nsynth = CachedSynthesizer(GoogleSynthesizer(api_key=\"...\"))\n</code></pre>"},{"location":"tutorial/caching/#include-config-in-cache-key","title":"Include Config in Cache Key","text":"<p>If you change the voice or model, you want the cache to invalidate:</p> <pre><code>synth = CachedSynthesizer(\n    GoogleSynthesizer(api_key=\"...\", voice=\"Kore\"),\n    cache_key_extra={\"voice\": \"Kore\", \"model\": \"gemini-2.5-flash-preview-tts\"},\n)\n</code></pre>"},{"location":"tutorial/caching/#custom-cache-directory","title":"Custom Cache Directory","text":"<pre><code>from russo import AudioCache, CachedSynthesizer\n\ncache = AudioCache(Path(\"/tmp/russo_audio_cache\"))\nsynth = CachedSynthesizer(GoogleSynthesizer(api_key=\"...\"), cache=cache)\n</code></pre>"},{"location":"tutorial/caching/#disable-at-runtime","title":"Disable at Runtime","text":"<pre><code>synth = CachedSynthesizer(GoogleSynthesizer(api_key=\"...\"), enabled=False)\n</code></pre>"},{"location":"tutorial/caching/#audiocache","title":"AudioCache","text":"<p>The low-level cache stores audio as file pairs:</p> <ul> <li><code>&lt;key&gt;.audio</code> \u2014 raw audio bytes</li> <li><code>&lt;key&gt;.meta</code> \u2014 JSON metadata (format, sample rate, prompt)</li> </ul> <pre><code>from russo import AudioCache\n\ncache = AudioCache()               # default: .russo_cache/\ncache = AudioCache(Path(\"custom\")) # custom directory\n\n# Manual operations\ncache.get(\"abc123\")       # Audio | None\ncache.put(\"abc123\", audio, prompt=\"hello\")\ncache.size()              # number of cached entries\ncache.clear()             # remove all entries\n</code></pre>"},{"location":"tutorial/caching/#pytest-integration","title":"pytest Integration","text":"<p>The pytest plugin automatically wraps your synthesizer with caching. Control it via CLI:</p> <pre><code># Caching is ON by default\npytest\n\n# Disable caching\npytest --russo-no-cache\n\n# Clear cache before running\npytest --russo-clear-cache\n\n# Custom cache directory\npytest --russo-cache-dir /tmp/my_cache\n</code></pre>"},{"location":"tutorial/caching/#api-reference","title":"API Reference","text":"<p>See <code>AudioCache</code> and <code>CachedSynthesizer</code> for the full API docs.</p>"},{"location":"tutorial/evaluators/","title":"Evaluators","text":"<p>Evaluators compare expected tool calls against the actual tool calls returned by the agent.</p>"},{"location":"tutorial/evaluators/#protocol","title":"Protocol","text":"<pre><code>class Evaluator(Protocol):\n    def evaluate(self, expected: list[ToolCall], actual: list[ToolCall]) -&gt; EvalResult: ...\n</code></pre>"},{"location":"tutorial/evaluators/#built-in-exactevaluator","title":"Built-in: ExactEvaluator","text":"<p>The default evaluator performs exact name + arguments matching:</p> <pre><code>from russo.evaluators import ExactEvaluator\n\nevaluator = ExactEvaluator()\n</code></pre>"},{"location":"tutorial/evaluators/#configuration","title":"Configuration","text":"<pre><code>evaluator = ExactEvaluator(\n    match_order=False,         # True = tool calls must match in order\n    ignore_extra_args=False,   # True = actual may have extra arguments\n    ignore_extra_calls=True,   # True = extra actual calls don't cause failure\n)\n</code></pre>"},{"location":"tutorial/evaluators/#examples","title":"Examples","text":"<pre><code>from russo._types import ToolCall\n\nexpected = [ToolCall(name=\"book_flight\", arguments={\"from\": \"NYC\", \"to\": \"LA\"})]\nactual = [ToolCall(name=\"book_flight\", arguments={\"from\": \"NYC\", \"to\": \"LA\"})]\n\nresult = evaluator.evaluate(expected=expected, actual=actual)\nassert result.passed  # True\nassert result.match_rate == 1.0\n</code></pre> <p>With <code>ignore_extra_args=True</code>:</p> <pre><code>evaluator = ExactEvaluator(ignore_extra_args=True)\n\nexpected = [ToolCall(name=\"book_flight\", arguments={\"from\": \"NYC\"})]\nactual = [ToolCall(name=\"book_flight\", arguments={\"from\": \"NYC\", \"to\": \"LA\", \"class\": \"economy\"})]\n\nresult = evaluator.evaluate(expected=expected, actual=actual)\nassert result.passed  # True \u2014 extra args are ignored\n</code></pre>"},{"location":"tutorial/evaluators/#custom-evaluators","title":"Custom Evaluators","text":"<p>Implement the protocol for custom matching logic:</p> <pre><code>class FuzzyEvaluator:\n    \"\"\"Evaluator that uses fuzzy string matching on argument values.\"\"\"\n\n    def evaluate(self, expected: list[ToolCall], actual: list[ToolCall]) -&gt; EvalResult:\n        # Your custom logic here\n        ...\n</code></pre>"},{"location":"tutorial/evaluators/#api-reference","title":"API Reference","text":"<p>See <code>ExactEvaluator</code> for the full API docs.</p>"},{"location":"tutorial/pipeline/","title":"Pipeline","text":"<p>The pipeline is the core of russo. It chains three components together: Synthesizer \u2192 Agent \u2192 Evaluator.</p>"},{"location":"tutorial/pipeline/#russorun","title":"<code>russo.run()</code>","text":"<p>The <code>run</code> function is the main entry point:</p> <pre><code>result = await russo.run(\n    prompt=\"Book a flight from Berlin to Rome\",\n    synthesizer=my_synthesizer,\n    agent=my_agent,\n    evaluator=ExactEvaluator(),\n    expect=[russo.tool_call(\"book_flight\", from_city=\"Berlin\", to_city=\"Rome\")],\n)\n</code></pre> <p>All arguments are keyword-only. Here's what each does:</p> Argument Type Purpose <code>prompt</code> <code>str</code> Text to synthesize into audio <code>synthesizer</code> <code>Synthesizer</code> Converts text \u2192 audio <code>agent</code> <code>Agent</code> The agent under test (audio \u2192 tool calls) <code>evaluator</code> <code>Evaluator</code> Compares expected vs actual tool calls <code>expect</code> <code>list[ToolCall]</code> The tool calls you expect the agent to make"},{"location":"tutorial/pipeline/#what-happens-inside","title":"What Happens Inside","text":"<pre><code>async def run(*, prompt, synthesizer, agent, evaluator, expect):\n    audio = await synthesizer.synthesize(prompt)    # 1. Text \u2192 Audio\n    response = await agent.run(audio)               # 2. Audio \u2192 AgentResponse\n    return evaluator.evaluate(                      # 3. Compare\n        expected=expect,\n        actual=response.tool_calls,\n    )\n</code></pre> <p>That's it. Three steps. Each step is pluggable.</p>"},{"location":"tutorial/pipeline/#the-result","title":"The Result","text":"<p><code>russo.run()</code> returns an <code>EvalResult</code>:</p> <pre><code>result.passed       # bool \u2014 did all expected tool calls match?\nresult.match_rate   # float \u2014 fraction of expected calls that matched (0.0\u20131.0)\nresult.expected     # list[ToolCall] \u2014 what you expected\nresult.actual       # list[ToolCall] \u2014 what the agent returned\nresult.matches      # list[ToolCallMatch] \u2014 per-call match details\nresult.summary()    # str \u2014 human-readable summary\n</code></pre>"},{"location":"tutorial/pipeline/#assertions","title":"Assertions","text":"<p>Use <code>russo.assert_tool_calls()</code> for rich error messages:</p> <pre><code>russo.assert_tool_calls(result)\n# Raises ToolCallAssertionError with detailed diff if it fails\n</code></pre> <p>Or use standard assertions:</p> <pre><code>assert result.passed\nassert result.match_rate &gt;= 0.8  # at least 80% match\n</code></pre>"},{"location":"tutorial/pipeline/#api-reference","title":"API Reference","text":"<p>See <code>russo.run()</code> for the full API docs.</p>"},{"location":"tutorial/pytest-plugin/","title":"pytest Plugin","text":"<p>russo ships with a pytest plugin that's auto-discovered via the <code>pytest11</code> entry point. No configuration needed \u2014 just install russo and it's available.</p>"},{"location":"tutorial/pytest-plugin/#markers","title":"Markers","text":"<p>Use <code>@pytest.mark.russo</code> to declare test scenarios:</p> <pre><code>import pytest\nimport russo\n\n@pytest.mark.russo(\n    prompt=\"Book a flight from NYC to LA\",\n    expect=[russo.tool_call(\"book_flight\", from_city=\"NYC\", to_city=\"LA\")],\n)\nasync def test_book_flight(russo_result):\n    russo.assert_tool_calls(russo_result)\n</code></pre>"},{"location":"tutorial/pytest-plugin/#marker-arguments","title":"Marker Arguments","text":"Argument Type Description <code>prompt</code> <code>str</code> Text prompt to synthesize <code>expect</code> <code>list[ToolCall]</code> Expected tool calls"},{"location":"tutorial/pytest-plugin/#fixtures","title":"Fixtures","text":""},{"location":"tutorial/pytest-plugin/#required-fixtures-you-provide","title":"Required Fixtures (You Provide)","text":"<p>You must define these in your <code>conftest.py</code>:</p> <pre><code># conftest.py\nimport pytest\nfrom russo.synthesizers import GoogleSynthesizer\nfrom russo.adapters import GeminiLiveAgent\n\n@pytest.fixture(scope=\"session\")\ndef russo_synthesizer():\n    \"\"\"The TTS synthesizer to use.\"\"\"\n    return GoogleSynthesizer(api_key=\"...\")\n\n@pytest.fixture(scope=\"session\")\ndef russo_agent():\n    \"\"\"The agent under test.\"\"\"\n    return GeminiLiveAgent(api_key=\"...\", tools=[...])\n</code></pre>"},{"location":"tutorial/pytest-plugin/#built-in-fixtures","title":"Built-in Fixtures","text":"Fixture Scope Description <code>russo_result</code> function Runs the pipeline, returns <code>EvalResult</code> <code>russo_evaluator</code> function Default <code>ExactEvaluator()</code> \u2014 override to customize <code>russo_audio_cache</code> session <code>AudioCache</code> instance \u2014 override for custom dir"},{"location":"tutorial/pytest-plugin/#override-the-evaluator","title":"Override the Evaluator","text":"<pre><code>@pytest.fixture\ndef russo_evaluator():\n    from russo.evaluators import ExactEvaluator\n    return ExactEvaluator(ignore_extra_args=True, match_order=True)\n</code></pre>"},{"location":"tutorial/pytest-plugin/#cli-options","title":"CLI Options","text":"<pre><code>pytest --russo-report report.html    # Generate HTML report\npytest --russo-no-cache              # Disable audio caching\npytest --russo-clear-cache           # Clear cache before running\npytest --russo-cache-dir ./cache     # Custom cache directory\n</code></pre>"},{"location":"tutorial/pytest-plugin/#terminal-summary","title":"Terminal Summary","text":"<p>After tests complete, russo prints a summary:</p> <pre><code>\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550 russo results \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\nPASSED  test_book_flight (100% match rate)\nFAILED  test_weather (0% match rate)\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nTotal: 2 | Passed: 1 | Failed: 1\n</code></pre>"},{"location":"tutorial/pytest-plugin/#html-report","title":"HTML Report","text":"<p>Use <code>--russo-report</code> to generate a standalone HTML report:</p> <pre><code>pytest --russo-report russo_report.html\n</code></pre>"},{"location":"tutorial/pytest-plugin/#api-reference","title":"API Reference","text":"<p>See the pytest plugin reference for full API docs.</p>"},{"location":"tutorial/synthesizers/","title":"Synthesizers","text":"<p>Synthesizers convert text prompts into audio. This is the first step of the russo pipeline.</p>"},{"location":"tutorial/synthesizers/#protocol","title":"Protocol","text":"<pre><code>class Synthesizer(Protocol):\n    async def synthesize(self, text: str) -&gt; Audio: ...\n</code></pre>"},{"location":"tutorial/synthesizers/#built-in-google-tts","title":"Built-in: Google TTS","text":"<pre><code>from russo.synthesizers import GoogleSynthesizer\n\nsynth = GoogleSynthesizer(\n    api_key=\"...\",\n    voice=\"Kore\",                              # optional\n    model=\"gemini-2.5-flash-preview-tts\",      # optional\n)\n\naudio = await synth.synthesize(\"Book a flight from Berlin to Rome\")\naudio.save(\"output.wav\")  # save to file\n</code></pre>"},{"location":"tutorial/synthesizers/#authentication-modes","title":"Authentication Modes","text":"API Key (Google AI)Vertex AI <pre><code>synth = GoogleSynthesizer(api_key=\"AIza...\")\n</code></pre> <pre><code>synth = GoogleSynthesizer(\n    project=\"my-gcp-project\",\n    location=\"us-central1\",\n)\n</code></pre>"},{"location":"tutorial/synthesizers/#custom-synthesizers","title":"Custom Synthesizers","text":"<p>Implement the protocol \u2014 no inheritance needed:</p> <pre><code>class ElevenLabsSynthesizer:\n    def __init__(self, api_key: str, voice_id: str = \"default\"):\n        self.api_key = api_key\n        self.voice_id = voice_id\n\n    async def synthesize(self, text: str) -&gt; russo.Audio:\n        # Call ElevenLabs API\n        audio_bytes = await eleven_labs_tts(text, self.voice_id, self.api_key)\n        return russo.Audio(data=audio_bytes, format=\"mp3\")\n</code></pre>"},{"location":"tutorial/synthesizers/#caching","title":"Caching","text":"<p>Wrap any synthesizer with <code>CachedSynthesizer</code> to avoid repeated TTS calls:</p> <pre><code>from russo import CachedSynthesizer\n\ncached = CachedSynthesizer(\n    GoogleSynthesizer(api_key=\"...\"),\n    cache_key_extra={\"voice\": \"Kore\"},  # invalidate cache on config change\n)\n</code></pre> <p>See Caching for details.</p>"},{"location":"tutorial/synthesizers/#api-reference","title":"API Reference","text":"<p>See <code>GoogleSynthesizer</code> for the full API docs.</p>"}]}